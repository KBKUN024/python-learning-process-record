{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ç¬¬ä¸€é¢˜  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before strip: \n",
      "after strip: \n",
      "====================\n",
      "before strip: database_host=localhost\n",
      "after strip: database_host=localhost\n",
      "====================\n",
      "key is:database_host,value is:localhost,keyçš„ç±»å‹:<class 'str'>,valueçš„ç±»å‹:<class 'str'>\n",
      "value.isdigit() False\n",
      "before strip: database_port=5432\n",
      "after strip: database_port=5432\n",
      "====================\n",
      "key is:database_port,value is:5432,keyçš„ç±»å‹:<class 'str'>,valueçš„ç±»å‹:<class 'str'>\n",
      "value.isdigit() True\n",
      "float_val is: 5432.0\n",
      "before strip: database_name=myapp\n",
      "after strip: database_name=myapp\n",
      "====================\n",
      "key is:database_name,value is:myapp,keyçš„ç±»å‹:<class 'str'>,valueçš„ç±»å‹:<class 'str'>\n",
      "value.isdigit() False\n",
      "before strip: debug_mode=True\n",
      "after strip: debug_mode=True\n",
      "====================\n",
      "key is:debug_mode,value is:True,keyçš„ç±»å‹:<class 'str'>,valueçš„ç±»å‹:<class 'str'>\n",
      "value.isdigit() False\n",
      "before strip: max_connections=100.6\n",
      "after strip: max_connections=100.6\n",
      "====================\n",
      "key is:max_connections,value is:100.6,keyçš„ç±»å‹:<class 'str'>,valueçš„ç±»å‹:<class 'str'>\n",
      "value.isdigit() False\n",
      "float_val is: 100.6\n",
      "config is: {'database_host': 'localhost', 'database_port': 5432, 'database_name': 'myapp', 'debug_mode': True, 'max_connections': 100.6}\n",
      "è§£æç»“æœï¼š {'database_host': 'localhost', 'database_port': 5432, 'database_name': 'myapp', 'debug_mode': True, 'max_connections': 100.6}\n",
      "ç±»å‹æ£€æŸ¥ï¼š\n",
      "  database_host: localhost (ç±»å‹: str)\n",
      "  database_port: 5432 (ç±»å‹: int)\n",
      "  database_name: myapp (ç±»å‹: str)\n",
      "  debug_mode: True (ç±»å‹: bool)\n",
      "  max_connections: 100.6 (ç±»å‹: float)\n"
     ]
    }
   ],
   "source": [
    "# æ ‡å‡†ç­”æ¡ˆ\n",
    "def read_config(filename):\n",
    "    \"\"\"è¯»å–é…ç½®æ–‡ä»¶å¹¶è§£æä¸ºå­—å…¸\"\"\"\n",
    "    config = {}\n",
    "\n",
    "    try:\n",
    "        with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
    "            for line in file:\n",
    "                print(\"before strip:\", line, end=\"\")\n",
    "                line = line.strip() # å…ˆå»é™¤å¤´å°¾çš„å­—ç¬¦ï¼ˆé»˜è®¤æ˜¯ç©ºæ ¼ï¼‰ï¼Œå¯ä»¥æŠŠæ¢è¡Œç¬¦å»é™¤ã€‚\n",
    "                print(\"after strip:\", line)\n",
    "                print(\"=\" * 20)\n",
    "                if line and \"=\" in line:\n",
    "                    key, value = line.split(\"=\", 1) # æŒ‰ç…§=å·æˆªå–ä¸ºä¸€ä¸ªåˆ—è¡¨ï¼Œæœ€å¤šä»å¤´å¼€å§‹æˆªå–ä¸€æ¬¡ï¼Œå…¶å®æˆ‘æ„Ÿè§‰ä¸ç”¨å†™1ä¹Ÿå¯ä»¥ï¼Œå› ä¸ºèµ‹å€¼å·åªèƒ½æœ‰ä¸€æ¬¡ï¼Œä½†æ˜¯å¯èƒ½æœ‰äº›å­—ç¬¦ä¸²åŒ…å«=å·ï¼Œè¿™ä¹ˆå†™ä¼šå¥å£®ä¸€ç‚¹ï¼Œåªä»æœ€å¼€å§‹åŒ¹é…åˆ°çš„=å·å¼€å§‹æˆªå–ï¼Œä¿é™©ä¸€ç‚¹ã€‚\n",
    "                    print(f'key is:{key},value is:{value},keyçš„ç±»å‹:{type(key)},valueçš„ç±»å‹:{type(value)}')\n",
    "                    key = key.strip() # å¿…é¡»è¦è¿›è¡Œstripæ“ä½œï¼Œå› ä¸ºä¸Šé¢çš„stripåªèƒ½å»é™¤å¤´å°¾çš„ç©ºæ ¼æˆ–å…¶ä»–å­—ç¬¦åºåˆ—ï¼Œä¸­é—´çš„ä¸èƒ½å»é™¤ï¼Œæ¯”å¦‚:data = 12,è¿™æ ·keyå°±æ˜¯:'data ',æ³¨æ„è¿™é‡Œçš„keyçš„ç»“å°¾æœ‰ä¸€ä¸ªç©ºæ ¼ï¼Œvalueæ˜¯' 12',12åƒç±³ä¹Ÿæœ‰ä¸€ä¸ªç©ºæ ¼ï¼Œæ‰€ä»¥è¦è¿›è¡Œstripæ“ä½œï¼Œstripä¹‹åï¼Œkeyä¸º'data',valueä¸º'12'\n",
    "                    value = value.strip()\n",
    "\n",
    "                    # æ•°æ®ç±»å‹è½¬æ¢\n",
    "                    print('value.isdigit()',value.isdigit())\n",
    "                    if value.lower() == \"true\":\n",
    "                        config[key] = True\n",
    "                    elif value.lower() == \"false\":\n",
    "                        config[key] = False\n",
    "                    else:\n",
    "                        try:\n",
    "                            float_val = float(value)\n",
    "                            print('float_val is:',float_val)\n",
    "                            if float_val.is_integer():\n",
    "                                config[key] = int(value)\n",
    "                            else:\n",
    "                                config[key] = float_val\n",
    "                        except ValueError:\n",
    "                            config[key] = value\n",
    "    except FileNotFoundError:\n",
    "        print(f\"é…ç½®æ–‡ä»¶ {filename} ä¸å­˜åœ¨\")\n",
    "        return {}\n",
    "    except Exception as e:\n",
    "        print(f\"è¯»å–é…ç½®æ–‡ä»¶æ—¶å‡ºé”™: {e}\")\n",
    "        return {}\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "# åˆ›å»ºé…ç½®æ–‡ä»¶\n",
    "config_content = \"\"\"\n",
    "database_host=localhost\n",
    "database_port=5432\n",
    "database_name=myapp\n",
    "debug_mode=True\n",
    "max_connections=100.6\n",
    "\"\"\"\n",
    "\n",
    "with open(\"config.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(config_content)\n",
    "\n",
    "\n",
    "# ç¬¬äºŒæ­¥ï¼šç¼–å†™é…ç½®è§£æå™¨\n",
    "def parse_config(filename):\n",
    "    \"\"\"\n",
    "    è§£æé…ç½®æ–‡ä»¶å¹¶è¿”å›å­—å…¸\n",
    "    æ”¯æŒè‡ªåŠ¨ç±»å‹è½¬æ¢ï¼šæ•´æ•°ã€å¸ƒå°”å€¼ã€å­—ç¬¦ä¸²\n",
    "    \"\"\"\n",
    "    config = {}\n",
    "\n",
    "    # TODO: åœ¨è¿™é‡Œå®ç°é…ç½®æ–‡ä»¶è¯»å–å’Œè§£æé€»è¾‘\n",
    "    config = read_config(\"config.txt\")\n",
    "    print(\"config is:\", config)\n",
    "    # æç¤ºï¼š\n",
    "    # 1. æ‰“å¼€æ–‡ä»¶å¹¶é€è¡Œè¯»å–\n",
    "    # 2. è§£æé”®å€¼å¯¹ï¼ˆkey=valueæ ¼å¼ï¼‰\n",
    "    # 3. è¿›è¡Œç±»å‹è½¬æ¢ï¼ˆintã€boolã€strï¼‰\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "# æµ‹è¯•ä»£ç \n",
    "if __name__ == \"__main__\":\n",
    "    result = parse_config(\"config.txt\")\n",
    "    print(\"è§£æç»“æœï¼š\", result)\n",
    "    print(\"ç±»å‹æ£€æŸ¥ï¼š\")\n",
    "    for key, value in result.items():\n",
    "        print(f\"  {key}: {value} (ç±»å‹: {type(value).__name__})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### å¯¹äºä¸Šè¿°æ ‡å‡†ç­”æ¡ˆçš„ä¸€äº›åœ°æ–¹çš„ç†è§£\n",
    "1. æ•°æ®ç±»å‹è½¬æ¢çš„é€»è¾‘\n",
    "```python\n",
    "# æ•°æ®ç±»å‹è½¬æ¢\n",
    "if value.lower() == \"true\":\n",
    "    config[key] = True\n",
    "elif value.lower() == \"false\":\n",
    "    config[key] = False\n",
    "elif value.isdigit():\n",
    "    config[key] = int(value)\n",
    "else:\n",
    "    config[key] = value\n",
    "```\n",
    "***ä½ å¯èƒ½ä¼šæœ‰ç–‘é—®ï¼šä¸ºä»€ä¹ˆè¦`value.lower()`ï¼Ÿä¸ºä»€ä¹ˆè¦å’Œtrueå’Œfalseåšæ¯”è¾ƒï¼Ÿpythonä¸­ä¸æ˜¯å†™ä½œTrueæˆ–è€…Falseå—ï¼Ÿ***\n",
    "\n",
    "è§£ç­”ï¼šå…¶å®è¿™é‡Œå’Œä»€ä¹ˆTrueå’ŒFalseçš„å†™æ³•æ˜¯æ²¡æœ‰å…³ç³»çš„ã€‚value.lower()æ˜¯åœ¨å°†valueè½¬æ¢æˆå…¨å°å†™ï¼Œçœ‹ä¸€ä¸‹è½¬æ¢æˆå…¨å°å†™åæ˜¯ä¸æ˜¯trueï¼Œè¿™æ ·èƒ½æé«˜é…ç½®çš„çµæ´»æ€§ï¼Œå› ä¸ºæˆ‘ä»¬è¿™é‡Œæ˜¯åœ¨åšæ•°æ®ç±»å‹çš„è½¬æ¢ï¼Œé…ç½®çš„ä»£ç ä¸­å¯èƒ½ä¼šå†™:data = trueï¼Œæˆ–è€…data = Trueï¼Œæç«¯çš„ç”šè‡³å†™æˆdata = tRuEï¼Œæˆ‘ä»¬ç›´æ¥æŠŠ=å³è¾¹çš„valueç»™lower()äº†ä¸€ä¸‹ï¼Œè¿™æ ·ä¸ç®¡ç”¨æˆ·å†™ä»€ä¹ˆå¤§å°å†™æ··åˆçš„å¸ƒå°”å€¼ï¼Œéƒ½èƒ½è¢«è¯†åˆ«æˆå…¨å°å†™çš„å¸ƒå°”å€¼ï¼Œå‡å¦‚è¯†åˆ«åˆ°è¯¥å¸ƒå°”å€¼çš„å…¨å°å†™æ˜¯true,è¯´æ˜å½“å‰è¿™ä¸ªé…ç½®é¡¹å°±æ˜¯å¸ƒå°”ç±»å‹çš„ï¼Œé‚£ä¹ˆconfig[key] = Trueï¼Œä¹Ÿå°±æ˜¯è¯´è§£æå®Œä¹‹åçš„configè¢«èµ‹å€¼ä¸ºTrue,ä¹Ÿå°±æ˜¯:data = Trueã€‚\n",
    "\n",
    "---\n",
    "***ä½ å¯èƒ½åˆä¼šæœ‰ç–‘é—®ï¼šè¿™é‡Œçš„æ•°æ®ç±»å‹è½¬æ¢çš„é€»è¾‘ä¸ºä»€ä¹ˆæ˜¯è¿™æ ·ï¼Ÿ***\n",
    "\n",
    "è§£ç­”ï¼šé‚£æˆ‘æ¥è¯´ä¸‹è¿™ä¸ªè½¬æ¢çš„é€»è¾‘è¿‡ç¨‹ï¼ŒåŸºç¡€æ•°æ®ç±»å‹æœ‰int,str,bool,float\n",
    "\n",
    "å¾ˆæ˜æ˜¾ï¼Œå‰ä¸¤ä¸ªifåˆ¤æ–­æ˜¯ç”¨æ¥åˆ¤æ–­å½“valueä¸ºboolç±»å‹çš„æ—¶å€™ï¼Œå½“valueä¸ºçº¯æ•°å­—çš„æ—¶å€™ï¼Œå°†å®ƒæ”¹ä¸ºintç±»å‹ï¼ˆè¿™é‡Œä¸èƒ½åˆ¤æ–­æµ®ç‚¹ç±»å‹ï¼Œç¨åæ”¹è¿›ï¼‰ï¼Œå½“æ—¢ä¸æ˜¯boolï¼Œåˆä¸æ˜¯æ•°å­—çš„æ—¶å€™ï¼Œå°±ç›´æ¥è¿”å›å®ƒçš„ç±»å‹ã€‚\n",
    "\n",
    "***æ”¹è¿›ï¼šæ–°å¢å¯¹æµ®ç‚¹æ•°çš„åˆ¤å®šï¼Œè®©ç¨‹åºæ›´åŠ å¥å£®***\n",
    "```python\n",
    "# æ•°æ®ç±»å‹è½¬æ¢\n",
    "if value.lower() == \"true\":\n",
    "    config[key] = True\n",
    "elif value.lower() == \"false\":\n",
    "    config[key] = False\n",
    "else:\n",
    "    try:\n",
    "        if float(value).is_integer(): # å¦‚æœæ˜¯ä¸€ä¸ªæ•´æ•°ã€‚å¯¹çš„ï¼Œåˆ¤æ–­æ˜¯å¦æ˜¯æ•´æ•°éœ€è¦å…ˆè½¬æ¢ä¸ºfloatæ‰è¡Œ\n",
    "            config[key] = int(value)\n",
    "        else:\n",
    "            config[key] = float(value)\n",
    "    except ValueError:\n",
    "        config[key] = value\n",
    "```\n",
    "è¿™æ ·å°±å¯ä»¥æ­£ç¡®å¤„ç†æ•´æ•°å’Œæµ®ç‚¹æ•°äº†\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç¬¬äºŒé¢˜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“‹ ç”¨æˆ·å®ç°é—®é¢˜åˆ†æ\n",
    "\n",
    "**æˆ‘çš„å®ç°ä¸­å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š**\n",
    "\n",
    "1. **`analyze_log_levels()`** - `KeyErroråŸå› ï¼šå­—å…¸ä¸­è¿˜æ²¡æœ‰è¯¥keyæ—¶ç¬¬ä¸€æ¬¡è®¿é—®ä¼šæŠ¥é”™`ï¼Œæˆ‘ä¸€ç›´æé”™è¿™ä¸ªï¼Œè¦è°¨è®°â€¼ï¸\n",
    "\n",
    "`å…³äºå­—å…¸çš„ä¸€äº›è¡¥å……ï¼š`\n",
    "\n",
    "åœ¨ Python ä¸­ï¼Œå½“ä½ ç›´æ¥é€šè¿‡ log_dict[key] è®¿é—®æˆ–è®¾ç½®ä¸€ä¸ªä¸å­˜åœ¨çš„é”®æ—¶ï¼Œç¡®å®ä¼šå¼•å‘ KeyError å¼‚å¸¸ã€‚è¿™æ˜¯å› ä¸ºå­—å…¸çš„ `__getitem__` æ–¹æ³•ï¼ˆå³ [] æ“ä½œç¬¦ï¼‰åœ¨è®¾è®¡ä¸Šè¦æ±‚é”®å¿…é¡»å­˜åœ¨ï¼Œå¦åˆ™å°±æŠ›å‡ºå¼‚å¸¸ã€‚\n",
    "\n",
    "è€Œ log_dict.get(key, default) æ–¹æ³•åˆ™ä¸åŒï¼Œå®ƒæ˜¯ä¸“é—¨è®¾è®¡æ¥å¤„ç†é”®å¯èƒ½ä¸å­˜åœ¨çš„æƒ…å†µçš„ã€‚å®ƒçš„å·¥ä½œåŸç†æ˜¯ï¼š\n",
    "- å¦‚æœé”®å­˜åœ¨ï¼Œè¿”å›å¯¹åº”çš„å€¼\n",
    "- å¦‚æœé”®ä¸å­˜åœ¨ï¼Œè¿”å›ä½ æŒ‡å®šçš„é»˜è®¤å€¼ï¼ˆå¦‚æœä¸æŒ‡å®šé»˜è®¤å€¼ï¼Œåˆ™è¿”å› Noneï¼‰\n",
    "\n",
    "æ‰€ä»¥å½“ä½ ä½¿ç”¨ log_dict.get(key, 0) æ—¶ï¼š\n",
    "- å¦‚æœ key å­˜åœ¨ï¼Œè¿”å›å®ƒçš„å€¼\n",
    "- å¦‚æœ key ä¸å­˜åœ¨ï¼Œè¿”å› 0 è€Œä¸ä¼šæŠ¥é”™\n",
    "\n",
    "è¿™å®é™…ä¸Šæ˜¯ä¸¤ç§ä¸åŒçš„è®¿é—®ç­–ç•¥ï¼š\n",
    "\n",
    "- [] æ“ä½œç¬¦ï¼šä¸¥æ ¼è¦æ±‚é”®å¿…é¡»å­˜åœ¨ï¼Œé€‚åˆå½“ä½ ç¡®å®šé”®å­˜åœ¨æ—¶ä½¿ç”¨\n",
    "- .get() æ–¹æ³•ï¼šå®½æ¾è®¿é—®ï¼Œé€‚åˆé”®å¯èƒ½ä¸å­˜åœ¨çš„æƒ…å†µ\n",
    "2. **`get_error_messages()`** - é€»è¾‘é”™è¯¯ï¼šè¿”å›çš„æ˜¯éERRORæ—¥å¿—ï¼Œåº”è¯¥è¿”å›ERRORæ—¥å¿—  \n",
    "3. **`extract_user_ids()`** - è¿”å›åµŒå¥—åˆ—è¡¨ï¼Œåº”è¯¥å±•å¹³ä¸ºç®€å•åˆ—è¡¨\n",
    "4. **`hourly_log_count()`** - å°æ—¶èŒƒå›´é”™è¯¯ï¼šåº”è¯¥æ˜¯0-23ï¼Œä¸æ˜¯1-24\n",
    "5. **`load_logs()`** - split(\" \")ä¸å¤Ÿå¥å£®ï¼Œæ—¥å¿—æ¶ˆæ¯å¯èƒ½æœ‰å¤šä¸ªç©ºæ ¼\n",
    "\n",
    "ä¸‹é¢æ˜¯æ ‡å‡†ç­”æ¡ˆå®ç°ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== æ ‡å‡†ç­”æ¡ˆæµ‹è¯• ===\n",
      "\n",
      "1. æ—¥å¿—çº§åˆ«ç»Ÿè®¡ï¼š\n",
      "   INFO: 3\n",
      "   ERROR: 2\n",
      "   WARNING: 1\n",
      "extract_user_ids,matches: ['123']\n",
      "user_ids: ['123']\n",
      "extract_user_ids,matches: []\n",
      "user_ids: ['123']\n",
      "extract_user_ids,matches: ['123']\n",
      "user_ids: ['123', '123']\n",
      "extract_user_ids,matches: []\n",
      "user_ids: ['123', '123']\n",
      "extract_user_ids,matches: ['456']\n",
      "user_ids: ['123', '123', '456']\n",
      "extract_user_ids,matches: []\n",
      "user_ids: ['123', '123', '456']\n",
      "unique_user_ids: ['123', '456'] set: {'456', '123'}\n",
      "\n",
      "2. ç”¨æˆ·IDåˆ—è¡¨ï¼š ['123', '456']\n",
      "\n",
      "3. é”™è¯¯ä¿¡æ¯ï¼š\n",
      "   2024-01-15 10:31:10 ERROR Database connection failed: timeout\n",
      "   2024-01-15 10:35:30 ERROR Authentication failed: invalid_token\n",
      "\n",
      "4. æ¯å°æ—¶æ—¥å¿—æ•°é‡ï¼š\n",
      "   10ç‚¹: 6æ¡\n",
      "\n",
      "============================================================\n",
      "==================================================\n",
      "ğŸ“Š æ—¥å¿—åˆ†ææŠ¥å‘Š\n",
      "==================================================\n",
      "ğŸ“ æ—¥å¿—æ–‡ä»¶ï¼šaccess_standard.log\n",
      "ğŸ“ æ€»æ—¥å¿—æ¡æ•°ï¼š6\n",
      "\n",
      "ğŸ“ˆ æ—¥å¿—çº§åˆ«ç»Ÿè®¡ï¼š\n",
      "dict_items([('INFO', 3), ('ERROR', 2), ('WARNING', 1)])\n",
      "   ERROR: 2 æ¡\n",
      "   INFO: 3 æ¡\n",
      "   WARNING: 1 æ¡\n",
      "extract_user_ids,matches: ['123']\n",
      "user_ids: ['123']\n",
      "extract_user_ids,matches: []\n",
      "user_ids: ['123']\n",
      "extract_user_ids,matches: ['123']\n",
      "user_ids: ['123', '123']\n",
      "extract_user_ids,matches: []\n",
      "user_ids: ['123', '123']\n",
      "extract_user_ids,matches: ['456']\n",
      "user_ids: ['123', '123', '456']\n",
      "extract_user_ids,matches: []\n",
      "user_ids: ['123', '123', '456']\n",
      "unique_user_ids: ['123', '456'] set: {'456', '123'}\n",
      "\n",
      "ğŸ‘¥ æ´»è·ƒç”¨æˆ·ï¼š2 ä¸ª\n",
      "   ç”¨æˆ·ID: 123, 456\n",
      "\n",
      "âŒ é”™è¯¯æ—¥å¿—ï¼š2 æ¡\n",
      "   2024-01-15 10:31:10 ERROR Database connection failed: timeout\n",
      "   2024-01-15 10:35:30 ERROR Authentication failed: invalid_token\n",
      "hourly: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 6, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0, 23: 0}\n",
      "\n",
      "â° æ´»è·ƒæ—¶æ®µï¼š\n",
      "   10:00 - 6 æ¡æ—¥å¿—\n"
     ]
    }
   ],
   "source": [
    "# é¢˜ç›®2ï¼šæ—¥å¿—æ–‡ä»¶åˆ†æå™¨ - æ ‡å‡†ç­”æ¡ˆç‰ˆæœ¬\n",
    "\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "from datetime import datetime\n",
    "\n",
    "# é‡æ–°åˆ›å»ºæ—¥å¿—æ–‡ä»¶ï¼ˆç¡®ä¿æ•°æ®ä¸€è‡´ï¼‰\n",
    "log_data_standard = \"\"\"\n",
    "2024-01-15 10:30:25 INFO User login successful: user_id=123\n",
    "2024-01-15 10:31:10 ERROR Database connection failed: timeout\n",
    "2024-01-15 10:32:15 INFO User logout: user_id=123\n",
    "2024-01-15 10:33:20 WARNING High memory usage: 85%\n",
    "2024-01-15 10:34:05 INFO User login successful: user_id=456\n",
    "2024-01-15 10:35:30 ERROR Authentication failed: invalid_token\n",
    "\"\"\"\n",
    "\n",
    "with open(\"access_standard.log\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(log_data_standard)\n",
    "\n",
    "\n",
    "class LogAnalyzerStandard:\n",
    "    \"\"\"æ ‡å‡†ç‰ˆæ—¥å¿—åˆ†æå™¨ç±»\"\"\"\n",
    "\n",
    "    def __init__(self, log_file):\n",
    "        self.log_file = log_file\n",
    "        self.logs = []\n",
    "        self.load_logs()\n",
    "\n",
    "    def load_logs(self):\n",
    "        \"\"\"åŠ è½½æ—¥å¿—æ–‡ä»¶ - æ ‡å‡†å®ç°\"\"\"\n",
    "        try:\n",
    "            with open(self.log_file, \"r\", encoding=\"utf-8\") as f:\n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    if line:  # è·³è¿‡ç©ºè¡Œ\n",
    "                        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åˆ†å‰²ï¼Œæ›´å¥å£®\n",
    "                        # æ ¼å¼ï¼šæ—¥æœŸ æ—¶é—´ çº§åˆ« æ¶ˆæ¯\n",
    "                        parts = line.split(\n",
    "                            \" \", 3\n",
    "                        )  # æœ€å¤šåˆ†å‰²3æ¬¡ï¼Œä¿æŒæ¶ˆæ¯å®Œæ•´ï¼Œå¾—åˆ°è¯¸å¦‚ï¼š['2024-01-15', '10:30:25', 'INFO', 'User login successful: user_id=123']ï¼Œæœ€åçš„User login xxx: user_id=xxxæ˜¯ä¸€ç»„çš„\n",
    "                        # print('parts:',parts)\n",
    "                        if len(parts) >= 4:\n",
    "                            self.logs.append(parts)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {self.log_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"è¯»å–æ–‡ä»¶æ—¶å‡ºé”™ï¼š{e}\")\n",
    "\n",
    "    def analyze_log_levels(self):\n",
    "        \"\"\"ç»Ÿè®¡ä¸åŒæ—¥å¿—çº§åˆ«çš„æ•°é‡ - æ ‡å‡†å®ç°\"\"\"\n",
    "        # æ–¹æ³•1ï¼šä½¿ç”¨å­—å…¸getæ–¹æ³•\n",
    "        log_levels = {}\n",
    "        # for log in self.logs:\n",
    "        #     print('log:',log)\n",
    "        #     if len(log) >= 3:\n",
    "        #         level = log[2]\n",
    "        #         log_levels[level] = log_levels.get(level, 0) + 1\n",
    "\n",
    "        # æ–¹æ³•2ï¼šä½¿ç”¨Counterï¼ˆæ›´ç®€æ´ï¼‰ï¼ŒCounterçš„æ‹¬å·ä¸­æ˜¯ä¸€ä¸ªç”Ÿæˆå™¨è¡¨è¾¾å¼\n",
    "        \"\"\"\n",
    "        ä¸ºä»€ä¹ˆCounteræ‹¬å·ä¸­æ˜¯ä¸€ä¸ªç”Ÿæˆå™¨è¡¨è¾¾å¼ï¼Ÿå¹¶æ²¡æœ‰å‡ºç°yieldå•Šï¼Ÿ\n",
    "        ç”Ÿæˆå™¨è¡¨è¾¾å¼ï¼ˆGenerator Expressionï¼‰æ˜¯Pythonä¸­çš„ä¸€ç§è¯­æ³•ç³–ï¼Œå®ƒä¸éœ€è¦æ˜¾å¼ä½¿ç”¨yieldå…³é”®å­—ã€‚å®ƒçš„è¯­æ³•ç±»ä¼¼äºåˆ—è¡¨æ¨å¯¼å¼ï¼Œä½†ä½¿ç”¨åœ†æ‹¬å·è€Œä¸æ˜¯æ–¹æ‹¬å·ã€‚\n",
    "        åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼š\n",
    "        Counter(log[2] for log in self.logs if len(log) >= 3)\n",
    "        (log[2] for log in self.logs if len(log) >= 3)å°±æ˜¯ä¸€ä¸ªç”Ÿæˆå™¨è¡¨è¾¾å¼ï¼Œå®ƒä¼šæŒ‰éœ€ç”Ÿæˆå€¼ï¼Œè€Œä¸æ˜¯ä¸€æ¬¡æ€§åˆ›å»ºæ•´ä¸ªåˆ—è¡¨ã€‚è¿™æ¯”ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼æ›´èŠ‚çœå†…å­˜ï¼Œç‰¹åˆ«æ˜¯å½“å¤„ç†å¤§é‡æ•°æ®æ—¶ã€‚\n",
    "        ç”Ÿæˆå™¨è¡¨è¾¾å¼å’Œyieldçš„åŒºåˆ«åœ¨äºï¼š\n",
    "        - yieldç”¨äºå®šä¹‰ç”Ÿæˆå™¨å‡½æ•° \n",
    "        - ç”Ÿæˆå™¨è¡¨è¾¾å¼æ˜¯ä¸€ç§æ›´ç®€æ´çš„è¯­æ³•ï¼Œç”¨äºåˆ›å»ºç®€å•çš„ç”Ÿæˆå™¨\n",
    "        ä¸¤è€…éƒ½èƒ½å®ç°æƒ°æ€§è®¡ç®—ï¼Œä½†ç”Ÿæˆå™¨è¡¨è¾¾å¼æ›´é€‚ç”¨äºç®€å•çš„åœºæ™¯ã€‚\n",
    "        \"\"\"\n",
    "        # log_levels = Counter(log[2] for log in self.logs if len(log) >= 3)\n",
    "        # print(\"ä½¿ç”¨äº†counterçš„log_levels:\", log_levels)\n",
    "\n",
    "        # æ–¹æ³•3ï¼šä½¿ç”¨defaultdict\n",
    "        log_levels = defaultdict(int)\n",
    "        for log in self.logs:\n",
    "            if len(log) >= 3:\n",
    "                log_levels[log[2]] += 1\n",
    "\n",
    "        return dict(log_levels)\n",
    "\n",
    "    def extract_user_ids(self):\n",
    "        \"\"\"æå–æ‰€æœ‰ç”¨æˆ·ID - æ ‡å‡†å®ç°\"\"\"\n",
    "        user_ids = []\n",
    "        pattern = r\"user_id=(\\d+)\"  # ä½¿ç”¨æ•è·ç»„ç›´æ¥æå–æ•°å­—,âš ï¸æå–çš„æ˜¯()å†…çš„å†…å®¹ï¼Œä¼šå¾—åˆ°å°æ‹¬å·å†…çš„éƒ¨åˆ†ï¼Œuser_id=123 - > å¾—åˆ°ï¼š123ã€‚æˆ‘çš„ç­”æ¡ˆæ˜¯ï¼šr\"user_id=[\\d]+\"ï¼Œæ²¡æœ‰åˆ†ç»„æ•è·ï¼Œæ— æ³•å•ç‹¬æå–æ•°å­—éƒ¨åˆ†ï¼ˆå› ä¸ºæ²¡æœ‰æ‹¬å·ï¼‰ï¼Œä¼šå¾—åˆ°æ•´ä¸ªåŒ¹é…æ–‡æœ¬ï¼Œæ¯”å¦‚user_id=123\n",
    "\n",
    "        for log in self.logs:\n",
    "            if len(log) >= 4:\n",
    "                message = log[3]\n",
    "                matches = re.findall(pattern, message)\n",
    "                print(\"extract_user_ids,matches:\", matches)\n",
    "                user_ids.extend(matches)  # ç›´æ¥æ‰©å±•ï¼Œé¿å…åµŒå¥—åˆ—è¡¨\n",
    "                print(\"user_ids:\", user_ids)\n",
    "        \"\"\"\n",
    "        è¿™é‡Œè®¾ç½®ä¸€ä¸ªåä¸ºseençš„setåªæ˜¯ç”¨æ¥æ£€æŸ¥æ˜¯å¦é‡å¤ï¼Œè¿”å›çš„æ—¶å€™ï¼Œç›´æ¥è¿”å›è¿™ä¸ªsetä¸å°±å¯ä»¥äº†å—ï¼Ÿä¸ºä»€ä¹ˆè¿˜è¦å®šä¹‰ä¸€ä¸ªåˆ—è¡¨unique_user_idså¹¶è¿”å›å®ƒï¼Ÿ\n",
    "        ä½¿ç”¨åˆ—è¡¨è€Œä¸ç›´æ¥è¿”å›seené›†åˆæœ‰ä¸¤ä¸ªåŸå› ï¼š\n",
    "        1. ä¿æŒé¡ºåº - é›†åˆï¼ˆsetï¼‰æ˜¯æ— åºçš„ï¼Œè€Œåˆ—è¡¨ä¿æŒäº†ç”¨æˆ·IDé¦–æ¬¡å‡ºç°çš„é¡ºåº\n",
    "        2. ä¿æŒä¸€è‡´æ€§ - å‡½æ•°è¿”å›å€¼ç±»å‹åº”è¯¥æ˜¯å¯é¢„æµ‹çš„ï¼Œè¿™é‡Œç»Ÿä¸€è¿”å›åˆ—è¡¨æ›´ç¬¦åˆæ¥å£è®¾è®¡åŸåˆ™\n",
    "        æ‰€ä»¥è¿™é‡Œç”¨setåªæ˜¯ä¸ºäº†O(1)æ—¶é—´å¤æ‚åº¦çš„æŸ¥é‡ï¼Œè€Œè¿”å›åˆ—è¡¨æ˜¯ä¸ºäº†ç»´æŠ¤é¡ºåºå’Œä¸€è‡´æ€§ã€‚\n",
    "        \"\"\"\n",
    "        # å»é‡å¹¶ä¿æŒé¡ºåº\n",
    "        seen = set()\n",
    "        unique_user_ids = []\n",
    "        for uid in user_ids:\n",
    "            if uid not in seen:\n",
    "                seen.add(uid)\n",
    "                unique_user_ids.append(uid)\n",
    "        print(\"unique_user_ids:\", unique_user_ids, \"set:\", seen)\n",
    "        return unique_user_ids\n",
    "\n",
    "    def get_error_messages(self):\n",
    "        \"\"\"æ‰¾å‡ºæ‰€æœ‰é”™è¯¯ä¿¡æ¯ - æ ‡å‡†å®ç°\"\"\"\n",
    "        error_messages = []\n",
    "\n",
    "        for log in self.logs:\n",
    "            if len(log) >= 3 and log[2] == \"ERROR\":  # æ­£ç¡®çš„æ¡ä»¶\n",
    "                # é‡æ„å®Œæ•´çš„æ—¥å¿—æ¶ˆæ¯\n",
    "                full_message = \" \".join(log)\n",
    "                error_messages.append(full_message)\n",
    "\n",
    "        return error_messages\n",
    "\n",
    "    def hourly_log_count(self):\n",
    "        \"\"\"ç»Ÿè®¡æ¯å°æ—¶çš„æ—¥å¿—æ¡æ•° - æ ‡å‡†å®ç°\"\"\"\n",
    "        hourly_count = defaultdict(int)\n",
    "\n",
    "        for log in self.logs:\n",
    "            if len(log) >= 2:\n",
    "                try:\n",
    "                    # è§£ææ—¶é—´æˆ³\n",
    "                    timestamp_str = f\"{log[0]} {log[1]}\"\n",
    "                    dt = datetime.strptime(timestamp_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "                    hour = dt.hour  # 0-23\n",
    "                    hourly_count[hour] += 1\n",
    "                except ValueError as e:\n",
    "                    print(f\"æ—¶é—´è§£æé”™è¯¯ï¼š{e}\")\n",
    "\n",
    "        # è½¬æ¢ä¸ºæ ‡å‡†å­—å…¸å¹¶è¡¥å……0è®¡æ•°çš„å°æ—¶\n",
    "        result = {}\n",
    "        for hour in range(24):  # 0-23å°æ—¶\n",
    "            result[hour] = hourly_count[hour]\n",
    "\n",
    "        return result\n",
    "\n",
    "    def generate_report(self):\n",
    "        \"\"\"ç”Ÿæˆå®Œæ•´çš„åˆ†ææŠ¥å‘Š\"\"\"\n",
    "        print(\"=\" * 50)\n",
    "        print(\"ğŸ“Š æ—¥å¿—åˆ†ææŠ¥å‘Š\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        # åŸºæœ¬ä¿¡æ¯\n",
    "        print(f\"ğŸ“ æ—¥å¿—æ–‡ä»¶ï¼š{self.log_file}\")\n",
    "        print(f\"ğŸ“ æ€»æ—¥å¿—æ¡æ•°ï¼š{len(self.logs)}\")\n",
    "\n",
    "        # æ—¥å¿—çº§åˆ«ç»Ÿè®¡\n",
    "        levels = self.analyze_log_levels()\n",
    "        print(f\"\\nğŸ“ˆ æ—¥å¿—çº§åˆ«ç»Ÿè®¡ï¼š\")\n",
    "        print((levels.items()))\n",
    "        for level, count in sorted(levels.items()):\n",
    "            print(f\"   {level}: {count} æ¡\")\n",
    "\n",
    "        # ç”¨æˆ·æ´»åŠ¨\n",
    "        user_ids = self.extract_user_ids()\n",
    "        print(f\"\\nğŸ‘¥ æ´»è·ƒç”¨æˆ·ï¼š{len(user_ids)} ä¸ª\")\n",
    "        print(f\"   ç”¨æˆ·ID: {', '.join(user_ids)}\")\n",
    "\n",
    "        # é”™è¯¯ä¿¡æ¯\n",
    "        errors = self.get_error_messages()\n",
    "        print(f\"\\nâŒ é”™è¯¯æ—¥å¿—ï¼š{len(errors)} æ¡\")\n",
    "        for error in errors:\n",
    "            print(f\"   {error}\")\n",
    "\n",
    "        # æ—¶é—´åˆ†å¸ƒ\n",
    "        hourly = self.hourly_log_count()\n",
    "        print('hourly:',hourly)\n",
    "        active_hours = [(hour, count) for hour, count in hourly.items() if count > 0]\n",
    "        print(f\"\\nâ° æ´»è·ƒæ—¶æ®µï¼š\")\n",
    "        for hour, count in sorted(active_hours):\n",
    "            print(f\"   {hour:02d}:00 - {count} æ¡æ—¥å¿—\")\n",
    "\n",
    "\n",
    "# æµ‹è¯•æ ‡å‡†å®ç°\n",
    "print(\"=== æ ‡å‡†ç­”æ¡ˆæµ‹è¯• ===\")\n",
    "analyzer_std = LogAnalyzerStandard(\"access_standard.log\")\n",
    "\n",
    "print(\"\\n1. æ—¥å¿—çº§åˆ«ç»Ÿè®¡ï¼š\")\n",
    "levels = analyzer_std.analyze_log_levels()\n",
    "for level, count in levels.items():\n",
    "    print(f\"   {level}: {count}\")\n",
    "\n",
    "print(\"\\n2. ç”¨æˆ·IDåˆ—è¡¨ï¼š\", analyzer_std.extract_user_ids())\n",
    "\n",
    "print(\"\\n3. é”™è¯¯ä¿¡æ¯ï¼š\")\n",
    "errors = analyzer_std.get_error_messages()\n",
    "for error in errors:\n",
    "    print(f\"   {error}\")\n",
    "\n",
    "print(\"\\n4. æ¯å°æ—¶æ—¥å¿—æ•°é‡ï¼š\")\n",
    "hourly = analyzer_std.hourly_log_count()\n",
    "for hour, count in hourly.items():\n",
    "    if count > 0:  # åªæ˜¾ç¤ºæœ‰æ—¥å¿—çš„å°æ—¶\n",
    "        print(f\"   {hour:02d}ç‚¹: {count}æ¡\")\n",
    "\n",
    "# ç”Ÿæˆå®Œæ•´æŠ¥å‘Š\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "analyzer_std.generate_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ” å¯¹æ¯”æ€»ç»“\n",
    "\n",
    "| åŠŸèƒ½ | ä½ çš„å®ç° | æ ‡å‡†å®ç° | ä¸»è¦åŒºåˆ« |\n",
    "|------|----------|----------|----------|\n",
    "| **load_logs()** | `split(\" \")` | `split(\" \", 3)` | æ ‡å‡†ç‰ˆé™åˆ¶åˆ†å‰²æ¬¡æ•°ï¼Œä¿æŒæ¶ˆæ¯å®Œæ•´ |\n",
    "| **analyze_log_levels()** | try-exceptå¤„ç†KeyError | `dict.get(key, 0)` | æ ‡å‡†ç‰ˆæ›´ç®€æ´ï¼Œé¿å…å¼‚å¸¸ |\n",
    "| **extract_user_ids()** | è¿”å›åµŒå¥—åˆ—è¡¨ | ä½¿ç”¨æ•è·ç»„+extend | æ ‡å‡†ç‰ˆç›´æ¥æå–æ•°å­—ï¼Œå»é‡ |\n",
    "| **get_error_messages()** | âŒ `!= \"ERROR\"` | âœ… `== \"ERROR\"` | ä½ çš„é€»è¾‘ç›¸åäº† |\n",
    "| **hourly_log_count()** | å°æ—¶1-24 | å°æ—¶0-23 | æ ‡å‡†ç‰ˆç¬¦åˆå®é™…æ—¶é—´æ ¼å¼ |\n",
    "\n",
    "### ğŸ’¡ å­¦ä¹ è¦ç‚¹\n",
    "\n",
    "1. **å­—å…¸æ“ä½œ**ï¼šä½¿ç”¨ `dict.get(key, default)` æ¯” try-except æ›´ç®€æ´\n",
    "2. **æ­£åˆ™è¡¨è¾¾å¼**ï¼šä½¿ç”¨æ•è·ç»„ `(\\d+)` ç›´æ¥æå–éœ€è¦çš„éƒ¨åˆ†\n",
    "3. **åˆ—è¡¨æ“ä½œ**ï¼šä½¿ç”¨ `extend()` è€Œä¸æ˜¯ `append()` æ¥å±•å¹³åˆ—è¡¨\n",
    "4. **é€»è¾‘æ¡ä»¶**ï¼šä»”ç»†ç†è§£éœ€æ±‚ï¼Œé¿å…æ¡ä»¶å†™å\n",
    "5. **æ—¶é—´å¤„ç†**ï¼šæ³¨æ„å°æ—¶æ˜¯0-23ï¼Œä¸æ˜¯1-24\n",
    "6. **é”™è¯¯å¤„ç†**ï¼šæ·»åŠ é€‚å½“çš„å¼‚å¸¸å¤„ç†ï¼Œæé«˜ä»£ç å¥å£®æ€§\n",
    "\n",
    "### ğŸ§ å…³äºæ ‡å‡†ç­”æ¡ˆä¸­æ¨¡å—çš„ä½¿ç”¨\n",
    "1. `Counter`: [ç‚¹å‡»æŸ¥çœ‹](../çŸ¥è¯†ç‚¹/pythonæ¨¡å—/collections/Counter.ipynb)\n",
    "\n",
    "### ğŸ§ å…³äºä¸€äº›ä¸ç†Ÿæ‚‰çš„ç”¨æ³•\n",
    "1. `åˆ†ç»„æ•è·`: [ç‚¹å‡»æŸ¥çœ‹](../çŸ¥è¯†ç‚¹/æ­£åˆ™è¡¨è¾¾å¼/å…³äºåˆ†ç»„æ•è·.ipynb)\n",
    "2. `extend`å‡½æ•°: [ç‚¹å‡»æŸ¥çœ‹](../çŸ¥è¯†ç‚¹/å‡½æ•°/pythonå†…ç½®å‡½æ•°/å…³äºextendå‡½æ•°.ipynb)\n",
    "3. `sorted`å‡½æ•°: [ç‚¹å‡»æŸ¥çœ‹](../çŸ¥è¯†ç‚¹/å‡½æ•°/pythonå†…ç½®å‡½æ•°/å…³äºsortedå‡½æ•°çš„ç”¨æ³•.ipynb)\n",
    "\n",
    "ä½ çš„åŸºæœ¬æ€è·¯æ˜¯æ­£ç¡®çš„ï¼Œåªæ˜¯åœ¨ä¸€äº›ç»†èŠ‚ä¸Šéœ€è¦è°ƒæ•´ï¼ ğŸ¯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç¬¬ä¸‰é¢˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.employees: [{'å§“å': 'å¼ ä¸‰', 'éƒ¨é—¨': 'æŠ€æœ¯éƒ¨', 'å·¥èµ„': 8000, 'å…¥èŒæ—¥æœŸ': datetime.datetime(2023, 1, 15, 0, 0)}, {'å§“å': 'æå››', 'éƒ¨é—¨': 'é”€å”®éƒ¨', 'å·¥èµ„': 6000, 'å…¥èŒæ—¥æœŸ': datetime.datetime(2023, 2, 20, 0, 0)}, {'å§“å': 'ç‹äº”', 'éƒ¨é—¨': 'æŠ€æœ¯éƒ¨', 'å·¥èµ„': 9000, 'å…¥èŒæ—¥æœŸ': datetime.datetime(2022, 12, 10, 0, 0)}, {'å§“å': 'èµµå…­', 'éƒ¨é—¨': 'äººäº‹éƒ¨', 'å·¥èµ„': 7000, 'å…¥èŒæ—¥æœŸ': datetime.datetime(2023, 3, 5, 0, 0)}, {'å§“å': 'é’±ä¸ƒ', 'éƒ¨é—¨': 'æŠ€æœ¯éƒ¨', 'å·¥èµ„': 8500, 'å…¥èŒæ—¥æœŸ': datetime.datetime(2023, 1, 25, 0, 0)}]\n",
      "=== å‘˜å·¥æ•°æ®åˆ†æ ===\n",
      "1. å‘˜å·¥æ•°æ®ï¼š\n",
      "   å¼ ä¸‰ - æŠ€æœ¯éƒ¨ - 8000å…ƒ - 2023-01-15\n",
      "   æå›› - é”€å”®éƒ¨ - 6000å…ƒ - 2023-02-20\n",
      "   ç‹äº” - æŠ€æœ¯éƒ¨ - 9000å…ƒ - 2022-12-10\n",
      "   èµµå…­ - äººäº‹éƒ¨ - 7000å…ƒ - 2023-03-05\n",
      "   é’±ä¸ƒ - æŠ€æœ¯éƒ¨ - 8500å…ƒ - 2023-01-25\n",
      "\n",
      "2. éƒ¨é—¨å¹³å‡å·¥èµ„ï¼š\n",
      "   æŠ€æœ¯éƒ¨: 8500.0å…ƒ\n",
      "   é”€å”®éƒ¨: 6000.0å…ƒ\n",
      "   äººäº‹éƒ¨: 7000.0å…ƒ\n",
      "\n",
      "3. å·¥èµ„æå€¼ï¼š\n",
      "   æœ€é«˜å·¥èµ„: ç‹äº” (æŠ€æœ¯éƒ¨) - 9000å…ƒ\n",
      "   æœ€ä½å·¥èµ„: æå›› (é”€å”®éƒ¨) - 6000å…ƒ\n",
      "\n",
      "4. æŒ‰å…¥èŒæ—¥æœŸæ’åºï¼š\n",
      "sorted_employees:  [{'å§“å': 'ç‹äº”', 'éƒ¨é—¨': 'æŠ€æœ¯éƒ¨', 'å·¥èµ„': 9000, 'å…¥èŒæ—¥æœŸ': datetime.datetime(2022, 12, 10, 0, 0)}, {'å§“å': 'å¼ ä¸‰', 'éƒ¨é—¨': 'æŠ€æœ¯éƒ¨', 'å·¥èµ„': 8000, 'å…¥èŒæ—¥æœŸ': datetime.datetime(2023, 1, 15, 0, 0)}, {'å§“å': 'é’±ä¸ƒ', 'éƒ¨é—¨': 'æŠ€æœ¯éƒ¨', 'å·¥èµ„': 8500, 'å…¥èŒæ—¥æœŸ': datetime.datetime(2023, 1, 25, 0, 0)}, {'å§“å': 'æå››', 'éƒ¨é—¨': 'é”€å”®éƒ¨', 'å·¥èµ„': 6000, 'å…¥èŒæ—¥æœŸ': datetime.datetime(2023, 2, 20, 0, 0)}, {'å§“å': 'èµµå…­', 'éƒ¨é—¨': 'äººäº‹éƒ¨', 'å·¥èµ„': 7000, 'å…¥èŒæ—¥æœŸ': datetime.datetime(2023, 3, 5, 0, 0)}]\n",
      "   ç‹äº” - 2022-12-10 (æŠ€æœ¯éƒ¨)\n",
      "   å¼ ä¸‰ - 2023-01-15 (æŠ€æœ¯éƒ¨)\n",
      "   é’±ä¸ƒ - 2023-01-25 (æŠ€æœ¯éƒ¨)\n",
      "   æå›› - 2023-02-20 (é”€å”®éƒ¨)\n",
      "   èµµå…­ - 2023-03-05 (äººäº‹éƒ¨)\n",
      "æ•°æ®å·²ä¿å­˜åˆ° éƒ¨é—¨å¹³å‡å·¥èµ„.csv\n",
      "æ•°æ®å·²ä¿å­˜åˆ° å‘˜å·¥æŒ‰å…¥èŒæ—¥æœŸæ’åº.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "# åˆ›å»ºç¤ºä¾‹CSVæ–‡ä»¶\n",
    "csv_data = \"\"\"\n",
    "å§“å,éƒ¨é—¨,å·¥èµ„,å…¥èŒæ—¥æœŸ\n",
    "å¼ ä¸‰,æŠ€æœ¯éƒ¨,8000,2023-01-15\n",
    "æå››,é”€å”®éƒ¨,6000,2023-02-20\n",
    "ç‹äº”,æŠ€æœ¯éƒ¨,9000,2022-12-10\n",
    "èµµå…­,äººäº‹éƒ¨,7000,2023-03-05\n",
    "é’±ä¸ƒ,æŠ€æœ¯éƒ¨,8500,2023-01-25\n",
    "\"\"\"\n",
    "\n",
    "with open(\"employees.csv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(csv_data.strip())\n",
    "\n",
    "\n",
    "class EmployeeDataProcessor:\n",
    "    \"\"\"å‘˜å·¥æ•°æ®å¤„ç†å™¨\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file):\n",
    "        self.csv_file = csv_file\n",
    "        self.employees = []\n",
    "        self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"è¯»å–CSVæ–‡ä»¶å¹¶è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨\"\"\"\n",
    "        try:\n",
    "            with open(self.csv_file, \"r\", encoding=\"utf-8\") as file:\n",
    "                reader = csv.DictReader(file)\n",
    "                self.employees = list(reader)\n",
    "                # æ•°æ®ç±»å‹è½¬æ¢\n",
    "                for employee in self.employees:\n",
    "                    employee[\"å·¥èµ„\"] = int(employee[\"å·¥èµ„\"])\n",
    "                    employee[\"å…¥èŒæ—¥æœŸ\"] = datetime.strptime(\n",
    "                        employee[\"å…¥èŒæ—¥æœŸ\"], \"%Y-%m-%d\"\n",
    "                    )\n",
    "                print('self.employees:',self.employees)\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"æ–‡ä»¶æœªæ‰¾åˆ°: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {e}\")\n",
    "\n",
    "    def calculate_department_avg_salary(self):\n",
    "        \"\"\"è®¡ç®—å„éƒ¨é—¨çš„å¹³å‡å·¥èµ„\"\"\"\n",
    "        if not self.employees:\n",
    "            return {}\n",
    "\n",
    "        dept_salaries = defaultdict(list) # è¿™ä¸€æ­¥æˆ‘å…¶å®æƒ³åˆ°äº†ï¼Œé”®æ˜¯å­—ç¬¦ä¸²ï¼Œå€¼æ˜¯åˆ—è¡¨ï¼Œä½†æ˜¯åé¢æ²¡å†™å‡ºæ¥\n",
    "\n",
    "        # æŒ‰éƒ¨é—¨åˆ†ç»„æ”¶é›†å·¥èµ„\n",
    "        for employee in self.employees:\n",
    "            dept = employee[\"éƒ¨é—¨\"]\n",
    "            salary = employee[\"å·¥èµ„\"]\n",
    "            dept_salaries[dept].append(salary) # æœ€å…³é”®â€¼ï¸çš„å…¶å®æ˜¯è¿™ä¸€æ­¥ï¼Œæˆ‘å½“æ—¶å°±æ˜¯ä¸çŸ¥é“æ€ä¹ˆæŠŠå·¥èµ„åŠ å…¥åˆ°defaultdictçš„åé¢çš„åˆ—è¡¨é‡Œï¼Œå¯¼è‡´å¡ä½\n",
    "\n",
    "        # è®¡ç®—å¹³å‡å·¥èµ„\n",
    "        avg_salaries = {}\n",
    "        for dept, salaries in dept_salaries.items():\n",
    "            avg_salaries[dept] = round(sum(salaries) / len(salaries), 2)\n",
    "\n",
    "        return avg_salaries\n",
    "\n",
    "    def find_salary_extremes(self):\n",
    "        \"\"\"æ‰¾å‡ºå·¥èµ„æœ€é«˜å’Œæœ€ä½çš„å‘˜å·¥\"\"\"\n",
    "        if not self.employees:\n",
    "            return {\"æœ€é«˜\": None, \"æœ€ä½\": None}\n",
    "\n",
    "        max_employee = max(self.employees, key=lambda x: x[\"å·¥èµ„\"])\n",
    "        min_employee = min(self.employees, key=lambda x: x[\"å·¥èµ„\"])\n",
    "\n",
    "        return {\n",
    "            \"æœ€é«˜\": {\n",
    "                \"å§“å\": max_employee[\"å§“å\"],\n",
    "                \"éƒ¨é—¨\": max_employee[\"éƒ¨é—¨\"],\n",
    "                \"å·¥èµ„\": max_employee[\"å·¥èµ„\"],\n",
    "            },\n",
    "            \"æœ€ä½\": {\n",
    "                \"å§“å\": min_employee[\"å§“å\"],\n",
    "                \"éƒ¨é—¨\": min_employee[\"éƒ¨é—¨\"],\n",
    "                \"å·¥èµ„\": min_employee[\"å·¥èµ„\"],\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def sort_by_join_date(self):\n",
    "        \"\"\"æŒ‰å…¥èŒæ—¥æœŸæ’åº\"\"\"\n",
    "        if not self.employees:\n",
    "            return []\n",
    "\n",
    "        sorted_employees = sorted(self.employees, key=lambda x: x[\"å…¥èŒæ—¥æœŸ\"])\n",
    "        print('sorted_employees: ',sorted_employees)\n",
    "        # è½¬æ¢å›å­—ç¬¦ä¸²æ ¼å¼ä¾¿äºæ˜¾ç¤º\n",
    "        result = []\n",
    "        for emp in sorted_employees:\n",
    "            \"\"\"\n",
    "            ä¸ºä»€ä¹ˆè¿™é‡Œè¦æµ…æ‹·è´ï¼Ÿ\n",
    "            å› ä¸ºæˆ‘ä»¬è¦ä¿®æ”¹å…¥èŒæ—¥æœŸçš„æ ¼å¼ã€‚å¦‚æœä¸æ‹·è´ç›´æ¥ä¿®æ”¹åŸå¯¹è±¡ï¼Œä¼šå½±å“åŸå§‹æ•°æ®ã€‚\n",
    "            æµ…æ‹·è´åœ¨è¿™é‡Œè¶³å¤Ÿç”¨ï¼Œå› ä¸ºæˆ‘ä»¬åªä¿®æ”¹ç¬¬ä¸€å±‚çš„æ—¥æœŸå€¼ã€‚\n",
    "            \"\"\"\n",
    "            emp_copy = emp.copy()\n",
    "            emp_copy[\"å…¥èŒæ—¥æœŸ\"] = emp[\"å…¥èŒæ—¥æœŸ\"].strftime(\"%Y-%m-%d\")\n",
    "            result.append(emp_copy)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def save_results(self, filename, data):\n",
    "        \"\"\"å°†ç»“æœä¿å­˜åˆ°æ–°çš„CSVæ–‡ä»¶\"\"\"\n",
    "        if not data:\n",
    "            print(\"æ²¡æœ‰æ•°æ®éœ€è¦ä¿å­˜\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "                if isinstance(data, list) and data:\n",
    "                    # ä¿å­˜å‘˜å·¥åˆ—è¡¨æ•°æ®\n",
    "                    fieldnames = data[0].keys()\n",
    "                    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "                    writer.writeheader()\n",
    "                    writer.writerows(data)\n",
    "                elif isinstance(data, dict):\n",
    "                    # ä¿å­˜ç»Ÿè®¡æ•°æ®ï¼ˆå¦‚éƒ¨é—¨å¹³å‡å·¥èµ„ï¼‰\n",
    "                    writer = csv.writer(file)\n",
    "                    writer.writerow([\"éƒ¨é—¨\", \"å¹³å‡å·¥èµ„\"])\n",
    "                    for dept, salary in data.items():\n",
    "                        writer.writerow([dept, salary])\n",
    "\n",
    "                print(f\"æ•°æ®å·²ä¿å­˜åˆ° {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {e}\")\n",
    "\n",
    "\n",
    "# æµ‹è¯•ä»£ç \n",
    "processor = EmployeeDataProcessor(\"employees.csv\")\n",
    "print(\"=== å‘˜å·¥æ•°æ®åˆ†æ ===\")\n",
    "print(\"1. å‘˜å·¥æ•°æ®ï¼š\")\n",
    "for emp in processor.employees:\n",
    "    print(\n",
    "        f\"   {emp['å§“å']} - {emp['éƒ¨é—¨']} - {emp['å·¥èµ„']}å…ƒ - {emp['å…¥èŒæ—¥æœŸ'].strftime('%Y-%m-%d')}\"\n",
    "    )\n",
    "\n",
    "print(\"\\n2. éƒ¨é—¨å¹³å‡å·¥èµ„ï¼š\")\n",
    "avg_salaries = processor.calculate_department_avg_salary()\n",
    "for dept, avg in avg_salaries.items():\n",
    "    print(f\"   {dept}: {avg}å…ƒ\")\n",
    "\n",
    "print(\"\\n3. å·¥èµ„æå€¼ï¼š\")\n",
    "extremes = processor.find_salary_extremes()\n",
    "print(\n",
    "    f\"   æœ€é«˜å·¥èµ„: {extremes['æœ€é«˜']['å§“å']} ({extremes['æœ€é«˜']['éƒ¨é—¨']}) - {extremes['æœ€é«˜']['å·¥èµ„']}å…ƒ\"\n",
    ")\n",
    "print(\n",
    "    f\"   æœ€ä½å·¥èµ„: {extremes['æœ€ä½']['å§“å']} ({extremes['æœ€ä½']['éƒ¨é—¨']}) - {extremes['æœ€ä½']['å·¥èµ„']}å…ƒ\"\n",
    ")\n",
    "\n",
    "print(\"\\n4. æŒ‰å…¥èŒæ—¥æœŸæ’åºï¼š\")\n",
    "sorted_employees = processor.sort_by_join_date()\n",
    "for emp in sorted_employees:\n",
    "    print(f\"   {emp['å§“å']} - {emp['å…¥èŒæ—¥æœŸ']} ({emp['éƒ¨é—¨']})\")\n",
    "\n",
    "# ä¿å­˜ç»“æœç¤ºä¾‹\n",
    "processor.save_results(\"éƒ¨é—¨å¹³å‡å·¥èµ„.csv\", avg_salaries)\n",
    "processor.save_results(\"å‘˜å·¥æŒ‰å…¥èŒæ—¥æœŸæ’åº.csv\", sorted_employees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç¬¬å››é¢˜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### ğŸ“‹ ç¬¬å››é¢˜è§£é¢˜è¦ç‚¹åˆ†æ\n",
    "\n",
    "**ä¸»è¦è€ƒæŸ¥çŸ¥è¯†ç‚¹ï¼š**\n",
    "1. **JSONæ•°æ®å¤„ç†** - æ·±å±‚åµŒå¥—ç»“æ„çš„è®¿é—®\n",
    "2. **åˆ—è¡¨æ¨å¯¼ä¸è¿‡æ»¤** - æ´»è·ƒç”¨æˆ·ç­›é€‰\n",
    "3. **æ•°æ®ç»Ÿè®¡è®¡ç®—** - å¹³å‡å€¼ã€åˆ†ç»„ç»Ÿè®¡\n",
    "4. **defaultdictä½¿ç”¨** - ç®€åŒ–è®¡æ•°é€»è¾‘\n",
    "5. **åˆ—è¡¨æˆå‘˜æ£€æŸ¥** - `in` æ“ä½œç¬¦ä½¿ç”¨\n",
    "\n",
    "**æ ¸å¿ƒè§£é¢˜æ€è·¯ï¼š**\n",
    "\n",
    "#### 1. æ•°æ®æå–è·¯å¾„\n",
    "```python\n",
    "# æ­£ç¡®çš„æ•°æ®è®¿é—®è·¯å¾„\n",
    "users = json_data[\"data\"][\"users\"]  # äºŒå±‚åµŒå¥—è®¿é—®\n",
    "```\n",
    "\n",
    "#### 2. æ¡ä»¶è¿‡æ»¤æŠ€å·§\n",
    "```python\n",
    "# æ–¹æ³•1: ä¼ ç»Ÿå¾ªç¯\n",
    "active_users = []\n",
    "for user in users:\n",
    "    if user['is_active']:\n",
    "        active_users.append(user)\n",
    "\n",
    "# æ–¹æ³•2: åˆ—è¡¨æ¨å¯¼(æ›´ç®€æ´)\n",
    "active_users = [user for user in users if user['is_active']]\n",
    "```\n",
    "\n",
    "#### 3. ç»Ÿè®¡è®¡ç®—æ¨¡å¼\n",
    "```python\n",
    "# ç´¯åŠ æ¨¡å¼ - ç”¨äºå¹³å‡å€¼è®¡ç®—\n",
    "total_age = sum(user['profile']['age'] for user in users)\n",
    "avg_age = total_age / len(users)\n",
    "\n",
    "# è®¡æ•°æ¨¡å¼ - ç”¨äºåˆ†ç»„ç»Ÿè®¡\n",
    "dept_counts = defaultdict(int)\n",
    "for user in users:\n",
    "    dept_counts[user['profile']['department']] += 1\n",
    "```\n",
    "\n",
    "#### 4. åˆ—è¡¨æˆå‘˜æ£€æŸ¥\n",
    "```python\n",
    "# æ£€æŸ¥åˆ—è¡¨ä¸­æ˜¯å¦åŒ…å«æŸå…ƒç´ \n",
    "if 'admin' in user['roles']:  # rolesæ˜¯ä¸€ä¸ªåˆ—è¡¨\n",
    "    admin_users.append(user)\n",
    "```\n",
    "\n",
    "**å¸¸è§é”™è¯¯é¿å…ï¼š**\n",
    "- âŒ æ•°æ®è®¿é—®è·¯å¾„é”™è¯¯ï¼š`json_data[\"users\"]` \n",
    "- âœ… æ­£ç¡®è·¯å¾„ï¼š`json_data[\"data\"][\"users\"]`\n",
    "- âŒ å¿˜è®°å¤„ç†åµŒå¥—ç»“æ„ï¼š`user[\"age\"]`\n",
    "- âœ… æ­£ç¡®è®¿é—®ï¼š`user[\"profile\"][\"age\"]`\n",
    "- âŒ å¹³å‡å€¼ä¸å¤„ç†ç©ºåˆ—è¡¨æƒ…å†µ\n",
    "- âœ… æ·»åŠ é˜²æŠ¤ï¼š`avg_age = total / len(users) if users else 0`\n",
    "\n",
    "**è¿›é˜¶ä¼˜åŒ–æŠ€å·§ï¼š**\n",
    "```python\n",
    "# ä½¿ç”¨ç”Ÿæˆå™¨è¡¨è¾¾å¼èŠ‚çœå†…å­˜\n",
    "ages = (user['profile']['age'] for user in users)\n",
    "avg_age = sum(ages) / len(users)\n",
    "\n",
    "# ä½¿ç”¨Counterç®€åŒ–ç»Ÿè®¡\n",
    "from collections import Counter\n",
    "dept_counts = Counter(user['profile']['department'] for user in users)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é¢˜ç›®4ï¼šJSON APIæ•°æ®æ¨¡æ‹Ÿ - æ ‡å‡†ç­”æ¡ˆ\n",
    "\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "def process_api_data():\n",
    "    \"\"\"å¤„ç†API JSONæ•°æ®\"\"\"\n",
    "    \n",
    "    json_data = {\n",
    "        \"status\": \"success\",\n",
    "        \"data\": {\n",
    "            \"users\": [\n",
    "                {\n",
    "                    \"id\": 1,\n",
    "                    \"username\": \"admin\",\n",
    "                    \"email\": \"admin@example.com\",\n",
    "                    \"roles\": [\"admin\", \"user\"],\n",
    "                    \"profile\": {\n",
    "                        \"first_name\": \"å¼ \",\n",
    "                        \"last_name\": \"ä¸‰\",\n",
    "                        \"age\": 28,\n",
    "                        \"department\": \"æŠ€æœ¯éƒ¨\"\n",
    "                    },\n",
    "                    \"is_active\": True,\n",
    "                    \"last_login\": \"2024-01-15T10:30:00Z\"\n",
    "                },\n",
    "                {\n",
    "                    \"id\": 2,\n",
    "                    \"username\": \"user1\",\n",
    "                    \"email\": \"user1@example.com\",\n",
    "                    \"roles\": [\"user\"],\n",
    "                    \"profile\": {\n",
    "                        \"first_name\": \"æ\",\n",
    "                        \"last_name\": \"å››\",\n",
    "                        \"age\": 25,\n",
    "                        \"department\": \"é”€å”®éƒ¨\"\n",
    "                    },\n",
    "                    \"is_active\": False,\n",
    "                    \"last_login\": \"2024-01-10T15:20:00Z\"\n",
    "                },\n",
    "                {\n",
    "                    \"id\": 3,\n",
    "                    \"username\": \"user2\",\n",
    "                    \"email\": \"user2@example.com\",\n",
    "                    \"roles\": [\"user\"],\n",
    "                    \"profile\": {\n",
    "                        \"first_name\": \"ç‹\",\n",
    "                        \"last_name\": \"äº”\",\n",
    "                        \"age\": 28,\n",
    "                        \"department\": \"äººäº‹éƒ¨\"\n",
    "                    },\n",
    "                    \"is_active\": True,\n",
    "                    \"last_login\": \"2024-01-20T12:20:00Z\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # 1. è§£æJSONæ•°æ®\n",
    "    users = json_data[\"data\"][\"users\"]\n",
    "    print(f\"ğŸ“Š æ€»ç”¨æˆ·æ•°é‡: {len(users)}\")\n",
    "    \n",
    "    # 2. æå–æ‰€æœ‰æ´»è·ƒç”¨æˆ·çš„ä¿¡æ¯\n",
    "    active_users = []\n",
    "    for user in users:\n",
    "        if user['is_active']:\n",
    "            active_users.append(user)\n",
    "    \n",
    "    print(f\"âœ… æ´»è·ƒç”¨æˆ·æ•°é‡: {len(active_users)}\")\n",
    "    for user in active_users:\n",
    "        print(f\"   - {user['username']} ({user['profile']['first_name']}{user['profile']['last_name']})\")\n",
    "    \n",
    "    # 3. è®¡ç®—ç”¨æˆ·å¹³å‡å¹´é¾„\n",
    "    total_age = 0\n",
    "    for user in users:\n",
    "        total_age += user['profile']['age']\n",
    "    \n",
    "    avg_age = round(total_age / len(users), 2) if users else 0\n",
    "    print(f\"ğŸ“ˆ ç”¨æˆ·å¹³å‡å¹´é¾„: {avg_age} å²\")\n",
    "    \n",
    "    # 4. æŒ‰éƒ¨é—¨åˆ†ç»„ç»Ÿè®¡ç”¨æˆ·æ•°é‡\n",
    "    dept_counts = defaultdict(int)\n",
    "    for user in users:\n",
    "        department = user['profile']['department']\n",
    "        dept_counts[department] += 1\n",
    "    \n",
    "    print(f\"ğŸ¢ éƒ¨é—¨ç”¨æˆ·ç»Ÿè®¡:\")\n",
    "    for dept, count in dept_counts.items():\n",
    "        print(f\"   - {dept}: {count} äºº\")\n",
    "    \n",
    "    # 5. æ‰¾å‡ºæ‹¥æœ‰adminè§’è‰²çš„ç”¨æˆ·\n",
    "    admin_users = []\n",
    "    for user in users:\n",
    "        if 'admin' in user['roles']:\n",
    "            admin_users.append(user)\n",
    "    \n",
    "    print(f\"ğŸ‘‘ ç®¡ç†å‘˜ç”¨æˆ·æ•°é‡: {len(admin_users)}\")\n",
    "    for admin in admin_users:\n",
    "        print(f\"   - {admin['username']} (è§’è‰²: {', '.join(admin['roles'])})\")\n",
    "    \n",
    "    return {\n",
    "        \"active_users\": active_users,\n",
    "        \"average_age\": avg_age,\n",
    "        \"department_counts\": dict(dept_counts),\n",
    "        \"admin_users\": admin_users\n",
    "    }\n",
    "\n",
    "\n",
    "# æµ‹è¯•ä»£ç \n",
    "result = process_api_data()\n",
    "print(\"\\n=== JSON APIæ•°æ®å¤„ç†ç»“æœæ‘˜è¦ ===\")\n",
    "print(\"æ´»è·ƒç”¨æˆ·æ•°é‡:\", len(result[\"active_users\"]))\n",
    "print(\"ç”¨æˆ·å¹³å‡å¹´é¾„:\", result[\"average_age\"])\n",
    "print(\"éƒ¨é—¨ç”¨æˆ·ç»Ÿè®¡:\", result[\"department_counts\"])\n",
    "print(\"ç®¡ç†å‘˜ç”¨æˆ·:\", [user[\"username\"] for user in result[\"admin_users\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# ç¬¬äº”é¢˜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### ğŸ“‹ ç¬¬äº”é¢˜è§£é¢˜è¦ç‚¹åˆ†æ\n",
    "\n",
    "**ä¸»è¦è€ƒæŸ¥çŸ¥è¯†ç‚¹ï¼š**\n",
    "1. **æ–‡ä»¶ç³»ç»Ÿæ“ä½œ** - `os`æ¨¡å—çš„ç›®å½•å’Œæ–‡ä»¶æ“ä½œ\n",
    "2. **æ–‡ä»¶å¤åˆ¶** - `shutil`æ¨¡å—çš„é«˜çº§æ–‡ä»¶æ“ä½œ\n",
    "3. **ç›®å½•éå†** - `os.walk()`é€’å½’éå†æ–‡ä»¶æ ‘\n",
    "4. **è·¯å¾„å¤„ç†** - ç›¸å¯¹è·¯å¾„ã€ç»å¯¹è·¯å¾„è½¬æ¢\n",
    "5. **æ—¶é—´æˆ³å¤„ç†** - `datetime`æ ¼å¼åŒ–å’ŒISOæ ¼å¼\n",
    "6. **JSONæ•°æ®å¤„ç†** - æŠ¥å‘Šç”Ÿæˆå’Œæ•°æ®åºåˆ—åŒ–\n",
    "7. **å¼‚å¸¸å¤„ç†** - æ–‡ä»¶æ“ä½œçš„é”™è¯¯æ•è·\n",
    "\n",
    "**æ ¸å¿ƒè§£é¢˜æ€è·¯ï¼š**\n",
    "\n",
    "#### 1. æ–‡ä»¶ç³»ç»ŸåŸºç¡€æ“ä½œ\n",
    "```python\n",
    "# ç›®å½•åˆ›å»º\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# ç›®å½•å­˜åœ¨æ£€æŸ¥\n",
    "os.path.exists(path)\n",
    "\n",
    "# æ–‡ä»¶å¤§å°è·å–\n",
    "os.path.getsize(file_path)\n",
    "\n",
    "# è·¯å¾„æ‹¼æ¥\n",
    "os.path.join(dir1, dir2, filename)\n",
    "```\n",
    "\n",
    "#### 2. ç›®å½•éå†æŠ€å·§\n",
    "```python\n",
    "# os.walk()è¿”å›ä¸‰å…ƒç»„: (å½“å‰ç›®å½•, å­ç›®å½•åˆ—è¡¨, æ–‡ä»¶åˆ—è¡¨)\n",
    "for root, dirs, files in os.walk(source_dir):\n",
    "    for filename in files:\n",
    "        full_path = os.path.join(root, filename)\n",
    "        # è®¡ç®—ç›¸å¯¹è·¯å¾„ä¿æŒç›®å½•ç»“æ„\n",
    "        relative_path = os.path.relpath(full_path, source_dir)\n",
    "```\n",
    "\n",
    "#### 3. æ–‡ä»¶å¤åˆ¶æ–¹æ³•é€‰æ‹©\n",
    "```python\n",
    "# shutil.copy2() - æ¨èï¼Œä¿æŒæ–‡ä»¶å…ƒæ•°æ®\n",
    "shutil.copy2(source, destination)\n",
    "\n",
    "# shutil.copy() - åªå¤åˆ¶æ–‡ä»¶å†…å®¹å’Œæƒé™\n",
    "shutil.copy(source, destination)\n",
    "\n",
    "# shutil.copyfile() - åªå¤åˆ¶æ–‡ä»¶å†…å®¹\n",
    "shutil.copyfile(source, destination)\n",
    "```\n",
    "\n",
    "#### 4. æ—¶é—´æˆ³å¤„ç†æ¨¡å¼\n",
    "```python\n",
    "# ç”Ÿæˆæ—¶é—´æˆ³åç¼€\n",
    "timestamp = datetime.now().strftime(\"_%Y%m%d_%H%M%S\")\n",
    "\n",
    "# ISOæ ¼å¼æ—¶é—´(é€‚åˆJSON)\n",
    "iso_time = datetime.now().isoformat()\n",
    "```\n",
    "\n",
    "#### 5. æ–‡ä»¶å¤§å°æ ¼å¼åŒ–\n",
    "```python\n",
    "def format_size(bytes):\n",
    "    if bytes < 1024:\n",
    "        return f\"{bytes} B\"\n",
    "    elif bytes < 1024**2:\n",
    "        return f\"{bytes/1024:.2f} KB\"\n",
    "    # ... ç»§ç»­å¤„ç†MB, GB\n",
    "```\n",
    "\n",
    "**å¸¸è§é”™è¯¯é¿å…ï¼š**\n",
    "- âŒ ä¸æ£€æŸ¥æºç›®å½•å­˜åœ¨æ€§å°±å¼€å§‹å¤‡ä»½\n",
    "- âœ… å…ˆéªŒè¯ `os.path.exists(source_dir)`\n",
    "- âŒ ç›´æ¥å¤åˆ¶åˆ°æ ¹ç›®å½•ï¼Œç ´åç›®å½•ç»“æ„\n",
    "- âœ… ä½¿ç”¨ `os.path.relpath()` ä¿æŒç›¸å¯¹è·¯å¾„\n",
    "- âŒ æ–‡ä»¶åå†²çªæ—¶è¦†ç›–åŸæ–‡ä»¶\n",
    "- âœ… æ·»åŠ æ—¶é—´æˆ³é¿å…å†²çª\n",
    "- âŒ å¿½ç•¥å•ä¸ªæ–‡ä»¶å¤åˆ¶å¤±è´¥\n",
    "- âœ… try-exceptåŒ…è£…æ¯ä¸ªæ–‡ä»¶æ“ä½œ\n",
    "\n",
    "**ç”Ÿäº§çº§å¢å¼ºåŠŸèƒ½ï¼š**\n",
    "```python\n",
    "# 1. è¿›åº¦å›è°ƒ\n",
    "def backup_with_progress(self, progress_callback=None):\n",
    "    for i, file_info in enumerate(files):\n",
    "        # å¤‡ä»½æ–‡ä»¶...\n",
    "        if progress_callback:\n",
    "            progress_callback(i+1, total_files)\n",
    "\n",
    "# 2. æ–‡ä»¶è¿‡æ»¤\n",
    "def should_backup(self, filename):\n",
    "    # æ’é™¤ä¸´æ—¶æ–‡ä»¶ã€éšè—æ–‡ä»¶ç­‰\n",
    "    return not filename.startswith('.') and not filename.endswith('.tmp')\n",
    "\n",
    "# 3. å¢é‡å¤‡ä»½\n",
    "def incremental_backup(self):\n",
    "    # åªå¤‡ä»½ä¿®æ”¹æ—¶é—´æ–°äºä¸Šæ¬¡å¤‡ä»½çš„æ–‡ä»¶\n",
    "    pass\n",
    "```\n",
    "\n",
    "**å…³é”®å­¦ä¹ ç‚¹ï¼š**\n",
    "- æ–‡ä»¶æ“ä½œå¿…é¡»æœ‰å®Œæ•´çš„å¼‚å¸¸å¤„ç†\n",
    "- ä¿æŒç›®å½•ç»“æ„éœ€è¦æ­£ç¡®å¤„ç†ç›¸å¯¹è·¯å¾„\n",
    "- ä½¿ç”¨`shutil.copy2()`ä¿æŒæ–‡ä»¶å…ƒæ•°æ®\n",
    "- JSONæŠ¥å‘Šä¾¿äºåç»­å¤„ç†å’Œæ¢å¤\n",
    "- æ—¶é—´æˆ³é¿å…æ–‡ä»¶åå†²çª\n",
    "- é€’å½’éå†å¤„ç†åµŒå¥—ç›®å½•ç»“æ„\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é¢˜ç›®5ï¼šæ•°æ®å¤‡ä»½å·¥å…· - ä»£ç å®ç°åŒºåŸŸ\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "\n",
    "class BackupTool:\n",
    "    \"\"\"æ•°æ®å¤‡ä»½å·¥å…·ç±»\"\"\"\n",
    "\n",
    "    def __init__(self, source_dir, backup_dir):\n",
    "        self.source_dir = source_dir\n",
    "        self.backup_dir = backup_dir\n",
    "        self.backup_report = {\n",
    "            \"backup_time\": None,\n",
    "            \"source_directory\": source_dir,\n",
    "            \"backup_directory\": backup_dir,\n",
    "            \"files_backed_up\": [],\n",
    "            \"total_files\": 0,\n",
    "            \"total_size\": 0,\n",
    "            \"status\": \"pending\",\n",
    "            \"errors\": [],\n",
    "        }\n",
    "    def _format_file_size(self,size_bytes):\n",
    "        \"\"\"æ ¼å¼åŒ–æ–‡ä»¶å¤§å°æ˜¾ç¤º\"\"\"\n",
    "        if size_bytes < 1024:\n",
    "            return f'{size_bytes} B'\n",
    "        elif size_bytes < 1024*1024:\n",
    "            return f'{size_bytes / 1024:.2f} KB'\n",
    "        elif size_bytes < 1024*1024*1024:\n",
    "            return f'{size_bytes / (1024*1024):.2f} MB'\n",
    "        else:\n",
    "            return f'{size_bytes / (1024*1024*1024):.2f} GB'    \n",
    "        \n",
    "    def _get_timestamp_suffix(self):\n",
    "        \"\"\"ç”Ÿæˆæ—¶é—´æˆ³åç¼€\"\"\"\n",
    "        return datetime.now().strftime(\"_%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    def create_backup(self):\n",
    "        \"\"\"åˆ›å»ºå¤‡ä»½\"\"\"\n",
    "        # TODO: å®ç°å¤‡ä»½é€»è¾‘\n",
    "        # 1. åˆ›å»ºå¤‡ä»½ç›®å½• -> ä¸çŸ¥é“æ€ä¹ˆæâŒ\n",
    "        # 2. éå†æºç›®å½•ä¸­çš„æ–‡ä»¶ -> ç”¨os.walk()?\n",
    "        # 3. ä¸ºæ¯ä¸ªæ–‡ä»¶æ·»åŠ æ—¶é—´æˆ³åå¤åˆ¶åˆ°å¤‡ä»½ç›®å½• -> datetime.now()?\n",
    "        # 4. è®¡ç®—æ€»å¤§å° -> osæ¨¡å—çš„æŸä¸ªå‡½æ•°ï¼Ÿ\n",
    "        # 5. è®°å½•å¤‡ä»½ä¿¡æ¯ -> è®°å½•åˆ°self.report\n",
    "        # é‡è¦â€¼ï¸ï¼Œè¦ä½¿ç”¨try-except\n",
    "        # ä»¥ä¸‹æ˜¯æŠ„çš„æ ‡å‡†ç­”æ¡ˆã€‚ã€‚ã€‚ç”±äºè‡ªå·±æ€è€ƒè¿˜æ²¡ç”¨è¿‡çš„æ¨¡å—å®åœ¨æ˜¯å¤ªè´¹æ—¶é—´ï¼Œä¸å¦‚ç›´æ¥çœ‹ç­”æ¡ˆï¼ŒèƒŒä½\n",
    "        try:\n",
    "            # è®°å½•å¤‡ä»½å¼€å§‹æ—¶é—´\n",
    "            self.backup_report['backup_time'] = datetime.now().isoformat()\n",
    "            print(f'â™»ï¸ å¼€å§‹å¤‡ä»½ :{self.source_dir} -> {self.backup_dir}')\n",
    "\n",
    "            # 1. æ£€æŸ¥æºç›®å½•æ˜¯å¦å­˜åœ¨\n",
    "            if not os.path.exists(self.source_dir):\n",
    "                error_msg = f'æºç›®å½•ä¸å­˜åœ¨: {self.source_dir}'\n",
    "                self.backup_report['errors'].append(error_msg)\n",
    "                self.backup_report['status'] = 'failed'\n",
    "                print('self.backup_report',self.backup_report)\n",
    "                print(f'âŒ {error_msg}')\n",
    "                return False\n",
    "\n",
    "            # 2. æ­¤æ—¶è¯´æ˜æºç›®å½•æ˜¯å­˜åœ¨çš„ï¼Œé‚£ä¹ˆå¼€å§‹åˆ›å»ºå¤‡ä»½ç›®å½•\n",
    "            os.makedirs(self.backup_dir,exist_ok=True)\n",
    "            print(f'ğŸ“ƒ å¤‡ä»½ç›®å½•å·²ç»åˆ›å»º: {self.backup_dir}')\n",
    "\n",
    "            # 3. éå†æºç›®å½•ä¸­çš„æ–‡ä»¶\n",
    "            total_size = 0\n",
    "            files_count = 0\n",
    "            timestamp_suffix = self._get_timestamp_suffix()\n",
    "\n",
    "            for root,dirs,files in os.walk(self.source_dir):\n",
    "                print(f'root: {root}') # å½“å‰çš„æºç›®å½•ï¼Œä¹Ÿå°±æ˜¯å®ä¾‹ä¼ å…¥çš„ç¬¬ä¸€ä¸ªå‚æ•°\n",
    "                print(f'dirs: {dirs}') # æºç›®å½•é‡Œçš„å­ç›®å½•ï¼Œä¹Ÿå°±æ˜¯æºç›®å½•é‡Œé¢åŒ…å«å“ªäº›æ–‡ä»¶å¤¹\n",
    "                print(f'files: {files}') # æºç›®å½•é‡Œé¢åŒ…å«å“ªäº›æ–‡ä»¶ï¼Ÿä¼šè‡ªåŠ¨å¯»æ‰¾æ‰€æœ‰æ–‡ä»¶ï¼ŒåŒ…å«åµŒå¥—ç›®å½•ä¸­çš„æ–‡ä»¶ã€‚files:['test1.txt','test2.txt',config.json','nested_file.txt']\n",
    "                for filename in files:\n",
    "                    try:\n",
    "                        # æ„å»ºæºæ–‡ä»¶å’Œç›®æ ‡æ–‡ä»¶è·¯å¾„\n",
    "                        source_file = os.path.join(root,filename)\n",
    "                        print(f'===æ„å»ºæºæ–‡ä»¶å’Œç›®æ ‡æ–‡ä»¶è·¯å¾„:{source_file}===') # ===æ„å»ºæºæ–‡ä»¶å’Œç›®æ ‡æ–‡ä»¶è·¯å¾„:source_files/test1.txt===\n",
    "                        # è®¡ç®—ç›¸å¯¹è·¯å¾„ä»¥ä¿æŒç›®å½•ç»“æ„\n",
    "                        \"\"\"\n",
    "                        ä¿æŒç›¸å¯¹ç›®å½•ç»“æ„æœ‰ä»€ä¹ˆç”¨ï¼Ÿ\n",
    "                        \n",
    "                        ä¿æŒç›¸å¯¹ç›®å½•ç»“æ„ç¡®ä¿å¤‡ä»½åçš„æ–‡ä»¶ç»„ç»‡ä¸æºç›®å½•å®Œå…¨ä¸€è‡´ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæºç›®å½•ä¸­æœ‰ \"subfolder/file.txt\"ï¼Œå¤‡ä»½åä¹Ÿä¼šåœ¨å¤‡ä»½ç›®å½•ä¸­åˆ›å»ºç›¸åŒçš„å­æ–‡ä»¶å¤¹ç»“æ„ï¼Œè€Œä¸æ˜¯å°†æ‰€æœ‰æ–‡ä»¶éƒ½å¹³é“ºåœ¨ä¸€ä¸ªç›®å½•ä¸­ï¼Œè¿™æ ·ä¾¿äºç®¡ç†å’Œè¿˜åŸã€‚\n",
    "                        \"\"\"\n",
    "                        relative_path = os.path.relpath(source_file,self.source_dir) # è·å–å½“å‰æºæ–‡ä»¶å’Œæºç›®å½•çš„ç›¸å¯¹è·¯å¾„ï¼Œä½œç”¨æ˜¯æ„å»ºbackupç›®å½•çš„æ—¶å€™ï¼Œä¹Ÿèƒ½çŸ¥é“å¯¹åº”çš„æ–‡ä»¶å¤¹ç»“æ„ï¼Œç¡®ä¿åµŒå¥—å…³ç³»çš„æ­£ç¡®\n",
    "                        relative_dir = os.path.dirname(relative_path) # çŸ¥é“ç›¸å¯¹è·¯å¾„çš„æ–‡ä»¶å¤¹çš„åå­—æ˜¯ä»€ä¹ˆï¼Œå¦‚æœæœ‰åµŒå¥—å°±èƒ½å¾—åˆ°åµŒå¥—çš„æ–‡ä»¶å¤¹ï¼Œä¸ºäº†æ„å»ºæ­£ç¡®çš„æ–‡ä»¶å¤¹ç»“æ„è€Œå­˜åœ¨\n",
    "                        print(f'===è®¡ç®—ç›¸å¯¹è·¯å¾„ä»¥ä¿æŒç›®å½•ç»“æ„:{relative_path},å½“å‰ç›¸å¯¹è·¯å¾„ä¸­çš„æ–‡ä»¶å¤¹çš„åå­—æ˜¯: {relative_dir}===') # ===è®¡ç®—ç›¸å¯¹è·¯å¾„ä»¥ä¿æŒç›®å½•ç»“æ„:test2.txt,å½“å‰ç›¸å¯¹è·¯å¾„ä¸­çš„æ–‡ä»¶å¤¹çš„åå­—æ˜¯:=== -> è¿™ä¸ªæ„æ€æ˜¯æ²¡æœ‰æ–‡ä»¶å¤¹åå­—\n",
    "                        # ä¸ºæ–‡ä»¶åæ·»åŠ æ—¶é—´æˆ³\n",
    "                        name,ext = os.path.splitext(filename)\n",
    "                        print(f'æ‹†åˆ†æ–‡ä»¶å:\\n{os.path.splitext(filename)}') # æ‹†åˆ†æ–‡ä»¶å:('test1', '.txt')\n",
    "                        backup_filename = f'{name}{timestamp_suffix}{ext}' # å¤‡ä»½åçš„æ–‡ä»¶å\n",
    "\n",
    "                        # æ„å»ºå®Œæ•´çš„å¤‡ä»½è·¯å¾„\n",
    "                        backup_subdir = os.path.join(self.backup_dir,relative_dir) if relative_dir else self.backup_dir # è¿™æ˜¯ä¸€ä¸ªä¸‰å…ƒè¡¨è¾¾å¼\n",
    "                        os.makedirs(backup_subdir,exist_ok=True)\n",
    "                        backup_file = os.path.join(backup_subdir,backup_filename)\n",
    "\n",
    "                        # 4. å¤åˆ¶æ–‡ä»¶åˆ°å¤‡ä»½ç›®å½•\n",
    "                        shutil.copy2(source_file,backup_file) # copy2ä¿ç•™æ–‡ä»¶å…ƒæ•°æ®ï¼Œå°†source_fileä¸­çš„æ–‡ä»¶å†…å®¹ï¼Œå¤åˆ¶åˆ°backup_fileå½“ä¸­å»ï¼Œä¿ç•™åŸæ¥çš„æ–‡ä»¶å…ƒæ•°æ®ã€‚ï¼ˆæœ‰å“ªäº›å…ƒæ•°æ®â“ï¼‰\n",
    "\n",
    "                        # 5. è®¡ç®—æ–‡ä»¶å¤§å°\n",
    "                        file_size = os.path.getsize(source_file)\n",
    "                        total_size += file_size\n",
    "                        files_count += 1\n",
    "                        print(f'æ–‡ä»¶å¤§å°:{file_size},æ€»å¤§å°:{total_size},æ–‡ä»¶æ•°é‡:{files_count}')\n",
    "\n",
    "                        # 6. è®°å½•å¤‡ä»½ä¿¡æ¯\n",
    "                        file_info = {\n",
    "                            \"original_name\":relative_path,\n",
    "                            \"backup_name\":os.path.join(relative_dir,backup_filename) if relative_dir else backup_filename, \n",
    "                            \"size\":file_size,\n",
    "                            \"size_formatted\":self._format_file_size(file_size),\n",
    "                            \"backup_time\":datetime.now().isoformat()\n",
    "                        }\n",
    "                        print(f'å¤‡ä»½æ–‡ä»¶ä¿¡æ¯:\\n{file_info}')\n",
    "                        self.backup_report[\"files_backed_up\"].append(file_info)\n",
    "\n",
    "                        print(f'âœ… å·²å¤‡ä»½: {relative_path} -> {file_info['backup_name']} ({self._format_file_size(file_size)})')\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        error_msg = f\"å¤‡ä»½æ–‡ä»¶å¤±è´¥ {filename}:{str(e)}\"\n",
    "                        self.backup_report['errors'].append(error_msg)\n",
    "                        print(f'âŒ {error_msg}')\n",
    "                # æ›´æ–°æŠ¥å‘Šç»Ÿè®¡ä¿¡æ¯\n",
    "            self.backup_report[\"total_files\"] = files_count\n",
    "            self.backup_report[\"total_size\"] = total_size\n",
    "            self.backup_report[\"status\"] = \"success\" if not self.backup_report[\"errors\"] else \"completed_with_errors\"\n",
    "            \n",
    "            print(f\"\\nğŸ‰ å¤‡ä»½å®Œæˆ!\")\n",
    "            print(f\"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:\")\n",
    "            print(f\"   - å¤‡ä»½æ–‡ä»¶æ•°: {files_count}\")\n",
    "            print(f\"   - æ€»å¤§å°: {self._format_file_size(total_size)}\")\n",
    "            print(f\"   - é”™è¯¯æ•°: {len(self.backup_report['errors'])}\")\n",
    "            \n",
    "            return True\n",
    "        except Exception as e:\n",
    "             error_msg = f\"å¤‡ä»½è¿‡ç¨‹å‡ºé”™ :{str(e)}\"\n",
    "             self.backup_report['errors'].append(error_msg)\n",
    "             self.backup_report['status'] = 'failed'\n",
    "             print(f'âŒ {error_msg}')\n",
    "             return False\n",
    "\n",
    "    def generate_report(self):\n",
    "        \"\"\"ç”Ÿæˆå¤‡ä»½æŠ¥å‘Š\"\"\"\n",
    "        # TODO: ç”ŸæˆJSONæ ¼å¼çš„å¤‡ä»½æŠ¥å‘Š\n",
    "        # 1. åˆ›å»ºæŠ¥å‘Šæ–‡ä»¶åï¼ˆåŒ…å«æ—¶é—´æˆ³ï¼‰\n",
    "        # 2. å°†å¤‡ä»½ä¿¡æ¯å†™å…¥JSONæ–‡ä»¶\n",
    "        # 3. æ˜¾ç¤ºå¤‡ä»½ç»Ÿè®¡ä¿¡æ¯\n",
    "        try:\n",
    "            # 1. åˆ›å»ºæŠ¥å‘Šæ–‡ä»¶åï¼ˆåŒ…å«æ—¶é—´æˆ³ï¼‰\n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            report_filename = f'backup_report_{timestamp}.json'\n",
    "            report_path = os.path.join(self.backup_dir,report_filename)\n",
    "            print(f'å¤‡ä»½æŠ¥å‘Šæ—¶é—´æˆ³:{timestamp}')\n",
    "            print(f'å¤‡ä»½æŠ¥å‘Šæ–‡ä»¶å:{report_filename}')\n",
    "            print(f'å¤‡ä»½æŠ¥å‘Šæ–‡ä»¶è·¯å¾„:{report_path}')\n",
    "            # 2.å°†å¤‡ä»½ä¿¡æ¯å†™å…¥jsonæ–‡ä»¶\n",
    "            with open(report_path,'w',encoding='utf-8') as f:\n",
    "                json.dump(self.backup_report,f,ensure_ascii=False,indent=2)\n",
    "\n",
    "            # 3. æ˜¾ç¤ºå¤‡ä»½ç»Ÿè®¡ä¿¡æ¯\n",
    "            print(f\"\\nğŸ“‹ å¤‡ä»½æŠ¥å‘Šå·²ç”Ÿæˆ: {report_filename}\")\n",
    "            print(f\"ğŸ“„ æŠ¥å‘Šè¯¦æƒ…:\")\n",
    "            print(f\"   - å¤‡ä»½æ—¶é—´: {self.backup_report['backup_time']}\")\n",
    "            print(f\"   - æºç›®å½•: {self.backup_report['source_directory']}\")\n",
    "            print(f\"   - å¤‡ä»½ç›®å½•: {self.backup_report['backup_directory']}\")\n",
    "            print(f\"   - æ–‡ä»¶æ€»æ•°: {self.backup_report['total_files']}\")\n",
    "            print(f\"   - æ€»å¤§å°: {self._format_file_size(self.backup_report['total_size'])}\")\n",
    "            print(f\"   - çŠ¶æ€: {self.backup_report['status']}\")\n",
    "\n",
    "            # å¦‚æœæœ‰é”™çš„è¯ï¼Œæ˜¾ç¤ºå‡ºé”™è¯¯çš„åˆ—è¡¨\n",
    "            if self.backup_report['errors']:\n",
    "                print('âš ï¸ é”™è¯¯åˆ—è¡¨:')\n",
    "                for error in self.backup_report['errors']:\n",
    "                    print(f'    - {error}')\n",
    "\n",
    "            # æ˜¾ç¤ºå‡ºå¤‡ä»½æ–‡ä»¶åˆ—è¡¨\n",
    "            if self.backup_report['files_backed_up']:\n",
    "                print(f'\\næ–‡ä»¶ å¤‡ä»½æ–‡ä»¶åˆ—è¡¨')  \n",
    "                print(f\"å…ˆè¾“å‡ºself.backup_report['files_backed_up']çœ‹çœ‹:\\n{self.backup_report['files_backed_up']}\") \n",
    "                for file_info in self.backup_report['files_backed_up']:\n",
    "                    print(f'    {file_info['original_name']} -> {file_info['backup_name']} ({file_info['size_formatted']})')\n",
    "            return report_path\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {str(e)}\")\n",
    "            return None\n",
    "        \n",
    "    def restore_file(self,backup_filename,restore_path=None):\n",
    "        \"\"\"æ¢å¤å•ä¸ªæ–‡ä»¶\"\"\"\n",
    "        print(f'å½“å‰ä¼ å…¥çš„å‚æ•°æ˜¯:{backup_filename},{restore_path}')\n",
    "        try:\n",
    "            # æŸ¥æ‰¾å¤‡ä»½æ–‡ä»¶\n",
    "            for file_info in self.backup_report['files_backed_up']:\n",
    "                if file_info['backup_name'] == backup_filename:\n",
    "                    backup_file_path = os.path.join(self.backup_dir,file_info['backup_name'])\n",
    "\n",
    "                    if restore_path is None:\n",
    "                        restore_path = os.path.join(self.source_dir,file_info['original_name'])\n",
    "\n",
    "                    # ç¡®ä¿å›å¤ç›®å½•å­˜åœ¨\n",
    "                    os.makedirs(os.path.dirname(restore_path),exist_ok=True)\n",
    "\n",
    "                    # å¤åˆ¶æ–‡ä»¶\n",
    "                    shutil.copy2(backup_file_path,restore_path)\n",
    "                    print(f\"âœ… æ–‡ä»¶å·²æ¢å¤: {backup_filename} -> {restore_path}\")\n",
    "                    return True\n",
    "                \n",
    "            print(f\"âŒ æœªæ‰¾åˆ°å¤‡ä»½æ–‡ä»¶: {backup_filename}\")\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ æ¢å¤æ–‡ä»¶å¤±è´¥: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "# ç¤ºä¾‹ä½¿ç”¨å’Œæµ‹è¯•\n",
    "def demo_backup():\n",
    "    \"\"\"æ¼”ç¤ºå¤‡ä»½åŠŸèƒ½\"\"\"\n",
    "    # åˆ›å»ºæµ‹è¯•æ–‡ä»¶\n",
    "    print(\"ğŸ”§ å‡†å¤‡æµ‹è¯•ç¯å¢ƒ...\")\n",
    "    test_files = {\n",
    "        \"test1.txt\": \"è¿™æ˜¯test1.txtçš„å†…å®¹\\nåŒ…å«å¤šè¡Œæ•°æ®\\næµ‹è¯•å¤‡ä»½åŠŸèƒ½\",\n",
    "        \"test2.txt\": \"è¿™æ˜¯test2.txtçš„å†…å®¹\\nå¦ä¸€ä¸ªæµ‹è¯•æ–‡ä»¶\",\n",
    "        \"config.json\": json.dumps({\"app_name\": \"backup_tool\", \"version\": \"1.0\", \"settings\": {\"auto_backup\": True}}, ensure_ascii=False, indent=2),\n",
    "        \"subfolder/nested_file.txt\": \"è¿™æ˜¯åµŒå¥—æ–‡ä»¶å¤¹ä¸­çš„æ–‡ä»¶\\næµ‹è¯•ç›®å½•ç»“æ„ä¿æŒ\"\n",
    "    }\n",
    "    \n",
    "    for filepath, content in test_files.items():\n",
    "        full_path = os.path.join(\"source_files\", filepath) # æ¯”å¦‚ç¬¬ä¸€ä¸ªfilepathï¼Œå¾—åˆ°'source_files/test1.txt',æœ€åä¸€ä¸ªå¾—åˆ°'source_files/subfolder/nested_file.txt',éƒ½æ˜¯å¾—åˆ°å­—ç¬¦ä¸²\n",
    "        print('os.path.dirname(full_path):',os.path.dirname(full_path))\n",
    "        print('full_path is:',full_path)\n",
    "        os.makedirs(os.path.dirname(full_path), exist_ok=True)\n",
    "        with open(full_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(content)\n",
    "    \n",
    "    print(f\"âœ… æµ‹è¯•æ–‡ä»¶å·²åˆ›å»º\")\n",
    "    \n",
    "    # æ‰§è¡Œå¤‡ä»½\n",
    "    backup_tool = BackupTool(\"source_files\", \"backup_files\")\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"ğŸš€ å¼€å§‹å¤‡ä»½æ“ä½œ\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    success = backup_tool.create_backup()\n",
    "    \n",
    "    if success:\n",
    "        print(f'åˆ°è¿™é‡Œè¯´æ˜å¤‡ä»½å·²ç»æˆåŠŸ!')\n",
    "        report_path = backup_tool.generate_report()\n",
    "        print(f'å¤‡ä»½æ–‡ä»¶çš„è·¯å¾„:{report_path}')\n",
    "        # æ¼”ç¤ºæ¢å¤åŠŸèƒ½\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"ğŸ”„ æ¼”ç¤ºæ–‡ä»¶æ¢å¤åŠŸèƒ½\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        if backup_tool.backup_report[\"files_backed_up\"]:\n",
    "            first_backup = backup_tool.backup_report[\"files_backed_up\"][0]\n",
    "            backup_tool.restore_file(first_backup[\"backup_name\"], \"restored_files/\" + first_backup[\"original_name\"])\n",
    "\n",
    "    \"\"\"\n",
    "    è¿™é‡Œä¸ºä»€ä¹ˆè¦return backup_tool?\n",
    "        è¿”å›backup_toolæ˜¯ä¸ºäº†è®©ä¸»ç¨‹åº(if __name__ == \"__main__\")èƒ½è·å–åˆ°å¤‡ä»½å·¥å…·å®ä¾‹ï¼Œè¿™æ ·å¯ä»¥åœ¨éœ€è¦æ—¶ç»§ç»­ä½¿ç”¨è¿™ä¸ªå®ä¾‹è¿›è¡Œå…¶ä»–æ“ä½œã€‚è™½ç„¶åœ¨è¿™ä¸ªç¤ºä¾‹ä¸­æ²¡æœ‰è¿›ä¸€æ­¥ä½¿ç”¨ï¼Œä½†è¿™æ˜¯ä¸€ä¸ªè‰¯å¥½çš„ç¼–ç¨‹å®è·µï¼Œä¿æŒå‡½æ•°çš„å¯å¤ç”¨æ€§ã€‚\n",
    "    \"\"\"\n",
    "    return backup_tool\n",
    "\n",
    "# è¿è¡Œæ¼”ç¤º\n",
    "if __name__ == \"__main__\":\n",
    "    backup_tool = demo_backup()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "create_backup() å‡½æ•°æ‰§è¡Œæµç¨‹\n",
    "â”œâ”€â”€ 1. åˆå§‹åŒ–\n",
    "â”‚   â”œâ”€â”€ è®°å½•å¤‡ä»½å¼€å§‹æ—¶é—´\n",
    "â”‚   â”œâ”€â”€ æ£€æŸ¥æºç›®å½•æ˜¯å¦å­˜åœ¨ âŒâ†’ è¿”å›å¤±è´¥\n",
    "â”‚   â””â”€â”€ åˆ›å»ºå¤‡ä»½ç›®å½•\n",
    "â”œâ”€â”€ 2. éå†æ–‡ä»¶\n",
    "â”‚   â”œâ”€â”€ os.walk(source_dir)\n",
    "â”‚   â””â”€â”€ å¯¹æ¯ä¸ªæ–‡ä»¶æ‰§è¡Œï¼š\n",
    "â”‚       â”œâ”€â”€ æ„å»ºæºæ–‡ä»¶è·¯å¾„\n",
    "â”‚       â”œâ”€â”€ è®¡ç®—ç›¸å¯¹è·¯å¾„\n",
    "â”‚       â”œâ”€â”€ ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å\n",
    "â”‚       â”œâ”€â”€ åˆ›å»ºå¤‡ä»½å­ç›®å½•\n",
    "â”‚       â”œâ”€â”€ å¤åˆ¶æ–‡ä»¶ (shutil.copy2)\n",
    "â”‚       â””â”€â”€ è®°å½•å¤‡ä»½æ–‡ä»¶ä¿¡æ¯\n",
    "â”œâ”€â”€ 3. ç»Ÿè®¡å’ŒæŠ¥å‘Š\n",
    "â”‚   â”œâ”€â”€ æ›´æ–°æŠ¥å‘Šç»Ÿè®¡\n",
    "â”‚   â”œâ”€â”€ è®¾ç½®çŠ¶æ€ï¼ˆæˆåŠŸ/éƒ¨åˆ†æˆåŠŸï¼‰\n",
    "â”‚   â””â”€â”€ æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯\n",
    "â””â”€â”€ 4. è¿”å›ç»“æœ âœ… True / âŒ False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç¬¬å…­é¢˜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“‹ ä½ çš„åŸå§‹ä»£ç é—®é¢˜æ€»ç»“\n",
    "## âŒ ä¸¥é‡é—®é¢˜ï¼ˆå½±å“åŠŸèƒ½ï¼‰\n",
    "1. take_snapshot() æ–¹æ³• - æ€§èƒ½ç¾éš¾\n",
    "- åœ¨forå¾ªç¯ä¸­æ¯å¤„ç†ä¸€ä¸ªæ–‡ä»¶å°±å†™ä¸€æ¬¡JSONæ–‡ä»¶\n",
    "- ç›‘æ§å¿«ç…§æ–‡ä»¶æœ¬èº«ï¼Œé€ æˆæ— é™å¾ªç¯\n",
    "- ä¿å­˜è¿‡å¤šæ— ç”¨çš„æ–‡ä»¶å±æ€§ä¿¡æ¯\n",
    "2. detect_changes() æ–¹æ³• - é€»è¾‘é”™è¯¯\n",
    "- é‡å¤è°ƒç”¨load_snapshot()æµªè´¹IO\n",
    "- å˜é‡å‘½åæ··ä¹±ï¼šold_snapshotå®é™…åªåŒ…å«keys\n",
    "- æ¯”è¾ƒé€»è¾‘é”™è¯¯ï¼šç”¨keyså»ç´¢å¼•å®Œæ•´å­—å…¸\n",
    "3. log_changes() æ–¹æ³• - åŠŸèƒ½ç¼ºå¤±\n",
    "- åªæ˜¯æ‰“å°å˜åŒ–ï¼Œæ²¡æœ‰å†™å…¥æ—¥å¿—æ–‡ä»¶\n",
    "-ç¼ºå°‘æ—¶é—´æˆ³å’Œæ ¼å¼åŒ–\n",
    "## âš ï¸ è®¾è®¡é—®é¢˜\n",
    "- è¿‡åº¦ä½¿ç”¨print()è¿›è¡Œè°ƒè¯•\n",
    "- ç¼ºå°‘ç±»å‹æ³¨è§£å’Œæ–‡æ¡£å­—ç¬¦ä¸²\n",
    "- å¼‚å¸¸å¤„ç†ä¸å¤Ÿç²¾ç»†\n",
    "- ç¡¬ç¼–ç æ–‡ä»¶è·¯å¾„\n",
    "## âœ… ä¿®å¤åçš„æ ¸å¿ƒæ”¹è¿›\n",
    "1. æ€§èƒ½ä¼˜åŒ–\n",
    "```python\n",
    "# âŒ åŸä»£ç ï¼šæ¯ä¸ªæ–‡ä»¶éƒ½å†™ä¸€æ¬¡\n",
    "for file in files:\n",
    "    # å¤„ç†æ–‡ä»¶...\n",
    "    with open(snapshot_file, \"w\") as f:  # é‡å¤IOï¼\n",
    "        json.dump(snapshot, f)\n",
    "\n",
    "# âœ… ä¿®å¤åï¼šå¤„ç†å®Œæ‰€æœ‰æ–‡ä»¶å†å†™å…¥ä¸€æ¬¡\n",
    "snapshot = {}\n",
    "for file_path in self.monitor_dir.rglob('*'):\n",
    "    # å¤„ç†æ‰€æœ‰æ–‡ä»¶...\n",
    "    snapshot[file_path] = file_info\n",
    "\n",
    "self._save_snapshot(snapshot)  # ä¸€æ¬¡æ€§å†™å…¥a\n",
    "```\n",
    "2. é€»è¾‘ä¿®å¤\n",
    "```python\n",
    "# âŒ åŸä»£ç ï¼šé‡å¤è°ƒç”¨ä¸”é€»è¾‘é”™è¯¯\n",
    "old_snapshot = self.load_snapshot().keys()  # åªæœ‰keys\n",
    "old_snapshot_set = set(self.load_snapshot().keys())  # é‡å¤è°ƒç”¨\n",
    "if old_snapshot[file_path] != new_snapshot[file_path]:  # é”™è¯¯ï¼keysæ— æ³•ç´¢å¼•\n",
    "\n",
    "# âœ… ä¿®å¤åï¼šæ­£ç¡®çš„é€»è¾‘\n",
    "old_snapshot = self.load_snapshot()  # å®Œæ•´æ•°æ®ï¼Œåªè°ƒç”¨ä¸€æ¬¡\n",
    "old_files = set(old_snapshot.keys())\n",
    "new_files = set(new_snapshot.keys())\n",
    "\n",
    "for file_path in common_files:\n",
    "    old_info = old_snapshot[file_path]  # æ­£ç¡®ä½¿ç”¨\n",
    "    new_info = new_snapshot[file_path]\n",
    "    if old_info != new_info:\n",
    "        changes[\"modified\"].add(file_path)\n",
    "```\n",
    "3. åŠŸèƒ½å®Œå–„\n",
    "```python\n",
    "# âŒ åŸä»£ç ï¼šæ¯ä¸ªæ–‡ä»¶éƒ½å†™ä¸€æ¬¡\n",
    "for file in files:\n",
    "    # å¤„ç†æ–‡ä»¶...\n",
    "    with open(snapshot_file, \"w\") as f:  # é‡å¤IOï¼\n",
    "        json.dump(snapshot, f)\n",
    "\n",
    "# âœ… ä¿®å¤åï¼šå¤„ç†å®Œæ‰€æœ‰æ–‡ä»¶å†å†™å…¥ä¸€æ¬¡\n",
    "snapshot = {}\n",
    "for file_path in self.monitor_dir.rglob('*'):\n",
    "    # å¤„ç†æ‰€æœ‰æ–‡ä»¶...\n",
    "    snapshot[file_path] = file_info\n",
    "\n",
    "self._save_snapshot(snapshot)  # ä¸€æ¬¡æ€§å†™å…¥\n",
    "```\n",
    "## ğŸ¯ å­¦ä¹ è¦ç‚¹\n",
    "1. æ€§èƒ½æ„è¯†ï¼šé¿å…åœ¨å¾ªç¯ä¸­è¿›è¡Œé‡å¤çš„IOæ“ä½œ\n",
    "2. é€»è¾‘ä¸¥è°¨ï¼šç¡®ä¿å˜é‡çš„æ•°æ®ç±»å‹å’Œå†…å®¹ä¸ä½¿ç”¨æ–¹å¼åŒ¹é…\n",
    "3. åŠŸèƒ½å®Œæ•´ï¼šæ¯ä¸ªæ–¹æ³•éƒ½åº”è¯¥å®Œæˆå…¶æ‰¿è¯ºçš„åŠŸèƒ½\n",
    "4. ä»£ç è´¨é‡ï¼šä½¿ç”¨ç±»å‹æ³¨è§£ã€åˆç†çš„å¼‚å¸¸å¤„ç†ã€æ¸…æ™°çš„å‘½å\n",
    "\n",
    "æ€è·¯æ˜¯å¯¹çš„ï¼Œä½†å®ç°ç»†èŠ‚ä¸Šæœ‰ä¸å°‘é—®é¢˜ã€‚é€šè¿‡å¯¹æ¯”åŸå§‹ä»£ç å’Œä¿®å¤åçš„ç‰ˆæœ¬ï¼Œå¯ä»¥æ›´å¥½åœ°ç†è§£åç«¯å¼€å‘ä¸­éœ€è¦æ³¨æ„çš„è´¨é‡æ ‡å‡†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¬¬å…­é¢˜ï¼šæ–‡ä»¶ç›‘æ§å™¨ - æ ‡å‡†ç­”æ¡ˆ\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class FileMonitorStandard:\n",
    "    \"\"\"æ–‡ä»¶ç›‘æ§å™¨æ ‡å‡†å®ç° - ç”Ÿäº§çº§åˆ«çš„æ–‡ä»¶å˜åŒ–ç›‘æ§\"\"\"\n",
    "\n",
    "    def __init__(self, monitor_dir):\n",
    "        self.monitor_dir = monitor_dir\n",
    "        self.snapshot_file = \"file_snapshot.json\"\n",
    "        self.log_file = \"file_changes.log\"\n",
    "\n",
    "        # é…ç½®æ—¥å¿—è®°å½•\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "            handlers=[\n",
    "                logging.FileHandler(self.log_file, encoding=\"utf-8\"),\n",
    "                logging.StreamHandler(),\n",
    "            ],\n",
    "        )\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def get_file_info(self, filepath):\n",
    "        \"\"\"è·å–æ–‡ä»¶è¯¦ç»†ä¿¡æ¯\"\"\"\n",
    "        try:\n",
    "            # è·å–ç»å¯¹è·¯å¾„\n",
    "            abs_path = os.path.abspath(filepath)\n",
    "\n",
    "            if not os.path.exists(abs_path):\n",
    "                raise FileNotFoundError(f\"æ–‡ä»¶ä¸å­˜åœ¨: {filepath}\")\n",
    "\n",
    "            # è·å–æ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯\n",
    "            stat_info = os.stat(abs_path)\n",
    "\n",
    "            file_info = {\n",
    "                \"path\": abs_path,\n",
    "                \"size\": stat_info.st_size,  # æ–‡ä»¶å¤§å°(å­—èŠ‚)\n",
    "                \"mtime\": stat_info.st_mtime,  # ä¿®æ”¹æ—¶é—´(æ—¶é—´æˆ³)\n",
    "                \"ctime\": stat_info.st_ctime,  # åˆ›å»ºæ—¶é—´(æ—¶é—´æˆ³)\n",
    "                \"mtime_readable\": datetime.fromtimestamp(\n",
    "                    stat_info.st_mtime\n",
    "                ).isoformat(),\n",
    "                \"ctime_readable\": datetime.fromtimestamp(\n",
    "                    stat_info.st_ctime\n",
    "                ).isoformat(),\n",
    "                \"is_file\": os.path.isfile(abs_path),\n",
    "                \"is_dir\": os.path.isdir(abs_path),\n",
    "            }\n",
    "\n",
    "            return file_info\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥ {filepath}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def take_snapshot(self):\n",
    "        \"\"\"åˆ›å»ºå½“å‰ç›®å½•çŠ¶æ€çš„å¿«ç…§\"\"\"\n",
    "        snapshot = {}\n",
    "\n",
    "        try:\n",
    "            # æ£€æŸ¥ç›‘æ§ç›®å½•æ˜¯å¦å­˜åœ¨\n",
    "            if not os.path.exists(self.monitor_dir):\n",
    "                self.logger.error(f\"ç›‘æ§ç›®å½•ä¸å­˜åœ¨: {self.monitor_dir}\")\n",
    "                return {}\n",
    "\n",
    "            self.logger.info(f\"ğŸ“¸ å¼€å§‹åˆ›å»ºå¿«ç…§: {self.monitor_dir}\")\n",
    "\n",
    "            # éå†ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶\n",
    "            for root, dirs, files in os.walk(self.monitor_dir):\n",
    "                for filename in files:\n",
    "                    file_path = os.path.join(root, filename)\n",
    "                    relative_path = os.path.relpath(file_path, self.monitor_dir)\n",
    "\n",
    "                    # è·å–æ–‡ä»¶ä¿¡æ¯\n",
    "                    file_info = self.get_file_info(file_path)\n",
    "                    if file_info:\n",
    "                        # åªä¿å­˜å¿…è¦ä¿¡æ¯åˆ°å¿«ç…§\n",
    "                        snapshot[relative_path] = {\n",
    "                            \"size\": file_info[\"size\"],\n",
    "                            \"mtime\": file_info[\"mtime\"],\n",
    "                            \"mtime_readable\": file_info[\"mtime_readable\"],\n",
    "                        }\n",
    "\n",
    "            # ä¿å­˜å¿«ç…§åˆ°æ–‡ä»¶\n",
    "            self._save_snapshot(snapshot)\n",
    "\n",
    "            self.logger.info(f\"âœ… å¿«ç…§åˆ›å»ºå®Œæˆï¼ŒåŒ…å« {len(snapshot)} ä¸ªæ–‡ä»¶\")\n",
    "            return snapshot\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"åˆ›å»ºå¿«ç…§å¤±è´¥: {str(e)}\")\n",
    "            return {}\n",
    "\n",
    "    def _save_snapshot(self, snapshot):\n",
    "        \"\"\"ä¿å­˜å¿«ç…§åˆ°JSONæ–‡ä»¶\"\"\"\n",
    "        try:\n",
    "            with open(self.snapshot_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(\n",
    "                    {\"timestamp\": datetime.now().isoformat(), \"files\": snapshot},\n",
    "                    f,\n",
    "                    ensure_ascii=False,\n",
    "                    indent=2,\n",
    "                )\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"ä¿å­˜å¿«ç…§å¤±è´¥: {str(e)}\")\n",
    "\n",
    "    def load_snapshot(self):\n",
    "        \"\"\"åŠ è½½ä¹‹å‰ä¿å­˜çš„å¿«ç…§\"\"\"\n",
    "        try:\n",
    "            if not os.path.exists(self.snapshot_file):\n",
    "                self.logger.info(\"å¿«ç…§æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºæ–°å¿«ç…§\")\n",
    "                return {}\n",
    "\n",
    "            with open(self.snapshot_file, \"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # å…¼å®¹æ—§æ ¼å¼å’Œæ–°æ ¼å¼\n",
    "            if \"files\" in data:\n",
    "                return data[\"files\"]\n",
    "            else:\n",
    "                return data\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"åŠ è½½å¿«ç…§å¤±è´¥: {str(e)}\")\n",
    "            return {}\n",
    "\n",
    "    def detect_changes(self):\n",
    "        \"\"\"æ£€æµ‹æ–‡ä»¶å˜åŒ–\"\"\"\n",
    "        changes = {\n",
    "            \"added\": [],\n",
    "            \"modified\": [],\n",
    "            \"deleted\": [],\n",
    "            \"summary\": {\"total_changes\": 0, \"scan_time\": datetime.now().isoformat()},\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            # 1. åŠ è½½æ—§å¿«ç…§\n",
    "            old_snapshot = self.load_snapshot()\n",
    "\n",
    "            # 2. è·å–å½“å‰å¿«ç…§\n",
    "            current_snapshot = {}\n",
    "            if os.path.exists(self.monitor_dir):\n",
    "                for root, dirs, files in os.walk(self.monitor_dir):\n",
    "                    for filename in files:\n",
    "                        file_path = os.path.join(root, filename)\n",
    "                        relative_path = os.path.relpath(file_path, self.monitor_dir)\n",
    "\n",
    "                        file_info = self.get_file_info(file_path)\n",
    "                        if file_info:\n",
    "                            current_snapshot[relative_path] = {\n",
    "                                \"size\": file_info[\"size\"],\n",
    "                                \"mtime\": file_info[\"mtime\"],\n",
    "                                \"mtime_readable\": file_info[\"mtime_readable\"],\n",
    "                            }\n",
    "\n",
    "            # 3. æ¯”è¾ƒå·®å¼‚\n",
    "            current_files = set(current_snapshot.keys())\n",
    "            old_files = set(old_snapshot.keys())\n",
    "\n",
    "            # æ£€æµ‹æ–°å¢æ–‡ä»¶\n",
    "            added_files = current_files - old_files\n",
    "            for file_path in added_files:\n",
    "                file_info = current_snapshot[file_path]\n",
    "                changes[\"added\"].append(\n",
    "                    {\n",
    "                        \"path\": file_path,\n",
    "                        \"size\": file_info[\"size\"],\n",
    "                        \"mtime\": file_info[\"mtime_readable\"],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            # æ£€æµ‹åˆ é™¤æ–‡ä»¶\n",
    "            deleted_files = old_files - current_files\n",
    "            for file_path in deleted_files:\n",
    "                changes[\"deleted\"].append(\n",
    "                    {\n",
    "                        \"path\": file_path,\n",
    "                        \"last_seen\": old_snapshot[file_path][\"mtime_readable\"],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            # æ£€æµ‹ä¿®æ”¹æ–‡ä»¶\n",
    "            common_files = current_files & old_files\n",
    "            for file_path in common_files:\n",
    "                current_info = current_snapshot[file_path]\n",
    "                old_info = old_snapshot[file_path]\n",
    "\n",
    "                # æ¯”è¾ƒä¿®æ”¹æ—¶é—´æˆ–æ–‡ä»¶å¤§å°\n",
    "                if (\n",
    "                    current_info[\"mtime\"] != old_info[\"mtime\"]\n",
    "                    or current_info[\"size\"] != old_info[\"size\"]\n",
    "                ):\n",
    "                    changes[\"modified\"].append(\n",
    "                        {\n",
    "                            \"path\": file_path,\n",
    "                            \"old_size\": old_info[\"size\"],\n",
    "                            \"new_size\": current_info[\"size\"],\n",
    "                            \"old_mtime\": old_info[\"mtime_readable\"],\n",
    "                            \"new_mtime\": current_info[\"mtime_readable\"],\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "            # æ›´æ–°æ‘˜è¦ä¿¡æ¯\n",
    "            changes[\"summary\"][\"total_changes\"] = (\n",
    "                len(changes[\"added\"])\n",
    "                + len(changes[\"modified\"])\n",
    "                + len(changes[\"deleted\"])\n",
    "            )\n",
    "\n",
    "            return changes\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"æ£€æµ‹å˜åŒ–å¤±è´¥: {str(e)}\")\n",
    "            return changes\n",
    "\n",
    "    def log_changes(self, changes):\n",
    "        \"\"\"è®°å½•å˜åŒ–åˆ°æ—¥å¿—æ–‡ä»¶\"\"\"\n",
    "        try:\n",
    "            if changes[\"summary\"][\"total_changes\"] == 0:\n",
    "                self.logger.info(\"ğŸ” æ–‡ä»¶æ‰«æå®Œæˆï¼Œæœªå‘ç°å˜åŒ–\")\n",
    "                return\n",
    "\n",
    "            self.logger.info(\n",
    "                f\"ğŸš¨ æ£€æµ‹åˆ° {changes['summary']['total_changes']} ä¸ªæ–‡ä»¶å˜åŒ–\"\n",
    "            )\n",
    "\n",
    "            # è®°å½•æ–°å¢æ–‡ä»¶\n",
    "            for file_info in changes[\"added\"]:\n",
    "                self.logger.info(\n",
    "                    f\"â• æ–°å¢æ–‡ä»¶: {file_info['path']} \"\n",
    "                    f\"(å¤§å°: {file_info['size']} å­—èŠ‚)\"\n",
    "                )\n",
    "\n",
    "            # è®°å½•ä¿®æ”¹æ–‡ä»¶\n",
    "            for file_info in changes[\"modified\"]:\n",
    "                size_change = file_info[\"new_size\"] - file_info[\"old_size\"]\n",
    "                size_change_str = (\n",
    "                    f\"+{size_change}\" if size_change > 0 else str(size_change)\n",
    "                )\n",
    "                self.logger.info(\n",
    "                    f\"âœï¸  ä¿®æ”¹æ–‡ä»¶: {file_info['path']} \"\n",
    "                    f\"(å¤§å°å˜åŒ–: {size_change_str} å­—èŠ‚)\"\n",
    "                )\n",
    "\n",
    "            # è®°å½•åˆ é™¤æ–‡ä»¶\n",
    "            for file_info in changes[\"deleted\"]:\n",
    "                self.logger.info(\n",
    "                    f\"ğŸ—‘ï¸  åˆ é™¤æ–‡ä»¶: {file_info['path']} \"\n",
    "                    f\"(æœ€åè§äº: {file_info['last_seen']})\"\n",
    "                )\n",
    "\n",
    "            # ä¿å­˜è¯¦ç»†çš„å˜åŒ–æŠ¥å‘Š\n",
    "            self._save_change_report(changes)\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"è®°å½•å˜åŒ–å¤±è´¥: {str(e)}\")\n",
    "\n",
    "    def _save_change_report(self, changes):\n",
    "        \"\"\"ä¿å­˜è¯¦ç»†çš„å˜åŒ–æŠ¥å‘Šåˆ°JSONæ–‡ä»¶\"\"\"\n",
    "        try:\n",
    "            report_filename = (\n",
    "                f\"change_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "            )\n",
    "            with open(report_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(changes, f, ensure_ascii=False, indent=2)\n",
    "            self.logger.info(f\"ğŸ“„ å˜åŒ–æŠ¥å‘Šå·²ä¿å­˜: {report_filename}\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"ä¿å­˜å˜åŒ–æŠ¥å‘Šå¤±è´¥: {str(e)}\")\n",
    "\n",
    "    def start_monitoring(self, interval=5):\n",
    "        \"\"\"å¼€å§‹æŒç»­ç›‘æ§(ç”Ÿäº§ç¯å¢ƒç”¨)\"\"\"\n",
    "        self.logger.info(f\"ğŸ¯ å¼€å§‹ç›‘æ§ç›®å½•: {self.monitor_dir} (é—´éš”: {interval}ç§’)\")\n",
    "\n",
    "        # åˆ›å»ºåˆå§‹å¿«ç…§\n",
    "        self.take_snapshot()\n",
    "\n",
    "        try:\n",
    "            while True:\n",
    "                time.sleep(interval)\n",
    "                changes = self.detect_changes()\n",
    "                self.log_changes(changes)\n",
    "\n",
    "                # å¦‚æœæœ‰å˜åŒ–ï¼Œæ›´æ–°å¿«ç…§\n",
    "                if changes[\"summary\"][\"total_changes\"] > 0:\n",
    "                    self.take_snapshot()\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            self.logger.info(\"â¹ï¸  ç›‘æ§å·²åœæ­¢\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"ç›‘æ§è¿‡ç¨‹å‡ºé”™: {str(e)}\")\n",
    "\n",
    "\n",
    "# æ¼”ç¤ºå‡½æ•° - æ¨¡æ‹Ÿæ–‡ä»¶ç›‘æ§åœºæ™¯\n",
    "def demo_file_monitor():\n",
    "    \"\"\"æ¼”ç¤ºæ–‡ä»¶ç›‘æ§å™¨çš„å®Œæ•´åŠŸèƒ½\"\"\"\n",
    "    print(\"ğŸ”§ å‡†å¤‡æ–‡ä»¶ç›‘æ§æ¼”ç¤ºç¯å¢ƒ...\")\n",
    "\n",
    "    # åˆ›å»ºç›‘æ§ç›®å½•å’Œæµ‹è¯•æ–‡ä»¶\n",
    "    os.makedirs(\"watch_dir\", exist_ok=True)\n",
    "\n",
    "    # åˆ›å»ºåˆå§‹æµ‹è¯•æ–‡ä»¶\n",
    "    test_files = {\n",
    "        \"document.txt\": \"è¿™æ˜¯ä¸€ä¸ªæ–‡æ¡£æ–‡ä»¶\\nåŒ…å«é‡è¦ä¿¡æ¯\",\n",
    "        \"config.json\": json.dumps({\"app\": \"monitor\", \"version\": \"1.0\"}, indent=2),\n",
    "        \"data/log.txt\": \"åº”ç”¨æ—¥å¿—\\n2024-01-15: åº”ç”¨å¯åŠ¨\",\n",
    "    }\n",
    "\n",
    "    for filepath, content in test_files.items():\n",
    "        full_path = os.path.join(\"watch_dir\", filepath)\n",
    "        os.makedirs(os.path.dirname(full_path), exist_ok=True)\n",
    "        with open(full_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(content)\n",
    "\n",
    "    # åˆå§‹åŒ–æ–‡ä»¶ç›‘æ§å™¨\n",
    "    monitor = FileMonitorStandard(\"watch_dir\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ğŸ“¸ ç¬¬ä¸€æ­¥ï¼šåˆ›å»ºåˆå§‹å¿«ç…§\")\n",
    "    print(\"=\" * 60)\n",
    "    initial_snapshot = monitor.take_snapshot()\n",
    "\n",
    "    print(f\"åˆå§‹å¿«ç…§åŒ…å« {len(initial_snapshot)} ä¸ªæ–‡ä»¶:\")\n",
    "    for filepath, info in initial_snapshot.items():\n",
    "        print(f\"  ğŸ“„ {filepath} - {info['size']} å­—èŠ‚ - {info['mtime_readable']}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ğŸ”„ ç¬¬äºŒæ­¥ï¼šæ¨¡æ‹Ÿæ–‡ä»¶å˜åŒ–\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # ç­‰å¾…1ç§’ç¡®ä¿æ—¶é—´æˆ³ä¸åŒ\n",
    "    time.sleep(1)\n",
    "\n",
    "    # 1. æ–°å¢æ–‡ä»¶\n",
    "    with open(\"watch_dir/new_file.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"è¿™æ˜¯ä¸€ä¸ªæ–°å»ºçš„æ–‡ä»¶\")\n",
    "    print(\"â• æ–°å¢äº†æ–‡ä»¶: new_file.txt\")\n",
    "\n",
    "    # 2. ä¿®æ”¹ç°æœ‰æ–‡ä»¶\n",
    "    with open(\"watch_dir/document.txt\", \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\næ–°å¢çš„å†…å®¹è¡Œ\")\n",
    "    print(\"âœï¸ ä¿®æ”¹äº†æ–‡ä»¶: document.txt\")\n",
    "\n",
    "    # 3. åˆ é™¤æ–‡ä»¶\n",
    "    os.remove(\"watch_dir/data/log.txt\")\n",
    "    print(\"ğŸ—‘ï¸ åˆ é™¤äº†æ–‡ä»¶: data/log.txt\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ğŸ” ç¬¬ä¸‰æ­¥ï¼šæ£€æµ‹æ–‡ä»¶å˜åŒ–\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # æ£€æµ‹å˜åŒ–\n",
    "    changes = monitor.detect_changes()\n",
    "\n",
    "    # æ˜¾ç¤ºæ£€æµ‹ç»“æœ\n",
    "    print(f\"å˜åŒ–æ‘˜è¦:\")\n",
    "    print(f\"  - æ–°å¢æ–‡ä»¶: {len(changes['added'])} ä¸ª\")\n",
    "    print(f\"  - ä¿®æ”¹æ–‡ä»¶: {len(changes['modified'])} ä¸ª\")\n",
    "    print(f\"  - åˆ é™¤æ–‡ä»¶: {len(changes['deleted'])} ä¸ª\")\n",
    "    print(f\"  - æ€»å˜åŒ–æ•°: {changes['summary']['total_changes']} ä¸ª\")\n",
    "\n",
    "    if changes[\"added\"]:\n",
    "        print(f\"\\næ–°å¢æ–‡ä»¶è¯¦æƒ…:\")\n",
    "        for file_info in changes[\"added\"]:\n",
    "            print(f\"  â• {file_info['path']} ({file_info['size']} å­—èŠ‚)\")\n",
    "\n",
    "    if changes[\"modified\"]:\n",
    "        print(f\"\\nä¿®æ”¹æ–‡ä»¶è¯¦æƒ…:\")\n",
    "        for file_info in changes[\"modified\"]:\n",
    "            size_change = file_info[\"new_size\"] - file_info[\"old_size\"]\n",
    "            print(f\"  âœï¸ {file_info['path']} (å¤§å°å˜åŒ–: {size_change:+d} å­—èŠ‚)\")\n",
    "\n",
    "    if changes[\"deleted\"]:\n",
    "        print(f\"\\nåˆ é™¤æ–‡ä»¶è¯¦æƒ…:\")\n",
    "        for file_info in changes[\"deleted\"]:\n",
    "            print(f\"  ğŸ—‘ï¸ {file_info['path']}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ğŸ“ ç¬¬å››æ­¥ï¼šè®°å½•å˜åŒ–æ—¥å¿—\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # è®°å½•å˜åŒ–\n",
    "    monitor.log_changes(changes)\n",
    "\n",
    "    # æ›´æ–°å¿«ç…§\n",
    "    print(f\"\\nğŸ“¸ æ›´æ–°å¿«ç…§...\")\n",
    "    monitor.take_snapshot()\n",
    "\n",
    "    print(f\"\\nğŸ‰ æ–‡ä»¶ç›‘æ§æ¼”ç¤ºå®Œæˆï¼\")\n",
    "    print(f\"ğŸ“„ æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶:\")\n",
    "    print(f\"  - å¿«ç…§æ–‡ä»¶: {monitor.snapshot_file}\")\n",
    "    print(f\"  - æ—¥å¿—æ–‡ä»¶: {monitor.log_file}\")\n",
    "\n",
    "    return monitor\n",
    "\n",
    "\n",
    "# è¿è¡Œæ¼”ç¤º\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ğŸš€ å¼€å§‹è¿è¡Œæ–‡ä»¶ç›‘æ§å™¨æ ‡å‡†ç­”æ¡ˆæ¼”ç¤º...\")\n",
    "    monitor = demo_file_monitor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### ğŸ“š æ ‡å‡†ç­”æ¡ˆè§£æï¼šæ–‡ä»¶ç›‘æ§å™¨æ ¸å¿ƒæ¦‚å¿µè¯¦è§£\n",
    "\n",
    "**ğŸ¯ æ ¸å¿ƒåŠŸèƒ½æ¨¡å—åˆ†æï¼š**\n",
    "\n",
    "#### 1. **æ–‡ä»¶ä¿¡æ¯è·å–** (`get_file_info()`)\n",
    "```python\n",
    "# æ ¸å¿ƒæŠ€æœ¯ï¼šos.stat() è·å–æ–‡ä»¶å…ƒæ•°æ®\n",
    "stat_info = os.stat(abs_path)\n",
    "file_info = {\n",
    "    \"size\": stat_info.st_size,      # æ–‡ä»¶å¤§å°\n",
    "    \"mtime\": stat_info.st_mtime,    # ä¿®æ”¹æ—¶é—´æˆ³\n",
    "    \"ctime\": stat_info.st_ctime,    # åˆ›å»ºæ—¶é—´æˆ³\n",
    "}\n",
    "```\n",
    "**ğŸ’¡ å…³é”®çŸ¥è¯†ç‚¹ï¼š**\n",
    "- `os.stat()` è¿”å›æ–‡ä»¶çš„è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯\n",
    "- `st_mtime` æ˜¯æ£€æµ‹æ–‡ä»¶å˜åŒ–çš„å…³é”®æŒ‡æ ‡\n",
    "- æ—¶é—´æˆ³è½¬æ¢ï¼š`datetime.fromtimestamp()` ä¾¿äºé˜…è¯»\n",
    "\n",
    "#### 2. **å¿«ç…§ç®¡ç†ç®—æ³•** (`take_snapshot()` + `load_snapshot()`)\n",
    "```python\n",
    "# å¿«ç…§åˆ›å»ºï¼šéå† + ä¿¡æ¯æ”¶é›†\n",
    "for root, dirs, files in os.walk(self.monitor_dir):\n",
    "    relative_path = os.path.relpath(file_path, self.monitor_dir)\n",
    "    snapshot[relative_path] = file_info\n",
    "```\n",
    "**ğŸ’¡ ç®—æ³•æ€è·¯ï¼š**\n",
    "- ä½¿ç”¨ `os.walk()` é€’å½’éå†ç›®å½•æ ‘\n",
    "- ä¿å­˜ç›¸å¯¹è·¯å¾„é¿å…ç»å¯¹è·¯å¾„å˜åŒ–å¹²æ‰°\n",
    "- JSONåºåˆ—åŒ–ç¡®ä¿æŒä¹…åŒ–å­˜å‚¨\n",
    "\n",
    "#### 3. **å˜åŒ–æ£€æµ‹æ ¸å¿ƒç®—æ³•** (`detect_changes()`)\n",
    "```python\n",
    "# é›†åˆè¿ç®—æ£€æµ‹æ–‡ä»¶å˜åŒ–\n",
    "current_files = set(current_snapshot.keys())\n",
    "old_files = set(old_snapshot.keys())\n",
    "\n",
    "added_files = current_files - old_files      # æ–°å¢\n",
    "deleted_files = old_files - current_files    # åˆ é™¤\n",
    "common_files = current_files & old_files     # å…±åŒå­˜åœ¨çš„æ–‡ä»¶\n",
    "```\n",
    "**ğŸ’¡ ç®—æ³•ä¼˜åŠ¿ï¼š**\n",
    "- **æ—¶é—´å¤æ‚åº¦**: O(n) - çº¿æ€§æ—¶é—´å¤æ‚åº¦\n",
    "- **ç©ºé—´æ•ˆç‡**: ä½¿ç”¨é›†åˆè¿ç®—ï¼Œé¿å…åµŒå¥—å¾ªç¯\n",
    "- **é€»è¾‘æ¸…æ™°**: åˆ†ç¦»æ–°å¢ã€åˆ é™¤ã€ä¿®æ”¹ä¸‰ç§æƒ…å†µ\n",
    "\n",
    "#### 4. **ç”Ÿäº§çº§æ—¥å¿—ç³»ç»Ÿ** (`loggingæ¨¡å—`)\n",
    "```python\n",
    "# ç»“æ„åŒ–æ—¥å¿—é…ç½®\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(self.log_file, encoding='utf-8'),\n",
    "        logging.StreamHandler()  # åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ–‡ä»¶\n",
    "    ]\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ” **å…³é”®æŠ€æœ¯ç‚¹æ·±åº¦è§£æ**\n",
    "\n",
    "#### **1. æ—¶é—´æˆ³æ¯”è¾ƒç­–ç•¥**\n",
    "```python\n",
    "# ä¸ºä»€ä¹ˆåŒæ—¶æ£€æŸ¥ mtime å’Œ sizeï¼Ÿ\n",
    "if (current_info[\"mtime\"] != old_info[\"mtime\"] or \n",
    "    current_info[\"size\"] != old_info[\"size\"]):\n",
    "```\n",
    "- **ä¿®æ”¹æ—¶é—´**: å¤§éƒ¨åˆ†æƒ…å†µä¸‹è¶³å¤Ÿæ£€æµ‹å˜åŒ–\n",
    "- **æ–‡ä»¶å¤§å°**: é˜²æ­¢æ—¶é—´åŒæ­¥é—®é¢˜æˆ–ç‰¹æ®Šæ–‡ä»¶ç³»ç»Ÿ\n",
    "- **åŒé‡ä¿é™©**: æé«˜æ£€æµ‹å‡†ç¡®æ€§\n",
    "\n",
    "#### **2. ç›¸å¯¹è·¯å¾„å¤„ç†**\n",
    "```python\n",
    "relative_path = os.path.relpath(file_path, self.monitor_dir)\n",
    "```\n",
    "**ä¼˜åŠ¿è¯´æ˜ï¼š**\n",
    "- âœ… ç›®å½•ç§»åŠ¨æ—¶å¿«ç…§ä»ç„¶æœ‰æ•ˆ\n",
    "- âœ… è·¨å¹³å°å…¼å®¹æ€§ï¼ˆWindows/Linuxè·¯å¾„å·®å¼‚ï¼‰\n",
    "- âœ… å‡å°‘å­˜å‚¨ç©ºé—´ï¼ˆè·¯å¾„æ›´çŸ­ï¼‰\n",
    "\n",
    "#### **3. å¼‚å¸¸å¤„ç†å±‚æ¬¡**\n",
    "```python\n",
    "# ä¸‰å±‚å¼‚å¸¸å¤„ç†ç­–ç•¥\n",
    "try:\n",
    "    # å•ä¸ªæ–‡ä»¶æ“ä½œ\n",
    "except Exception as e:\n",
    "    self.logger.error(f\"å•ä¸ªæ–‡ä»¶å¤„ç†å¤±è´¥: {e}\")\n",
    "    continue  # ç»§ç»­å¤„ç†å…¶ä»–æ–‡ä»¶\n",
    "```\n",
    "- **æ–‡ä»¶çº§åˆ«**: å•ä¸ªæ–‡ä»¶å¤±è´¥ä¸å½±å“æ•´ä½“\n",
    "- **æ–¹æ³•çº§åˆ«**: è®°å½•æ–¹æ³•æ‰§è¡ŒçŠ¶æ€\n",
    "- **ç³»ç»Ÿçº§åˆ«**: æ•è·è‡´å‘½é”™è¯¯\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸš€ **ç®—æ³•ä¼˜åŒ–ä¸æ‰©å±•æ€è·¯**\n",
    "\n",
    "#### **1. æ€§èƒ½ä¼˜åŒ–ç­–ç•¥**\n",
    "```python\n",
    "# å¤§ç›®å½•ä¼˜åŒ–ï¼šå¢é‡æ£€æŸ¥\n",
    "def incremental_check(self, file_path):\n",
    "    \\\"\\\"\\\"åªæ£€æŸ¥ä¿®æ”¹æ—¶é—´å¤§äºä¸Šæ¬¡æ‰«æçš„æ–‡ä»¶\\\"\\\"\\\"\n",
    "    last_scan = self.get_last_scan_time()\n",
    "    file_mtime = os.path.getmtime(file_path)\n",
    "    return file_mtime > last_scan\n",
    "```\n",
    "\n",
    "#### **2. å†…å­˜ä¼˜åŒ–ç­–ç•¥**\n",
    "```python\n",
    "# ä½¿ç”¨ç”Ÿæˆå™¨é¿å…å¤§é‡æ–‡ä»¶æ—¶å†…å­˜æº¢å‡º\n",
    "def iter_files(self):\n",
    "    for root, dirs, files in os.walk(self.monitor_dir):\n",
    "        for filename in files:\n",
    "            yield os.path.join(root, filename)\n",
    "```\n",
    "\n",
    "#### **3. å®é™…åº”ç”¨æ‰©å±•**\n",
    "- **æ–‡ä»¶è¿‡æ»¤**: å¿½ç•¥ä¸´æ—¶æ–‡ä»¶ã€éšè—æ–‡ä»¶\n",
    "- **å®æ—¶ç›‘æ§**: ç»“åˆ `watchdog` åº“å®ç°äº‹ä»¶é©±åŠ¨\n",
    "- **ç½‘ç»œåŒæ­¥**: æ£€æµ‹åˆ°å˜åŒ–åè§¦å‘å¤‡ä»½/åŒæ­¥\n",
    "- **å®‰å…¨å®¡è®¡**: ç›‘æ§æ•æ„Ÿæ–‡ä»¶çš„ä¿®æ”¹è®°å½•\n",
    "\n",
    "---\n",
    "\n",
    "### âš ï¸ **å¸¸è§é”™è¯¯åŠé¿å…æ–¹æ³•**\n",
    "\n",
    "| é”™è¯¯ç±»å‹ | å…¸å‹é—®é¢˜ | è§£å†³æ–¹æ¡ˆ |\n",
    "|---------|---------|---------|\n",
    "| **è·¯å¾„é—®é¢˜** | ç¡¬ç¼–ç ç»å¯¹è·¯å¾„ | ä½¿ç”¨ `os.path.relpath()` |\n",
    "| **ç¼–ç é—®é¢˜** | ä¸­æ–‡æ–‡ä»¶åä¹±ç  | ç»Ÿä¸€ä½¿ç”¨ `encoding='utf-8'` |\n",
    "| **æ—¶é—´ç²¾åº¦** | æ¯«ç§’çº§å˜åŒ–æ£€æµ‹ä¸åˆ° | è€ƒè™‘ä½¿ç”¨æ–‡ä»¶å“ˆå¸Œå€¼ |\n",
    "| **å¤§æ–‡ä»¶å¤„ç†** | å†…å­˜å ç”¨è¿‡é«˜ | åˆ†æ‰¹å¤„ç†æˆ–æµå¼è¯»å– |\n",
    "| **å¹¶å‘é—®é¢˜** | æ–‡ä»¶æ­£åœ¨è¢«å†™å…¥ | æ·»åŠ æ–‡ä»¶é”æ£€æŸ¥ |\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ’¡ **å­¦ä¹ è¦ç‚¹æ€»ç»“**\n",
    "\n",
    "1. **æ–‡ä»¶ç³»ç»Ÿç¼–ç¨‹**ï¼šç†Ÿç»ƒä½¿ç”¨ `os.stat()`, `os.walk()`, `os.path` æ¨¡å—\n",
    "2. **æ•°æ®ç»“æ„åº”ç”¨**ï¼šé›†åˆè¿ç®—ä¼˜åŒ–ç®—æ³•æ•ˆç‡\n",
    "3. **çŠ¶æ€ç®¡ç†**ï¼šå¿«ç…§æ¨¡å¼å®ç°çŠ¶æ€æ¯”è¾ƒ\n",
    "4. **é”™è¯¯å¤„ç†**ï¼šåˆ†å±‚å¼‚å¸¸å¤„ç†ç¡®ä¿ç³»ç»Ÿç¨³å®šæ€§\n",
    "5. **æ—¥å¿—ç³»ç»Ÿ**ï¼šç»“æ„åŒ–æ—¥å¿—ä¾¿äºé—®é¢˜æ’æŸ¥\n",
    "6. **æ—¶é—´å¤„ç†**ï¼šæ—¶é—´æˆ³æ¯”è¾ƒå’Œæ ¼å¼åŒ–è½¬æ¢\n",
    "7. **JSONåºåˆ—åŒ–**ï¼šæ•°æ®æŒä¹…åŒ–å’Œè·¨è¯­è¨€å…¼å®¹\n",
    "\n",
    "è¿™ä¸ªå®ç°å±•ç¤ºäº†å¦‚ä½•æ„å»ºä¸€ä¸ª**ç”Ÿäº§çº§åˆ«**çš„æ–‡ä»¶ç›‘æ§ç³»ç»Ÿï¼Œä¸ä»…åŠŸèƒ½å®Œæ•´ï¼Œè¿˜å…·å¤‡è‰¯å¥½çš„å¯æ‰©å±•æ€§å’Œå¥å£®æ€§ï¼ ğŸ¯\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## ğŸš€ ç»™åˆå­¦è€…çš„ç®€åŒ–ç‰ˆæœ¬ - ä»ç®€å•å¼€å§‹ç†è§£\n",
    "\n",
    "### ğŸ’¡ **æ ¸å¿ƒæ€æƒ³å¾ˆç®€å•ï¼šè®°ä½æ–‡ä»¶åˆ—è¡¨ï¼Œä¸‹æ¬¡æ£€æŸ¥æ—¶å¯¹æ¯”å·®å¼‚**\n",
    "\n",
    "**ç¬¬ä¸€æ­¥ï¼šç†è§£æœ€åŸºæœ¬çš„æ¦‚å¿µ**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "ğŸ§ª è¶…ç®€å•æ–‡ä»¶ç›‘æ§å™¨æµ‹è¯•\n",
      "==================================================\n",
      "\n",
      "ç¬¬ä¸€æ¬¡æ£€æŸ¥:\n",
      "ğŸ“¸ ç¬¬ä¸€æ¬¡æ£€æŸ¥ï¼Œè®°å½•å½“å‰æ–‡ä»¶...\n",
      "  ğŸ“„ test1.txt\n",
      "\n",
      "æ·»åŠ æ–°æ–‡ä»¶å:\n",
      "ğŸš¨ å‘ç°æ–‡ä»¶å˜åŒ–!\n",
      "  â• æ–°å¢: test2.txt\n",
      "\n",
      "åˆ é™¤æ–‡ä»¶å:\n",
      "ğŸš¨ å‘ç°æ–‡ä»¶å˜åŒ–!\n",
      "  â– åˆ é™¤: test1.txt\n",
      "\n",
      "å†æ¬¡æ£€æŸ¥(æ— å˜åŒ–):\n",
      "âœ… æ²¡æœ‰æ–‡ä»¶å˜åŒ–\n"
     ]
    }
   ],
   "source": [
    "# ğŸŒ± è¶…çº§ç®€åŒ–ç‰ˆæ–‡ä»¶ç›‘æ§å™¨ - åˆå­¦è€…å‹å¥½ç‰ˆæœ¬\n",
    "import os\n",
    "\n",
    "class SimpleFileMonitor:\n",
    "    \"\"\"è¶…ç®€å•çš„æ–‡ä»¶ç›‘æ§å™¨ - åªå…³æ³¨æ ¸å¿ƒé€»è¾‘\"\"\"\n",
    "    \n",
    "    def __init__(self, folder_path):\n",
    "        self.folder = folder_path\n",
    "        self.old_files = []  # è®°ä½ä¸Šæ¬¡çš„æ–‡ä»¶åˆ—è¡¨\n",
    "    \n",
    "    def get_current_files(self):\n",
    "        \"\"\"è·å–å½“å‰æ–‡ä»¶å¤¹é‡Œçš„æ‰€æœ‰æ–‡ä»¶\"\"\"\n",
    "        if not os.path.exists(self.folder):\n",
    "            print(f\"æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {self.folder}\")\n",
    "            return []\n",
    "        \n",
    "        files = []\n",
    "        for filename in os.listdir(self.folder):\n",
    "            file_path = os.path.join(self.folder, filename)\n",
    "            if os.path.isfile(file_path):  # åªè¦æ–‡ä»¶ï¼Œä¸è¦æ–‡ä»¶å¤¹\n",
    "                files.append(filename)\n",
    "        \n",
    "        return files\n",
    "    \n",
    "    def check_changes(self):\n",
    "        \"\"\"æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æœ‰å˜åŒ–\"\"\"\n",
    "        current_files = self.get_current_files()\n",
    "        \n",
    "        # ç¬¬ä¸€æ¬¡è¿è¡Œï¼Œåªæ˜¯è®°å½•æ–‡ä»¶åˆ—è¡¨\n",
    "        if not self.old_files:\n",
    "            print(\"ğŸ“¸ ç¬¬ä¸€æ¬¡æ£€æŸ¥ï¼Œè®°å½•å½“å‰æ–‡ä»¶...\")\n",
    "            for file in current_files:\n",
    "                print(f\"  ğŸ“„ {file}\")\n",
    "            self.old_files = current_files.copy()\n",
    "            return\n",
    "        \n",
    "        # æ‰¾å‡ºæ–°å¢çš„æ–‡ä»¶\n",
    "        new_files = []\n",
    "        for file in current_files:\n",
    "            if file not in self.old_files:\n",
    "                new_files.append(file)\n",
    "        \n",
    "        # æ‰¾å‡ºåˆ é™¤çš„æ–‡ä»¶\n",
    "        deleted_files = []\n",
    "        for file in self.old_files:\n",
    "            if file not in current_files:\n",
    "                deleted_files.append(file)\n",
    "        \n",
    "        # æ˜¾ç¤ºç»“æœ\n",
    "        if new_files or deleted_files:\n",
    "            print(\"ğŸš¨ å‘ç°æ–‡ä»¶å˜åŒ–!\")\n",
    "            for file in new_files:\n",
    "                print(f\"  â• æ–°å¢: {file}\")\n",
    "            for file in deleted_files:\n",
    "                print(f\"  â– åˆ é™¤: {file}\")\n",
    "        else:\n",
    "            print(\"âœ… æ²¡æœ‰æ–‡ä»¶å˜åŒ–\")\n",
    "        \n",
    "        # æ›´æ–°è®°å½•\n",
    "        self.old_files = current_files.copy()\n",
    "\n",
    "# ğŸ§ª ç®€å•æµ‹è¯•\n",
    "print(\"=\" * 50)\n",
    "print(\"ğŸ§ª è¶…ç®€å•æ–‡ä»¶ç›‘æ§å™¨æµ‹è¯•\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# åˆ›å»ºæµ‹è¯•ç¯å¢ƒ\n",
    "os.makedirs(\"simple_test\", exist_ok=True)\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ªæ–‡ä»¶\n",
    "with open(\"simple_test/test1.txt\", \"w\") as f:\n",
    "    f.write(\"æµ‹è¯•æ–‡ä»¶\")\n",
    "\n",
    "# å¼€å§‹ç›‘æ§\n",
    "monitor = SimpleFileMonitor(\"simple_test\")\n",
    "\n",
    "print(\"\\nç¬¬ä¸€æ¬¡æ£€æŸ¥:\")\n",
    "monitor.check_changes()\n",
    "\n",
    "print(\"\\næ·»åŠ æ–°æ–‡ä»¶å:\")\n",
    "with open(\"simple_test/test2.txt\", \"w\") as f:\n",
    "    f.write(\"æ–°æ–‡ä»¶\")\n",
    "monitor.check_changes()\n",
    "\n",
    "print(\"\\nåˆ é™¤æ–‡ä»¶å:\")\n",
    "os.remove(\"simple_test/test1.txt\")\n",
    "monitor.check_changes()\n",
    "\n",
    "print(\"\\nå†æ¬¡æ£€æŸ¥(æ— å˜åŒ–):\")\n",
    "monitor.check_changes()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### ğŸ¯ **çœ‹åˆ°äº†å—ï¼Ÿæ ¸å¿ƒå°±æ˜¯è¿™ä¹ˆç®€å•ï¼**\n",
    "\n",
    "**ä¸Šé¢50è¡Œä»£ç å°±å®ç°äº†åŸºæœ¬çš„æ–‡ä»¶ç›‘æ§åŠŸèƒ½ï¼š**\n",
    "1. **è®°å½•** æ–‡ä»¶åˆ—è¡¨\n",
    "2. **æ¯”è¾ƒ** æ–°æ—§åˆ—è¡¨  \n",
    "3. **æ‰¾å‡º** å·®å¼‚\n",
    "4. **æ›´æ–°** è®°å½•\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š **ç»™åˆå­¦è€…çš„å¾ªåºæ¸è¿›å­¦ä¹ å»ºè®®**\n",
    "\n",
    "### ğŸŒ± **ç¬¬ä¸€é˜¶æ®µï¼šæŒæ¡åŸºç¡€ (1-2å‘¨)**\n",
    "```python\n",
    "# å…ˆç»ƒä¹ è¿™äº›åŸºæœ¬æ“ä½œ\n",
    "import os\n",
    "\n",
    "# 1. åˆ—å‡ºæ–‡ä»¶å¤¹ä¸­çš„æ–‡ä»¶\n",
    "files = os.listdir(\"æŸä¸ªæ–‡ä»¶å¤¹\")\n",
    "\n",
    "# 2. åˆ¤æ–­æ˜¯æ–‡ä»¶è¿˜æ˜¯æ–‡ä»¶å¤¹\n",
    "os.path.isfile(\"è·¯å¾„\")\n",
    "os.path.isdir(\"è·¯å¾„\")\n",
    "\n",
    "# 3. åˆ—è¡¨æ“ä½œ\n",
    "old_list = [\"a\", \"b\", \"c\"]\n",
    "new_list = [\"a\", \"c\", \"d\"]\n",
    "# æ‰¾æ–°å¢: åœ¨newé‡Œä½†ä¸åœ¨oldé‡Œ\n",
    "# æ‰¾åˆ é™¤: åœ¨oldé‡Œä½†ä¸åœ¨newé‡Œ\n",
    "```\n",
    "\n",
    "### ğŸŒ¿ **ç¬¬äºŒé˜¶æ®µï¼šå¢åŠ åŠŸèƒ½ (1-2å‘¨)**\n",
    "```python\n",
    "# 4. è·å–æ–‡ä»¶ä¿¡æ¯\n",
    "stat_info = os.stat(\"æ–‡ä»¶è·¯å¾„\")\n",
    "file_size = stat_info.st_size\n",
    "modify_time = stat_info.st_mtime\n",
    "\n",
    "# 5. ç®€å•çš„JSONå­˜å‚¨\n",
    "import json\n",
    "data = {\"files\": [\"a.txt\", \"b.txt\"]}\n",
    "with open(\"è®°å½•.json\", \"w\") as f:\n",
    "    json.dump(data, f)\n",
    "```\n",
    "\n",
    "### ğŸŒ³ **ç¬¬ä¸‰é˜¶æ®µï¼šå®Œå–„ç»†èŠ‚ (2-3å‘¨)**\n",
    "```python\n",
    "# 6. å¼‚å¸¸å¤„ç†\n",
    "try:\n",
    "    # æ–‡ä»¶æ“ä½œ\n",
    "except FileNotFoundError:\n",
    "    print(\"æ–‡ä»¶ä¸å­˜åœ¨\")\n",
    "\n",
    "# 7. é€’å½’éå†æ–‡ä»¶å¤¹\n",
    "for root, dirs, files in os.walk(\"æ–‡ä»¶å¤¹\"):\n",
    "    print(files)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’ª **æˆ‘çš„å»ºè®®ï¼šä¸è¦æ°”é¦ï¼**\n",
    "\n",
    "### âœ… **ä½ ç°åœ¨åº”è¯¥åšä»€ä¹ˆï¼š**\n",
    "1. **å…ˆç†è§£ç®€åŒ–ç‰ˆæœ¬** - è¿è¡Œä¸Šé¢çš„ä»£ç ï¼Œçœ‹çœ‹æ•ˆæœ\n",
    "2. **é€ä¸ªå­¦ä¹ æŠ€æœ¯ç‚¹** - ä¸è¦è¯•å›¾ä¸€æ¬¡æ€§ç†è§£æ‰€æœ‰ä¸œè¥¿\n",
    "3. **å¤šç»ƒåŸºç¡€æ“ä½œ** - æ–‡ä»¶æ“ä½œã€åˆ—è¡¨æ¯”è¾ƒç­‰\n",
    "4. **é€æ­¥æ·»åŠ åŠŸèƒ½** - ä»ç®€å•åˆ°å¤æ‚\n",
    "\n",
    "### âŒ **ä¸è¦åšä»€ä¹ˆï¼š**\n",
    "1. **ä¸è¦ä¸€å¼€å§‹å°±çœ‹å¤æ‚ç‰ˆæœ¬** - ä¼šè¢«å“åˆ°\n",
    "2. **ä¸è¦æ€¥äºæ±‚æˆ** - ç¼–ç¨‹éœ€è¦æ—¶é—´ç§¯ç´¯\n",
    "3. **ä¸è¦æ”¾å¼ƒ** - æ¯ä¸ªç¨‹åºå‘˜éƒ½æ˜¯ä»ä¸ä¼šå¼€å§‹çš„\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ **å­¦ä¹ è·¯å¾„å»ºè®®**\n",
    "\n",
    "```\n",
    "ç¬¬1å‘¨: åŸºç¡€æ–‡ä»¶æ“ä½œ (os.listdir, os.path)\n",
    "      â†“\n",
    "ç¬¬2å‘¨: åˆ—è¡¨æ“ä½œå’Œæ¯”è¾ƒé€»è¾‘\n",
    "      â†“  \n",
    "ç¬¬3å‘¨: JSONå­˜å‚¨å’Œè¯»å–\n",
    "      â†“\n",
    "ç¬¬4å‘¨: å¼‚å¸¸å¤„ç†å’Œé”™è¯¯é˜²æŠ¤\n",
    "      â†“\n",
    "ç¬¬5å‘¨: é€’å½’éå†å’Œé«˜çº§åŠŸèƒ½\n",
    "      â†“\n",
    "ç¬¬6å‘¨: æ—¥å¿—ç³»ç»Ÿå’Œä¼˜åŒ–\n",
    "```\n",
    "\n",
    "è®°ä½ï¼š**ç¼–ç¨‹æ˜¯ä¸€ä¸ªæ¸è¿›çš„è¿‡ç¨‹ï¼Œæ²¡æœ‰äººèƒ½ä¸€è¹´è€Œå°±ï¼** å…ˆä»ç®€å•çš„å¼€å§‹ï¼Œé€æ­¥ç§¯ç´¯ç»éªŒã€‚ä½ èƒ½çœ‹æ‡‚ç®€åŒ–ç‰ˆæœ¬ï¼Œå°±å·²ç»ç†è§£äº†æ ¸å¿ƒæ€æƒ³ï¼Œè¿™å°±æ˜¯å¾ˆå¤§çš„è¿›æ­¥ï¼ ğŸ‰\n",
    "\n",
    "ç»§ç»­åŠ æ²¹ï¼Œç›¸ä¿¡è‡ªå·±ï¼ ğŸ’ª\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonç»ƒä¹ ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
