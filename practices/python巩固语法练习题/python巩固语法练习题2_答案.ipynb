{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  第一题  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before strip: \n",
      "after strip: \n",
      "====================\n",
      "before strip: database_host=localhost\n",
      "after strip: database_host=localhost\n",
      "====================\n",
      "key is:database_host,value is:localhost,key的类型:<class 'str'>,value的类型:<class 'str'>\n",
      "value.isdigit() False\n",
      "before strip: database_port=5432\n",
      "after strip: database_port=5432\n",
      "====================\n",
      "key is:database_port,value is:5432,key的类型:<class 'str'>,value的类型:<class 'str'>\n",
      "value.isdigit() True\n",
      "float_val is: 5432.0\n",
      "before strip: database_name=myapp\n",
      "after strip: database_name=myapp\n",
      "====================\n",
      "key is:database_name,value is:myapp,key的类型:<class 'str'>,value的类型:<class 'str'>\n",
      "value.isdigit() False\n",
      "before strip: debug_mode=True\n",
      "after strip: debug_mode=True\n",
      "====================\n",
      "key is:debug_mode,value is:True,key的类型:<class 'str'>,value的类型:<class 'str'>\n",
      "value.isdigit() False\n",
      "before strip: max_connections=100.6\n",
      "after strip: max_connections=100.6\n",
      "====================\n",
      "key is:max_connections,value is:100.6,key的类型:<class 'str'>,value的类型:<class 'str'>\n",
      "value.isdigit() False\n",
      "float_val is: 100.6\n",
      "config is: {'database_host': 'localhost', 'database_port': 5432, 'database_name': 'myapp', 'debug_mode': True, 'max_connections': 100.6}\n",
      "解析结果： {'database_host': 'localhost', 'database_port': 5432, 'database_name': 'myapp', 'debug_mode': True, 'max_connections': 100.6}\n",
      "类型检查：\n",
      "  database_host: localhost (类型: str)\n",
      "  database_port: 5432 (类型: int)\n",
      "  database_name: myapp (类型: str)\n",
      "  debug_mode: True (类型: bool)\n",
      "  max_connections: 100.6 (类型: float)\n"
     ]
    }
   ],
   "source": [
    "# 标准答案\n",
    "def read_config(filename):\n",
    "    \"\"\"读取配置文件并解析为字典\"\"\"\n",
    "    config = {}\n",
    "\n",
    "    try:\n",
    "        with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
    "            for line in file:\n",
    "                print(\"before strip:\", line, end=\"\")\n",
    "                line = line.strip() # 先去除头尾的字符（默认是空格），可以把换行符去除。\n",
    "                print(\"after strip:\", line)\n",
    "                print(\"=\" * 20)\n",
    "                if line and \"=\" in line:\n",
    "                    key, value = line.split(\"=\", 1) # 按照=号截取为一个列表，最多从头开始截取一次，其实我感觉不用写1也可以，因为赋值号只能有一次，但是可能有些字符串包含=号，这么写会健壮一点，只从最开始匹配到的=号开始截取，保险一点。\n",
    "                    print(f'key is:{key},value is:{value},key的类型:{type(key)},value的类型:{type(value)}')\n",
    "                    key = key.strip() # 必须要进行strip操作，因为上面的strip只能去除头尾的空格或其他字符序列，中间的不能去除，比如:data = 12,这样key就是:'data ',注意这里的key的结尾有一个空格，value是' 12',12千米也有一个空格，所以要进行strip操作，strip之后，key为'data',value为'12'\n",
    "                    value = value.strip()\n",
    "\n",
    "                    # 数据类型转换\n",
    "                    print('value.isdigit()',value.isdigit())\n",
    "                    if value.lower() == \"true\":\n",
    "                        config[key] = True\n",
    "                    elif value.lower() == \"false\":\n",
    "                        config[key] = False\n",
    "                    else:\n",
    "                        try:\n",
    "                            float_val = float(value)\n",
    "                            print('float_val is:',float_val)\n",
    "                            if float_val.is_integer():\n",
    "                                config[key] = int(value)\n",
    "                            else:\n",
    "                                config[key] = float_val\n",
    "                        except ValueError:\n",
    "                            config[key] = value\n",
    "    except FileNotFoundError:\n",
    "        print(f\"配置文件 {filename} 不存在\")\n",
    "        return {}\n",
    "    except Exception as e:\n",
    "        print(f\"读取配置文件时出错: {e}\")\n",
    "        return {}\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "# 创建配置文件\n",
    "config_content = \"\"\"\n",
    "database_host=localhost\n",
    "database_port=5432\n",
    "database_name=myapp\n",
    "debug_mode=True\n",
    "max_connections=100.6\n",
    "\"\"\"\n",
    "\n",
    "with open(\"config.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(config_content)\n",
    "\n",
    "\n",
    "# 第二步：编写配置解析器\n",
    "def parse_config(filename):\n",
    "    \"\"\"\n",
    "    解析配置文件并返回字典\n",
    "    支持自动类型转换：整数、布尔值、字符串\n",
    "    \"\"\"\n",
    "    config = {}\n",
    "\n",
    "    # TODO: 在这里实现配置文件读取和解析逻辑\n",
    "    config = read_config(\"config.txt\")\n",
    "    print(\"config is:\", config)\n",
    "    # 提示：\n",
    "    # 1. 打开文件并逐行读取\n",
    "    # 2. 解析键值对（key=value格式）\n",
    "    # 3. 进行类型转换（int、bool、str）\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "# 测试代码\n",
    "if __name__ == \"__main__\":\n",
    "    result = parse_config(\"config.txt\")\n",
    "    print(\"解析结果：\", result)\n",
    "    print(\"类型检查：\")\n",
    "    for key, value in result.items():\n",
    "        print(f\"  {key}: {value} (类型: {type(value).__name__})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 对于上述标准答案的一些地方的理解\n",
    "1. 数据类型转换的逻辑\n",
    "```python\n",
    "# 数据类型转换\n",
    "if value.lower() == \"true\":\n",
    "    config[key] = True\n",
    "elif value.lower() == \"false\":\n",
    "    config[key] = False\n",
    "elif value.isdigit():\n",
    "    config[key] = int(value)\n",
    "else:\n",
    "    config[key] = value\n",
    "```\n",
    "***你可能会有疑问：为什么要`value.lower()`？为什么要和true和false做比较？python中不是写作True或者False吗？***\n",
    "\n",
    "解答：其实这里和什么True和False的写法是没有关系的。value.lower()是在将value转换成全小写，看一下转换成全小写后是不是true，这样能提高配置的灵活性，因为我们这里是在做数据类型的转换，配置的代码中可能会写:data = true，或者data = True，极端的甚至写成data = tRuE，我们直接把=右边的value给lower()了一下，这样不管用户写什么大小写混合的布尔值，都能被识别成全小写的布尔值，假如识别到该布尔值的全小写是true,说明当前这个配置项就是布尔类型的，那么config[key] = True，也就是说解析完之后的config被赋值为True,也就是:data = True。\n",
    "\n",
    "---\n",
    "***你可能又会有疑问：这里的数据类型转换的逻辑为什么是这样？***\n",
    "\n",
    "解答：那我来说下这个转换的逻辑过程，基础数据类型有int,str,bool,float\n",
    "\n",
    "很明显，前两个if判断是用来判断当value为bool类型的时候，当value为纯数字的时候，将它改为int类型（这里不能判断浮点类型，稍后改进），当既不是bool，又不是数字的时候，就直接返回它的类型。\n",
    "\n",
    "***改进：新增对浮点数的判定，让程序更加健壮***\n",
    "```python\n",
    "# 数据类型转换\n",
    "if value.lower() == \"true\":\n",
    "    config[key] = True\n",
    "elif value.lower() == \"false\":\n",
    "    config[key] = False\n",
    "else:\n",
    "    try:\n",
    "        if float(value).is_integer(): # 如果是一个整数。对的，判断是否是整数需要先转换为float才行\n",
    "            config[key] = int(value)\n",
    "        else:\n",
    "            config[key] = float(value)\n",
    "    except ValueError:\n",
    "        config[key] = value\n",
    "```\n",
    "这样就可以正确处理整数和浮点数了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第二题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📋 用户实现问题分析\n",
    "\n",
    "**我的实现中存在以下问题：**\n",
    "\n",
    "1. **`analyze_log_levels()`** - `KeyError原因：字典中还没有该key时第一次访问会报错`，我一直搞错这个，要谨记‼️\n",
    "\n",
    "`关于字典的一些补充：`\n",
    "\n",
    "在 Python 中，当你直接通过 log_dict[key] 访问或设置一个不存在的键时，确实会引发 KeyError 异常。这是因为字典的 `__getitem__` 方法（即 [] 操作符）在设计上要求键必须存在，否则就抛出异常。\n",
    "\n",
    "而 log_dict.get(key, default) 方法则不同，它是专门设计来处理键可能不存在的情况的。它的工作原理是：\n",
    "- 如果键存在，返回对应的值\n",
    "- 如果键不存在，返回你指定的默认值（如果不指定默认值，则返回 None）\n",
    "\n",
    "所以当你使用 log_dict.get(key, 0) 时：\n",
    "- 如果 key 存在，返回它的值\n",
    "- 如果 key 不存在，返回 0 而不会报错\n",
    "\n",
    "这实际上是两种不同的访问策略：\n",
    "\n",
    "- [] 操作符：严格要求键必须存在，适合当你确定键存在时使用\n",
    "- .get() 方法：宽松访问，适合键可能不存在的情况\n",
    "2. **`get_error_messages()`** - 逻辑错误：返回的是非ERROR日志，应该返回ERROR日志  \n",
    "3. **`extract_user_ids()`** - 返回嵌套列表，应该展平为简单列表\n",
    "4. **`hourly_log_count()`** - 小时范围错误：应该是0-23，不是1-24\n",
    "5. **`load_logs()`** - split(\" \")不够健壮，日志消息可能有多个空格\n",
    "\n",
    "下面是标准答案实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 标准答案测试 ===\n",
      "\n",
      "1. 日志级别统计：\n",
      "   INFO: 3\n",
      "   ERROR: 2\n",
      "   WARNING: 1\n",
      "extract_user_ids,matches: ['123']\n",
      "user_ids: ['123']\n",
      "extract_user_ids,matches: []\n",
      "user_ids: ['123']\n",
      "extract_user_ids,matches: ['123']\n",
      "user_ids: ['123', '123']\n",
      "extract_user_ids,matches: []\n",
      "user_ids: ['123', '123']\n",
      "extract_user_ids,matches: ['456']\n",
      "user_ids: ['123', '123', '456']\n",
      "extract_user_ids,matches: []\n",
      "user_ids: ['123', '123', '456']\n",
      "unique_user_ids: ['123', '456'] set: {'456', '123'}\n",
      "\n",
      "2. 用户ID列表： ['123', '456']\n",
      "\n",
      "3. 错误信息：\n",
      "   2024-01-15 10:31:10 ERROR Database connection failed: timeout\n",
      "   2024-01-15 10:35:30 ERROR Authentication failed: invalid_token\n",
      "\n",
      "4. 每小时日志数量：\n",
      "   10点: 6条\n",
      "\n",
      "============================================================\n",
      "==================================================\n",
      "📊 日志分析报告\n",
      "==================================================\n",
      "📁 日志文件：access_standard.log\n",
      "📝 总日志条数：6\n",
      "\n",
      "📈 日志级别统计：\n",
      "dict_items([('INFO', 3), ('ERROR', 2), ('WARNING', 1)])\n",
      "   ERROR: 2 条\n",
      "   INFO: 3 条\n",
      "   WARNING: 1 条\n",
      "extract_user_ids,matches: ['123']\n",
      "user_ids: ['123']\n",
      "extract_user_ids,matches: []\n",
      "user_ids: ['123']\n",
      "extract_user_ids,matches: ['123']\n",
      "user_ids: ['123', '123']\n",
      "extract_user_ids,matches: []\n",
      "user_ids: ['123', '123']\n",
      "extract_user_ids,matches: ['456']\n",
      "user_ids: ['123', '123', '456']\n",
      "extract_user_ids,matches: []\n",
      "user_ids: ['123', '123', '456']\n",
      "unique_user_ids: ['123', '456'] set: {'456', '123'}\n",
      "\n",
      "👥 活跃用户：2 个\n",
      "   用户ID: 123, 456\n",
      "\n",
      "❌ 错误日志：2 条\n",
      "   2024-01-15 10:31:10 ERROR Database connection failed: timeout\n",
      "   2024-01-15 10:35:30 ERROR Authentication failed: invalid_token\n",
      "hourly: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 6, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0, 23: 0}\n",
      "\n",
      "⏰ 活跃时段：\n",
      "   10:00 - 6 条日志\n"
     ]
    }
   ],
   "source": [
    "# 题目2：日志文件分析器 - 标准答案版本\n",
    "\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "from datetime import datetime\n",
    "\n",
    "# 重新创建日志文件（确保数据一致）\n",
    "log_data_standard = \"\"\"\n",
    "2024-01-15 10:30:25 INFO User login successful: user_id=123\n",
    "2024-01-15 10:31:10 ERROR Database connection failed: timeout\n",
    "2024-01-15 10:32:15 INFO User logout: user_id=123\n",
    "2024-01-15 10:33:20 WARNING High memory usage: 85%\n",
    "2024-01-15 10:34:05 INFO User login successful: user_id=456\n",
    "2024-01-15 10:35:30 ERROR Authentication failed: invalid_token\n",
    "\"\"\"\n",
    "\n",
    "with open(\"access_standard.log\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(log_data_standard)\n",
    "\n",
    "\n",
    "class LogAnalyzerStandard:\n",
    "    \"\"\"标准版日志分析器类\"\"\"\n",
    "\n",
    "    def __init__(self, log_file):\n",
    "        self.log_file = log_file\n",
    "        self.logs = []\n",
    "        self.load_logs()\n",
    "\n",
    "    def load_logs(self):\n",
    "        \"\"\"加载日志文件 - 标准实现\"\"\"\n",
    "        try:\n",
    "            with open(self.log_file, \"r\", encoding=\"utf-8\") as f:\n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    if line:  # 跳过空行\n",
    "                        # 使用正则表达式分割，更健壮\n",
    "                        # 格式：日期 时间 级别 消息\n",
    "                        parts = line.split(\n",
    "                            \" \", 3\n",
    "                        )  # 最多分割3次，保持消息完整，得到诸如：['2024-01-15', '10:30:25', 'INFO', 'User login successful: user_id=123']，最后的User login xxx: user_id=xxx是一组的\n",
    "                        # print('parts:',parts)\n",
    "                        if len(parts) >= 4:\n",
    "                            self.logs.append(parts)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"错误：找不到文件 {self.log_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"读取文件时出错：{e}\")\n",
    "\n",
    "    def analyze_log_levels(self):\n",
    "        \"\"\"统计不同日志级别的数量 - 标准实现\"\"\"\n",
    "        # 方法1：使用字典get方法\n",
    "        log_levels = {}\n",
    "        # for log in self.logs:\n",
    "        #     print('log:',log)\n",
    "        #     if len(log) >= 3:\n",
    "        #         level = log[2]\n",
    "        #         log_levels[level] = log_levels.get(level, 0) + 1\n",
    "\n",
    "        # 方法2：使用Counter（更简洁），Counter的括号中是一个生成器表达式\n",
    "        \"\"\"\n",
    "        为什么Counter括号中是一个生成器表达式？并没有出现yield啊？\n",
    "        生成器表达式（Generator Expression）是Python中的一种语法糖，它不需要显式使用yield关键字。它的语法类似于列表推导式，但使用圆括号而不是方括号。\n",
    "        在这个例子中：\n",
    "        Counter(log[2] for log in self.logs if len(log) >= 3)\n",
    "        (log[2] for log in self.logs if len(log) >= 3)就是一个生成器表达式，它会按需生成值，而不是一次性创建整个列表。这比使用列表推导式更节省内存，特别是当处理大量数据时。\n",
    "        生成器表达式和yield的区别在于：\n",
    "        - yield用于定义生成器函数 \n",
    "        - 生成器表达式是一种更简洁的语法，用于创建简单的生成器\n",
    "        两者都能实现惰性计算，但生成器表达式更适用于简单的场景。\n",
    "        \"\"\"\n",
    "        # log_levels = Counter(log[2] for log in self.logs if len(log) >= 3)\n",
    "        # print(\"使用了counter的log_levels:\", log_levels)\n",
    "\n",
    "        # 方法3：使用defaultdict\n",
    "        log_levels = defaultdict(int)\n",
    "        for log in self.logs:\n",
    "            if len(log) >= 3:\n",
    "                log_levels[log[2]] += 1\n",
    "\n",
    "        return dict(log_levels)\n",
    "\n",
    "    def extract_user_ids(self):\n",
    "        \"\"\"提取所有用户ID - 标准实现\"\"\"\n",
    "        user_ids = []\n",
    "        pattern = r\"user_id=(\\d+)\"  # 使用捕获组直接提取数字,⚠️提取的是()内的内容，会得到小括号内的部分，user_id=123 - > 得到：123。我的答案是：r\"user_id=[\\d]+\"，没有分组捕获，无法单独提取数字部分（因为没有括号），会得到整个匹配文本，比如user_id=123\n",
    "\n",
    "        for log in self.logs:\n",
    "            if len(log) >= 4:\n",
    "                message = log[3]\n",
    "                matches = re.findall(pattern, message)\n",
    "                print(\"extract_user_ids,matches:\", matches)\n",
    "                user_ids.extend(matches)  # 直接扩展，避免嵌套列表\n",
    "                print(\"user_ids:\", user_ids)\n",
    "        \"\"\"\n",
    "        这里设置一个名为seen的set只是用来检查是否重复，返回的时候，直接返回这个set不就可以了吗？为什么还要定义一个列表unique_user_ids并返回它？\n",
    "        使用列表而不直接返回seen集合有两个原因：\n",
    "        1. 保持顺序 - 集合（set）是无序的，而列表保持了用户ID首次出现的顺序\n",
    "        2. 保持一致性 - 函数返回值类型应该是可预测的，这里统一返回列表更符合接口设计原则\n",
    "        所以这里用set只是为了O(1)时间复杂度的查重，而返回列表是为了维护顺序和一致性。\n",
    "        \"\"\"\n",
    "        # 去重并保持顺序\n",
    "        seen = set()\n",
    "        unique_user_ids = []\n",
    "        for uid in user_ids:\n",
    "            if uid not in seen:\n",
    "                seen.add(uid)\n",
    "                unique_user_ids.append(uid)\n",
    "        print(\"unique_user_ids:\", unique_user_ids, \"set:\", seen)\n",
    "        return unique_user_ids\n",
    "\n",
    "    def get_error_messages(self):\n",
    "        \"\"\"找出所有错误信息 - 标准实现\"\"\"\n",
    "        error_messages = []\n",
    "\n",
    "        for log in self.logs:\n",
    "            if len(log) >= 3 and log[2] == \"ERROR\":  # 正确的条件\n",
    "                # 重构完整的日志消息\n",
    "                full_message = \" \".join(log)\n",
    "                error_messages.append(full_message)\n",
    "\n",
    "        return error_messages\n",
    "\n",
    "    def hourly_log_count(self):\n",
    "        \"\"\"统计每小时的日志条数 - 标准实现\"\"\"\n",
    "        hourly_count = defaultdict(int)\n",
    "\n",
    "        for log in self.logs:\n",
    "            if len(log) >= 2:\n",
    "                try:\n",
    "                    # 解析时间戳\n",
    "                    timestamp_str = f\"{log[0]} {log[1]}\"\n",
    "                    dt = datetime.strptime(timestamp_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "                    hour = dt.hour  # 0-23\n",
    "                    hourly_count[hour] += 1\n",
    "                except ValueError as e:\n",
    "                    print(f\"时间解析错误：{e}\")\n",
    "\n",
    "        # 转换为标准字典并补充0计数的小时\n",
    "        result = {}\n",
    "        for hour in range(24):  # 0-23小时\n",
    "            result[hour] = hourly_count[hour]\n",
    "\n",
    "        return result\n",
    "\n",
    "    def generate_report(self):\n",
    "        \"\"\"生成完整的分析报告\"\"\"\n",
    "        print(\"=\" * 50)\n",
    "        print(\"📊 日志分析报告\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        # 基本信息\n",
    "        print(f\"📁 日志文件：{self.log_file}\")\n",
    "        print(f\"📝 总日志条数：{len(self.logs)}\")\n",
    "\n",
    "        # 日志级别统计\n",
    "        levels = self.analyze_log_levels()\n",
    "        print(f\"\\n📈 日志级别统计：\")\n",
    "        print((levels.items()))\n",
    "        for level, count in sorted(levels.items()):\n",
    "            print(f\"   {level}: {count} 条\")\n",
    "\n",
    "        # 用户活动\n",
    "        user_ids = self.extract_user_ids()\n",
    "        print(f\"\\n👥 活跃用户：{len(user_ids)} 个\")\n",
    "        print(f\"   用户ID: {', '.join(user_ids)}\")\n",
    "\n",
    "        # 错误信息\n",
    "        errors = self.get_error_messages()\n",
    "        print(f\"\\n❌ 错误日志：{len(errors)} 条\")\n",
    "        for error in errors:\n",
    "            print(f\"   {error}\")\n",
    "\n",
    "        # 时间分布\n",
    "        hourly = self.hourly_log_count()\n",
    "        print('hourly:',hourly)\n",
    "        active_hours = [(hour, count) for hour, count in hourly.items() if count > 0]\n",
    "        print(f\"\\n⏰ 活跃时段：\")\n",
    "        for hour, count in sorted(active_hours):\n",
    "            print(f\"   {hour:02d}:00 - {count} 条日志\")\n",
    "\n",
    "\n",
    "# 测试标准实现\n",
    "print(\"=== 标准答案测试 ===\")\n",
    "analyzer_std = LogAnalyzerStandard(\"access_standard.log\")\n",
    "\n",
    "print(\"\\n1. 日志级别统计：\")\n",
    "levels = analyzer_std.analyze_log_levels()\n",
    "for level, count in levels.items():\n",
    "    print(f\"   {level}: {count}\")\n",
    "\n",
    "print(\"\\n2. 用户ID列表：\", analyzer_std.extract_user_ids())\n",
    "\n",
    "print(\"\\n3. 错误信息：\")\n",
    "errors = analyzer_std.get_error_messages()\n",
    "for error in errors:\n",
    "    print(f\"   {error}\")\n",
    "\n",
    "print(\"\\n4. 每小时日志数量：\")\n",
    "hourly = analyzer_std.hourly_log_count()\n",
    "for hour, count in hourly.items():\n",
    "    if count > 0:  # 只显示有日志的小时\n",
    "        print(f\"   {hour:02d}点: {count}条\")\n",
    "\n",
    "# 生成完整报告\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "analyzer_std.generate_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🔍 对比总结\n",
    "\n",
    "| 功能 | 你的实现 | 标准实现 | 主要区别 |\n",
    "|------|----------|----------|----------|\n",
    "| **load_logs()** | `split(\" \")` | `split(\" \", 3)` | 标准版限制分割次数，保持消息完整 |\n",
    "| **analyze_log_levels()** | try-except处理KeyError | `dict.get(key, 0)` | 标准版更简洁，避免异常 |\n",
    "| **extract_user_ids()** | 返回嵌套列表 | 使用捕获组+extend | 标准版直接提取数字，去重 |\n",
    "| **get_error_messages()** | ❌ `!= \"ERROR\"` | ✅ `== \"ERROR\"` | 你的逻辑相反了 |\n",
    "| **hourly_log_count()** | 小时1-24 | 小时0-23 | 标准版符合实际时间格式 |\n",
    "\n",
    "### 💡 学习要点\n",
    "\n",
    "1. **字典操作**：使用 `dict.get(key, default)` 比 try-except 更简洁\n",
    "2. **正则表达式**：使用捕获组 `(\\d+)` 直接提取需要的部分\n",
    "3. **列表操作**：使用 `extend()` 而不是 `append()` 来展平列表\n",
    "4. **逻辑条件**：仔细理解需求，避免条件写反\n",
    "5. **时间处理**：注意小时是0-23，不是1-24\n",
    "6. **错误处理**：添加适当的异常处理，提高代码健壮性\n",
    "\n",
    "### 🧐 关于标准答案中模块的使用\n",
    "1. `Counter`: [点击查看](../知识点/python模块/collections/Counter.ipynb)\n",
    "\n",
    "### 🧐 关于一些不熟悉的用法\n",
    "1. `分组捕获`: [点击查看](../知识点/正则表达式/关于分组捕获.ipynb)\n",
    "2. `extend`函数: [点击查看](../知识点/函数/python内置函数/关于extend函数.ipynb)\n",
    "3. `sorted`函数: [点击查看](../知识点/函数/python内置函数/关于sorted函数的用法.ipynb)\n",
    "\n",
    "你的基本思路是正确的，只是在一些细节上需要调整！ 🎯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第三题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.employees: [{'姓名': '张三', '部门': '技术部', '工资': 8000, '入职日期': datetime.datetime(2023, 1, 15, 0, 0)}, {'姓名': '李四', '部门': '销售部', '工资': 6000, '入职日期': datetime.datetime(2023, 2, 20, 0, 0)}, {'姓名': '王五', '部门': '技术部', '工资': 9000, '入职日期': datetime.datetime(2022, 12, 10, 0, 0)}, {'姓名': '赵六', '部门': '人事部', '工资': 7000, '入职日期': datetime.datetime(2023, 3, 5, 0, 0)}, {'姓名': '钱七', '部门': '技术部', '工资': 8500, '入职日期': datetime.datetime(2023, 1, 25, 0, 0)}]\n",
      "=== 员工数据分析 ===\n",
      "1. 员工数据：\n",
      "   张三 - 技术部 - 8000元 - 2023-01-15\n",
      "   李四 - 销售部 - 6000元 - 2023-02-20\n",
      "   王五 - 技术部 - 9000元 - 2022-12-10\n",
      "   赵六 - 人事部 - 7000元 - 2023-03-05\n",
      "   钱七 - 技术部 - 8500元 - 2023-01-25\n",
      "\n",
      "2. 部门平均工资：\n",
      "   技术部: 8500.0元\n",
      "   销售部: 6000.0元\n",
      "   人事部: 7000.0元\n",
      "\n",
      "3. 工资极值：\n",
      "   最高工资: 王五 (技术部) - 9000元\n",
      "   最低工资: 李四 (销售部) - 6000元\n",
      "\n",
      "4. 按入职日期排序：\n",
      "sorted_employees:  [{'姓名': '王五', '部门': '技术部', '工资': 9000, '入职日期': datetime.datetime(2022, 12, 10, 0, 0)}, {'姓名': '张三', '部门': '技术部', '工资': 8000, '入职日期': datetime.datetime(2023, 1, 15, 0, 0)}, {'姓名': '钱七', '部门': '技术部', '工资': 8500, '入职日期': datetime.datetime(2023, 1, 25, 0, 0)}, {'姓名': '李四', '部门': '销售部', '工资': 6000, '入职日期': datetime.datetime(2023, 2, 20, 0, 0)}, {'姓名': '赵六', '部门': '人事部', '工资': 7000, '入职日期': datetime.datetime(2023, 3, 5, 0, 0)}]\n",
      "   王五 - 2022-12-10 (技术部)\n",
      "   张三 - 2023-01-15 (技术部)\n",
      "   钱七 - 2023-01-25 (技术部)\n",
      "   李四 - 2023-02-20 (销售部)\n",
      "   赵六 - 2023-03-05 (人事部)\n",
      "数据已保存到 部门平均工资.csv\n",
      "数据已保存到 员工按入职日期排序.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "# 创建示例CSV文件\n",
    "csv_data = \"\"\"\n",
    "姓名,部门,工资,入职日期\n",
    "张三,技术部,8000,2023-01-15\n",
    "李四,销售部,6000,2023-02-20\n",
    "王五,技术部,9000,2022-12-10\n",
    "赵六,人事部,7000,2023-03-05\n",
    "钱七,技术部,8500,2023-01-25\n",
    "\"\"\"\n",
    "\n",
    "with open(\"employees.csv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(csv_data.strip())\n",
    "\n",
    "\n",
    "class EmployeeDataProcessor:\n",
    "    \"\"\"员工数据处理器\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file):\n",
    "        self.csv_file = csv_file\n",
    "        self.employees = []\n",
    "        self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"读取CSV文件并转换为字典列表\"\"\"\n",
    "        try:\n",
    "            with open(self.csv_file, \"r\", encoding=\"utf-8\") as file:\n",
    "                reader = csv.DictReader(file)\n",
    "                self.employees = list(reader)\n",
    "                # 数据类型转换\n",
    "                for employee in self.employees:\n",
    "                    employee[\"工资\"] = int(employee[\"工资\"])\n",
    "                    employee[\"入职日期\"] = datetime.strptime(\n",
    "                        employee[\"入职日期\"], \"%Y-%m-%d\"\n",
    "                    )\n",
    "                print('self.employees:',self.employees)\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"文件未找到: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"读取文件时出错: {e}\")\n",
    "\n",
    "    def calculate_department_avg_salary(self):\n",
    "        \"\"\"计算各部门的平均工资\"\"\"\n",
    "        if not self.employees:\n",
    "            return {}\n",
    "\n",
    "        dept_salaries = defaultdict(list) # 这一步我其实想到了，键是字符串，值是列表，但是后面没写出来\n",
    "\n",
    "        # 按部门分组收集工资\n",
    "        for employee in self.employees:\n",
    "            dept = employee[\"部门\"]\n",
    "            salary = employee[\"工资\"]\n",
    "            dept_salaries[dept].append(salary) # 最关键‼️的其实是这一步，我当时就是不知道怎么把工资加入到defaultdict的后面的列表里，导致卡住\n",
    "\n",
    "        # 计算平均工资\n",
    "        avg_salaries = {}\n",
    "        for dept, salaries in dept_salaries.items():\n",
    "            avg_salaries[dept] = round(sum(salaries) / len(salaries), 2)\n",
    "\n",
    "        return avg_salaries\n",
    "\n",
    "    def find_salary_extremes(self):\n",
    "        \"\"\"找出工资最高和最低的员工\"\"\"\n",
    "        if not self.employees:\n",
    "            return {\"最高\": None, \"最低\": None}\n",
    "\n",
    "        max_employee = max(self.employees, key=lambda x: x[\"工资\"])\n",
    "        min_employee = min(self.employees, key=lambda x: x[\"工资\"])\n",
    "\n",
    "        return {\n",
    "            \"最高\": {\n",
    "                \"姓名\": max_employee[\"姓名\"],\n",
    "                \"部门\": max_employee[\"部门\"],\n",
    "                \"工资\": max_employee[\"工资\"],\n",
    "            },\n",
    "            \"最低\": {\n",
    "                \"姓名\": min_employee[\"姓名\"],\n",
    "                \"部门\": min_employee[\"部门\"],\n",
    "                \"工资\": min_employee[\"工资\"],\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def sort_by_join_date(self):\n",
    "        \"\"\"按入职日期排序\"\"\"\n",
    "        if not self.employees:\n",
    "            return []\n",
    "\n",
    "        sorted_employees = sorted(self.employees, key=lambda x: x[\"入职日期\"])\n",
    "        print('sorted_employees: ',sorted_employees)\n",
    "        # 转换回字符串格式便于显示\n",
    "        result = []\n",
    "        for emp in sorted_employees:\n",
    "            \"\"\"\n",
    "            为什么这里要浅拷贝？\n",
    "            因为我们要修改入职日期的格式。如果不拷贝直接修改原对象，会影响原始数据。\n",
    "            浅拷贝在这里足够用，因为我们只修改第一层的日期值。\n",
    "            \"\"\"\n",
    "            emp_copy = emp.copy()\n",
    "            emp_copy[\"入职日期\"] = emp[\"入职日期\"].strftime(\"%Y-%m-%d\")\n",
    "            result.append(emp_copy)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def save_results(self, filename, data):\n",
    "        \"\"\"将结果保存到新的CSV文件\"\"\"\n",
    "        if not data:\n",
    "            print(\"没有数据需要保存\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "                if isinstance(data, list) and data:\n",
    "                    # 保存员工列表数据\n",
    "                    fieldnames = data[0].keys()\n",
    "                    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "                    writer.writeheader()\n",
    "                    writer.writerows(data)\n",
    "                elif isinstance(data, dict):\n",
    "                    # 保存统计数据（如部门平均工资）\n",
    "                    writer = csv.writer(file)\n",
    "                    writer.writerow([\"部门\", \"平均工资\"])\n",
    "                    for dept, salary in data.items():\n",
    "                        writer.writerow([dept, salary])\n",
    "\n",
    "                print(f\"数据已保存到 {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"保存文件时出错: {e}\")\n",
    "\n",
    "\n",
    "# 测试代码\n",
    "processor = EmployeeDataProcessor(\"employees.csv\")\n",
    "print(\"=== 员工数据分析 ===\")\n",
    "print(\"1. 员工数据：\")\n",
    "for emp in processor.employees:\n",
    "    print(\n",
    "        f\"   {emp['姓名']} - {emp['部门']} - {emp['工资']}元 - {emp['入职日期'].strftime('%Y-%m-%d')}\"\n",
    "    )\n",
    "\n",
    "print(\"\\n2. 部门平均工资：\")\n",
    "avg_salaries = processor.calculate_department_avg_salary()\n",
    "for dept, avg in avg_salaries.items():\n",
    "    print(f\"   {dept}: {avg}元\")\n",
    "\n",
    "print(\"\\n3. 工资极值：\")\n",
    "extremes = processor.find_salary_extremes()\n",
    "print(\n",
    "    f\"   最高工资: {extremes['最高']['姓名']} ({extremes['最高']['部门']}) - {extremes['最高']['工资']}元\"\n",
    ")\n",
    "print(\n",
    "    f\"   最低工资: {extremes['最低']['姓名']} ({extremes['最低']['部门']}) - {extremes['最低']['工资']}元\"\n",
    ")\n",
    "\n",
    "print(\"\\n4. 按入职日期排序：\")\n",
    "sorted_employees = processor.sort_by_join_date()\n",
    "for emp in sorted_employees:\n",
    "    print(f\"   {emp['姓名']} - {emp['入职日期']} ({emp['部门']})\")\n",
    "\n",
    "# 保存结果示例\n",
    "processor.save_results(\"部门平均工资.csv\", avg_salaries)\n",
    "processor.save_results(\"员工按入职日期排序.csv\", sorted_employees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第四题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 📋 第四题解题要点分析\n",
    "\n",
    "**主要考查知识点：**\n",
    "1. **JSON数据处理** - 深层嵌套结构的访问\n",
    "2. **列表推导与过滤** - 活跃用户筛选\n",
    "3. **数据统计计算** - 平均值、分组统计\n",
    "4. **defaultdict使用** - 简化计数逻辑\n",
    "5. **列表成员检查** - `in` 操作符使用\n",
    "\n",
    "**核心解题思路：**\n",
    "\n",
    "#### 1. 数据提取路径\n",
    "```python\n",
    "# 正确的数据访问路径\n",
    "users = json_data[\"data\"][\"users\"]  # 二层嵌套访问\n",
    "```\n",
    "\n",
    "#### 2. 条件过滤技巧\n",
    "```python\n",
    "# 方法1: 传统循环\n",
    "active_users = []\n",
    "for user in users:\n",
    "    if user['is_active']:\n",
    "        active_users.append(user)\n",
    "\n",
    "# 方法2: 列表推导(更简洁)\n",
    "active_users = [user for user in users if user['is_active']]\n",
    "```\n",
    "\n",
    "#### 3. 统计计算模式\n",
    "```python\n",
    "# 累加模式 - 用于平均值计算\n",
    "total_age = sum(user['profile']['age'] for user in users)\n",
    "avg_age = total_age / len(users)\n",
    "\n",
    "# 计数模式 - 用于分组统计\n",
    "dept_counts = defaultdict(int)\n",
    "for user in users:\n",
    "    dept_counts[user['profile']['department']] += 1\n",
    "```\n",
    "\n",
    "#### 4. 列表成员检查\n",
    "```python\n",
    "# 检查列表中是否包含某元素\n",
    "if 'admin' in user['roles']:  # roles是一个列表\n",
    "    admin_users.append(user)\n",
    "```\n",
    "\n",
    "**常见错误避免：**\n",
    "- ❌ 数据访问路径错误：`json_data[\"users\"]` \n",
    "- ✅ 正确路径：`json_data[\"data\"][\"users\"]`\n",
    "- ❌ 忘记处理嵌套结构：`user[\"age\"]`\n",
    "- ✅ 正确访问：`user[\"profile\"][\"age\"]`\n",
    "- ❌ 平均值不处理空列表情况\n",
    "- ✅ 添加防护：`avg_age = total / len(users) if users else 0`\n",
    "\n",
    "**进阶优化技巧：**\n",
    "```python\n",
    "# 使用生成器表达式节省内存\n",
    "ages = (user['profile']['age'] for user in users)\n",
    "avg_age = sum(ages) / len(users)\n",
    "\n",
    "# 使用Counter简化统计\n",
    "from collections import Counter\n",
    "dept_counts = Counter(user['profile']['department'] for user in users)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 题目4：JSON API数据模拟 - 标准答案\n",
    "\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "def process_api_data():\n",
    "    \"\"\"处理API JSON数据\"\"\"\n",
    "    \n",
    "    json_data = {\n",
    "        \"status\": \"success\",\n",
    "        \"data\": {\n",
    "            \"users\": [\n",
    "                {\n",
    "                    \"id\": 1,\n",
    "                    \"username\": \"admin\",\n",
    "                    \"email\": \"admin@example.com\",\n",
    "                    \"roles\": [\"admin\", \"user\"],\n",
    "                    \"profile\": {\n",
    "                        \"first_name\": \"张\",\n",
    "                        \"last_name\": \"三\",\n",
    "                        \"age\": 28,\n",
    "                        \"department\": \"技术部\"\n",
    "                    },\n",
    "                    \"is_active\": True,\n",
    "                    \"last_login\": \"2024-01-15T10:30:00Z\"\n",
    "                },\n",
    "                {\n",
    "                    \"id\": 2,\n",
    "                    \"username\": \"user1\",\n",
    "                    \"email\": \"user1@example.com\",\n",
    "                    \"roles\": [\"user\"],\n",
    "                    \"profile\": {\n",
    "                        \"first_name\": \"李\",\n",
    "                        \"last_name\": \"四\",\n",
    "                        \"age\": 25,\n",
    "                        \"department\": \"销售部\"\n",
    "                    },\n",
    "                    \"is_active\": False,\n",
    "                    \"last_login\": \"2024-01-10T15:20:00Z\"\n",
    "                },\n",
    "                {\n",
    "                    \"id\": 3,\n",
    "                    \"username\": \"user2\",\n",
    "                    \"email\": \"user2@example.com\",\n",
    "                    \"roles\": [\"user\"],\n",
    "                    \"profile\": {\n",
    "                        \"first_name\": \"王\",\n",
    "                        \"last_name\": \"五\",\n",
    "                        \"age\": 28,\n",
    "                        \"department\": \"人事部\"\n",
    "                    },\n",
    "                    \"is_active\": True,\n",
    "                    \"last_login\": \"2024-01-20T12:20:00Z\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # 1. 解析JSON数据\n",
    "    users = json_data[\"data\"][\"users\"]\n",
    "    print(f\"📊 总用户数量: {len(users)}\")\n",
    "    \n",
    "    # 2. 提取所有活跃用户的信息\n",
    "    active_users = []\n",
    "    for user in users:\n",
    "        if user['is_active']:\n",
    "            active_users.append(user)\n",
    "    \n",
    "    print(f\"✅ 活跃用户数量: {len(active_users)}\")\n",
    "    for user in active_users:\n",
    "        print(f\"   - {user['username']} ({user['profile']['first_name']}{user['profile']['last_name']})\")\n",
    "    \n",
    "    # 3. 计算用户平均年龄\n",
    "    total_age = 0\n",
    "    for user in users:\n",
    "        total_age += user['profile']['age']\n",
    "    \n",
    "    avg_age = round(total_age / len(users), 2) if users else 0\n",
    "    print(f\"📈 用户平均年龄: {avg_age} 岁\")\n",
    "    \n",
    "    # 4. 按部门分组统计用户数量\n",
    "    dept_counts = defaultdict(int)\n",
    "    for user in users:\n",
    "        department = user['profile']['department']\n",
    "        dept_counts[department] += 1\n",
    "    \n",
    "    print(f\"🏢 部门用户统计:\")\n",
    "    for dept, count in dept_counts.items():\n",
    "        print(f\"   - {dept}: {count} 人\")\n",
    "    \n",
    "    # 5. 找出拥有admin角色的用户\n",
    "    admin_users = []\n",
    "    for user in users:\n",
    "        if 'admin' in user['roles']:\n",
    "            admin_users.append(user)\n",
    "    \n",
    "    print(f\"👑 管理员用户数量: {len(admin_users)}\")\n",
    "    for admin in admin_users:\n",
    "        print(f\"   - {admin['username']} (角色: {', '.join(admin['roles'])})\")\n",
    "    \n",
    "    return {\n",
    "        \"active_users\": active_users,\n",
    "        \"average_age\": avg_age,\n",
    "        \"department_counts\": dict(dept_counts),\n",
    "        \"admin_users\": admin_users\n",
    "    }\n",
    "\n",
    "\n",
    "# 测试代码\n",
    "result = process_api_data()\n",
    "print(\"\\n=== JSON API数据处理结果摘要 ===\")\n",
    "print(\"活跃用户数量:\", len(result[\"active_users\"]))\n",
    "print(\"用户平均年龄:\", result[\"average_age\"])\n",
    "print(\"部门用户统计:\", result[\"department_counts\"])\n",
    "print(\"管理员用户:\", [user[\"username\"] for user in result[\"admin_users\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# 第五题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 📋 第五题解题要点分析\n",
    "\n",
    "**主要考查知识点：**\n",
    "1. **文件系统操作** - `os`模块的目录和文件操作\n",
    "2. **文件复制** - `shutil`模块的高级文件操作\n",
    "3. **目录遍历** - `os.walk()`递归遍历文件树\n",
    "4. **路径处理** - 相对路径、绝对路径转换\n",
    "5. **时间戳处理** - `datetime`格式化和ISO格式\n",
    "6. **JSON数据处理** - 报告生成和数据序列化\n",
    "7. **异常处理** - 文件操作的错误捕获\n",
    "\n",
    "**核心解题思路：**\n",
    "\n",
    "#### 1. 文件系统基础操作\n",
    "```python\n",
    "# 目录创建\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# 目录存在检查\n",
    "os.path.exists(path)\n",
    "\n",
    "# 文件大小获取\n",
    "os.path.getsize(file_path)\n",
    "\n",
    "# 路径拼接\n",
    "os.path.join(dir1, dir2, filename)\n",
    "```\n",
    "\n",
    "#### 2. 目录遍历技巧\n",
    "```python\n",
    "# os.walk()返回三元组: (当前目录, 子目录列表, 文件列表)\n",
    "for root, dirs, files in os.walk(source_dir):\n",
    "    for filename in files:\n",
    "        full_path = os.path.join(root, filename)\n",
    "        # 计算相对路径保持目录结构\n",
    "        relative_path = os.path.relpath(full_path, source_dir)\n",
    "```\n",
    "\n",
    "#### 3. 文件复制方法选择\n",
    "```python\n",
    "# shutil.copy2() - 推荐，保持文件元数据\n",
    "shutil.copy2(source, destination)\n",
    "\n",
    "# shutil.copy() - 只复制文件内容和权限\n",
    "shutil.copy(source, destination)\n",
    "\n",
    "# shutil.copyfile() - 只复制文件内容\n",
    "shutil.copyfile(source, destination)\n",
    "```\n",
    "\n",
    "#### 4. 时间戳处理模式\n",
    "```python\n",
    "# 生成时间戳后缀\n",
    "timestamp = datetime.now().strftime(\"_%Y%m%d_%H%M%S\")\n",
    "\n",
    "# ISO格式时间(适合JSON)\n",
    "iso_time = datetime.now().isoformat()\n",
    "```\n",
    "\n",
    "#### 5. 文件大小格式化\n",
    "```python\n",
    "def format_size(bytes):\n",
    "    if bytes < 1024:\n",
    "        return f\"{bytes} B\"\n",
    "    elif bytes < 1024**2:\n",
    "        return f\"{bytes/1024:.2f} KB\"\n",
    "    # ... 继续处理MB, GB\n",
    "```\n",
    "\n",
    "**常见错误避免：**\n",
    "- ❌ 不检查源目录存在性就开始备份\n",
    "- ✅ 先验证 `os.path.exists(source_dir)`\n",
    "- ❌ 直接复制到根目录，破坏目录结构\n",
    "- ✅ 使用 `os.path.relpath()` 保持相对路径\n",
    "- ❌ 文件名冲突时覆盖原文件\n",
    "- ✅ 添加时间戳避免冲突\n",
    "- ❌ 忽略单个文件复制失败\n",
    "- ✅ try-except包装每个文件操作\n",
    "\n",
    "**生产级增强功能：**\n",
    "```python\n",
    "# 1. 进度回调\n",
    "def backup_with_progress(self, progress_callback=None):\n",
    "    for i, file_info in enumerate(files):\n",
    "        # 备份文件...\n",
    "        if progress_callback:\n",
    "            progress_callback(i+1, total_files)\n",
    "\n",
    "# 2. 文件过滤\n",
    "def should_backup(self, filename):\n",
    "    # 排除临时文件、隐藏文件等\n",
    "    return not filename.startswith('.') and not filename.endswith('.tmp')\n",
    "\n",
    "# 3. 增量备份\n",
    "def incremental_backup(self):\n",
    "    # 只备份修改时间新于上次备份的文件\n",
    "    pass\n",
    "```\n",
    "\n",
    "**关键学习点：**\n",
    "- 文件操作必须有完整的异常处理\n",
    "- 保持目录结构需要正确处理相对路径\n",
    "- 使用`shutil.copy2()`保持文件元数据\n",
    "- JSON报告便于后续处理和恢复\n",
    "- 时间戳避免文件名冲突\n",
    "- 递归遍历处理嵌套目录结构\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 题目5：数据备份工具 - 代码实现区域\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "\n",
    "class BackupTool:\n",
    "    \"\"\"数据备份工具类\"\"\"\n",
    "\n",
    "    def __init__(self, source_dir, backup_dir):\n",
    "        self.source_dir = source_dir\n",
    "        self.backup_dir = backup_dir\n",
    "        self.backup_report = {\n",
    "            \"backup_time\": None,\n",
    "            \"source_directory\": source_dir,\n",
    "            \"backup_directory\": backup_dir,\n",
    "            \"files_backed_up\": [],\n",
    "            \"total_files\": 0,\n",
    "            \"total_size\": 0,\n",
    "            \"status\": \"pending\",\n",
    "            \"errors\": [],\n",
    "        }\n",
    "    def _format_file_size(self,size_bytes):\n",
    "        \"\"\"格式化文件大小显示\"\"\"\n",
    "        if size_bytes < 1024:\n",
    "            return f'{size_bytes} B'\n",
    "        elif size_bytes < 1024*1024:\n",
    "            return f'{size_bytes / 1024:.2f} KB'\n",
    "        elif size_bytes < 1024*1024*1024:\n",
    "            return f'{size_bytes / (1024*1024):.2f} MB'\n",
    "        else:\n",
    "            return f'{size_bytes / (1024*1024*1024):.2f} GB'    \n",
    "        \n",
    "    def _get_timestamp_suffix(self):\n",
    "        \"\"\"生成时间戳后缀\"\"\"\n",
    "        return datetime.now().strftime(\"_%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    def create_backup(self):\n",
    "        \"\"\"创建备份\"\"\"\n",
    "        # TODO: 实现备份逻辑\n",
    "        # 1. 创建备份目录 -> 不知道怎么搞❌\n",
    "        # 2. 遍历源目录中的文件 -> 用os.walk()?\n",
    "        # 3. 为每个文件添加时间戳后复制到备份目录 -> datetime.now()?\n",
    "        # 4. 计算总大小 -> os模块的某个函数？\n",
    "        # 5. 记录备份信息 -> 记录到self.report\n",
    "        # 重要‼️，要使用try-except\n",
    "        # 以下是抄的标准答案。。。由于自己思考还没用过的模块实在是太费时间，不如直接看答案，背住\n",
    "        try:\n",
    "            # 记录备份开始时间\n",
    "            self.backup_report['backup_time'] = datetime.now().isoformat()\n",
    "            print(f'♻️ 开始备份 :{self.source_dir} -> {self.backup_dir}')\n",
    "\n",
    "            # 1. 检查源目录是否存在\n",
    "            if not os.path.exists(self.source_dir):\n",
    "                error_msg = f'源目录不存在: {self.source_dir}'\n",
    "                self.backup_report['errors'].append(error_msg)\n",
    "                self.backup_report['status'] = 'failed'\n",
    "                print('self.backup_report',self.backup_report)\n",
    "                print(f'❌ {error_msg}')\n",
    "                return False\n",
    "\n",
    "            # 2. 此时说明源目录是存在的，那么开始创建备份目录\n",
    "            os.makedirs(self.backup_dir,exist_ok=True)\n",
    "            print(f'📃 备份目录已经创建: {self.backup_dir}')\n",
    "\n",
    "            # 3. 遍历源目录中的文件\n",
    "            total_size = 0\n",
    "            files_count = 0\n",
    "            timestamp_suffix = self._get_timestamp_suffix()\n",
    "\n",
    "            for root,dirs,files in os.walk(self.source_dir):\n",
    "                print(f'root: {root}') # 当前的源目录，也就是实例传入的第一个参数\n",
    "                print(f'dirs: {dirs}') # 源目录里的子目录，也就是源目录里面包含哪些文件夹\n",
    "                print(f'files: {files}') # 源目录里面包含哪些文件？会自动寻找所有文件，包含嵌套目录中的文件。files:['test1.txt','test2.txt',config.json','nested_file.txt']\n",
    "                for filename in files:\n",
    "                    try:\n",
    "                        # 构建源文件和目标文件路径\n",
    "                        source_file = os.path.join(root,filename)\n",
    "                        print(f'===构建源文件和目标文件路径:{source_file}===') # ===构建源文件和目标文件路径:source_files/test1.txt===\n",
    "                        # 计算相对路径以保持目录结构\n",
    "                        \"\"\"\n",
    "                        保持相对目录结构有什么用？\n",
    "                        \n",
    "                        保持相对目录结构确保备份后的文件组织与源目录完全一致。例如，如果源目录中有 \"subfolder/file.txt\"，备份后也会在备份目录中创建相同的子文件夹结构，而不是将所有文件都平铺在一个目录中，这样便于管理和还原。\n",
    "                        \"\"\"\n",
    "                        relative_path = os.path.relpath(source_file,self.source_dir) # 获取当前源文件和源目录的相对路径，作用是构建backup目录的时候，也能知道对应的文件夹结构，确保嵌套关系的正确\n",
    "                        relative_dir = os.path.dirname(relative_path) # 知道相对路径的文件夹的名字是什么，如果有嵌套就能得到嵌套的文件夹，为了构建正确的文件夹结构而存在\n",
    "                        print(f'===计算相对路径以保持目录结构:{relative_path},当前相对路径中的文件夹的名字是: {relative_dir}===') # ===计算相对路径以保持目录结构:test2.txt,当前相对路径中的文件夹的名字是:=== -> 这个意思是没有文件夹名字\n",
    "                        # 为文件名添加时间戳\n",
    "                        name,ext = os.path.splitext(filename)\n",
    "                        print(f'拆分文件名:\\n{os.path.splitext(filename)}') # 拆分文件名:('test1', '.txt')\n",
    "                        backup_filename = f'{name}{timestamp_suffix}{ext}' # 备份后的文件名\n",
    "\n",
    "                        # 构建完整的备份路径\n",
    "                        backup_subdir = os.path.join(self.backup_dir,relative_dir) if relative_dir else self.backup_dir # 这是一个三元表达式\n",
    "                        os.makedirs(backup_subdir,exist_ok=True)\n",
    "                        backup_file = os.path.join(backup_subdir,backup_filename)\n",
    "\n",
    "                        # 4. 复制文件到备份目录\n",
    "                        shutil.copy2(source_file,backup_file) # copy2保留文件元数据，将source_file中的文件内容，复制到backup_file当中去，保留原来的文件元数据。（有哪些元数据❓）\n",
    "\n",
    "                        # 5. 计算文件大小\n",
    "                        file_size = os.path.getsize(source_file)\n",
    "                        total_size += file_size\n",
    "                        files_count += 1\n",
    "                        print(f'文件大小:{file_size},总大小:{total_size},文件数量:{files_count}')\n",
    "\n",
    "                        # 6. 记录备份信息\n",
    "                        file_info = {\n",
    "                            \"original_name\":relative_path,\n",
    "                            \"backup_name\":os.path.join(relative_dir,backup_filename) if relative_dir else backup_filename, \n",
    "                            \"size\":file_size,\n",
    "                            \"size_formatted\":self._format_file_size(file_size),\n",
    "                            \"backup_time\":datetime.now().isoformat()\n",
    "                        }\n",
    "                        print(f'备份文件信息:\\n{file_info}')\n",
    "                        self.backup_report[\"files_backed_up\"].append(file_info)\n",
    "\n",
    "                        print(f'✅ 已备份: {relative_path} -> {file_info['backup_name']} ({self._format_file_size(file_size)})')\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        error_msg = f\"备份文件失败 {filename}:{str(e)}\"\n",
    "                        self.backup_report['errors'].append(error_msg)\n",
    "                        print(f'❌ {error_msg}')\n",
    "                # 更新报告统计信息\n",
    "            self.backup_report[\"total_files\"] = files_count\n",
    "            self.backup_report[\"total_size\"] = total_size\n",
    "            self.backup_report[\"status\"] = \"success\" if not self.backup_report[\"errors\"] else \"completed_with_errors\"\n",
    "            \n",
    "            print(f\"\\n🎉 备份完成!\")\n",
    "            print(f\"📊 统计信息:\")\n",
    "            print(f\"   - 备份文件数: {files_count}\")\n",
    "            print(f\"   - 总大小: {self._format_file_size(total_size)}\")\n",
    "            print(f\"   - 错误数: {len(self.backup_report['errors'])}\")\n",
    "            \n",
    "            return True\n",
    "        except Exception as e:\n",
    "             error_msg = f\"备份过程出错 :{str(e)}\"\n",
    "             self.backup_report['errors'].append(error_msg)\n",
    "             self.backup_report['status'] = 'failed'\n",
    "             print(f'❌ {error_msg}')\n",
    "             return False\n",
    "\n",
    "    def generate_report(self):\n",
    "        \"\"\"生成备份报告\"\"\"\n",
    "        # TODO: 生成JSON格式的备份报告\n",
    "        # 1. 创建报告文件名（包含时间戳）\n",
    "        # 2. 将备份信息写入JSON文件\n",
    "        # 3. 显示备份统计信息\n",
    "        try:\n",
    "            # 1. 创建报告文件名（包含时间戳）\n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            report_filename = f'backup_report_{timestamp}.json'\n",
    "            report_path = os.path.join(self.backup_dir,report_filename)\n",
    "            print(f'备份报告时间戳:{timestamp}')\n",
    "            print(f'备份报告文件名:{report_filename}')\n",
    "            print(f'备份报告文件路径:{report_path}')\n",
    "            # 2.将备份信息写入json文件\n",
    "            with open(report_path,'w',encoding='utf-8') as f:\n",
    "                json.dump(self.backup_report,f,ensure_ascii=False,indent=2)\n",
    "\n",
    "            # 3. 显示备份统计信息\n",
    "            print(f\"\\n📋 备份报告已生成: {report_filename}\")\n",
    "            print(f\"📄 报告详情:\")\n",
    "            print(f\"   - 备份时间: {self.backup_report['backup_time']}\")\n",
    "            print(f\"   - 源目录: {self.backup_report['source_directory']}\")\n",
    "            print(f\"   - 备份目录: {self.backup_report['backup_directory']}\")\n",
    "            print(f\"   - 文件总数: {self.backup_report['total_files']}\")\n",
    "            print(f\"   - 总大小: {self._format_file_size(self.backup_report['total_size'])}\")\n",
    "            print(f\"   - 状态: {self.backup_report['status']}\")\n",
    "\n",
    "            # 如果有错的话，显示出错误的列表\n",
    "            if self.backup_report['errors']:\n",
    "                print('⚠️ 错误列表:')\n",
    "                for error in self.backup_report['errors']:\n",
    "                    print(f'    - {error}')\n",
    "\n",
    "            # 显示出备份文件列表\n",
    "            if self.backup_report['files_backed_up']:\n",
    "                print(f'\\n文件 备份文件列表')  \n",
    "                print(f\"先输出self.backup_report['files_backed_up']看看:\\n{self.backup_report['files_backed_up']}\") \n",
    "                for file_info in self.backup_report['files_backed_up']:\n",
    "                    print(f'    {file_info['original_name']} -> {file_info['backup_name']} ({file_info['size_formatted']})')\n",
    "            return report_path\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 生成报告失败: {str(e)}\")\n",
    "            return None\n",
    "        \n",
    "    def restore_file(self,backup_filename,restore_path=None):\n",
    "        \"\"\"恢复单个文件\"\"\"\n",
    "        print(f'当前传入的参数是:{backup_filename},{restore_path}')\n",
    "        try:\n",
    "            # 查找备份文件\n",
    "            for file_info in self.backup_report['files_backed_up']:\n",
    "                if file_info['backup_name'] == backup_filename:\n",
    "                    backup_file_path = os.path.join(self.backup_dir,file_info['backup_name'])\n",
    "\n",
    "                    if restore_path is None:\n",
    "                        restore_path = os.path.join(self.source_dir,file_info['original_name'])\n",
    "\n",
    "                    # 确保回复目录存在\n",
    "                    os.makedirs(os.path.dirname(restore_path),exist_ok=True)\n",
    "\n",
    "                    # 复制文件\n",
    "                    shutil.copy2(backup_file_path,restore_path)\n",
    "                    print(f\"✅ 文件已恢复: {backup_filename} -> {restore_path}\")\n",
    "                    return True\n",
    "                \n",
    "            print(f\"❌ 未找到备份文件: {backup_filename}\")\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 恢复文件失败: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "# 示例使用和测试\n",
    "def demo_backup():\n",
    "    \"\"\"演示备份功能\"\"\"\n",
    "    # 创建测试文件\n",
    "    print(\"🔧 准备测试环境...\")\n",
    "    test_files = {\n",
    "        \"test1.txt\": \"这是test1.txt的内容\\n包含多行数据\\n测试备份功能\",\n",
    "        \"test2.txt\": \"这是test2.txt的内容\\n另一个测试文件\",\n",
    "        \"config.json\": json.dumps({\"app_name\": \"backup_tool\", \"version\": \"1.0\", \"settings\": {\"auto_backup\": True}}, ensure_ascii=False, indent=2),\n",
    "        \"subfolder/nested_file.txt\": \"这是嵌套文件夹中的文件\\n测试目录结构保持\"\n",
    "    }\n",
    "    \n",
    "    for filepath, content in test_files.items():\n",
    "        full_path = os.path.join(\"source_files\", filepath) # 比如第一个filepath，得到'source_files/test1.txt',最后一个得到'source_files/subfolder/nested_file.txt',都是得到字符串\n",
    "        print('os.path.dirname(full_path):',os.path.dirname(full_path))\n",
    "        print('full_path is:',full_path)\n",
    "        os.makedirs(os.path.dirname(full_path), exist_ok=True)\n",
    "        with open(full_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(content)\n",
    "    \n",
    "    print(f\"✅ 测试文件已创建\")\n",
    "    \n",
    "    # 执行备份\n",
    "    backup_tool = BackupTool(\"source_files\", \"backup_files\")\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"🚀 开始备份操作\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    success = backup_tool.create_backup()\n",
    "    \n",
    "    if success:\n",
    "        print(f'到这里说明备份已经成功!')\n",
    "        report_path = backup_tool.generate_report()\n",
    "        print(f'备份文件的路径:{report_path}')\n",
    "        # 演示恢复功能\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"🔄 演示文件恢复功能\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        if backup_tool.backup_report[\"files_backed_up\"]:\n",
    "            first_backup = backup_tool.backup_report[\"files_backed_up\"][0]\n",
    "            backup_tool.restore_file(first_backup[\"backup_name\"], \"restored_files/\" + first_backup[\"original_name\"])\n",
    "\n",
    "    \"\"\"\n",
    "    这里为什么要return backup_tool?\n",
    "        返回backup_tool是为了让主程序(if __name__ == \"__main__\")能获取到备份工具实例，这样可以在需要时继续使用这个实例进行其他操作。虽然在这个示例中没有进一步使用，但这是一个良好的编程实践，保持函数的可复用性。\n",
    "    \"\"\"\n",
    "    return backup_tool\n",
    "\n",
    "# 运行演示\n",
    "if __name__ == \"__main__\":\n",
    "    backup_tool = demo_backup()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "create_backup() 函数执行流程\n",
    "├── 1. 初始化\n",
    "│   ├── 记录备份开始时间\n",
    "│   ├── 检查源目录是否存在 ❌→ 返回失败\n",
    "│   └── 创建备份目录\n",
    "├── 2. 遍历文件\n",
    "│   ├── os.walk(source_dir)\n",
    "│   └── 对每个文件执行：\n",
    "│       ├── 构建源文件路径\n",
    "│       ├── 计算相对路径\n",
    "│       ├── 生成带时间戳的文件名\n",
    "│       ├── 创建备份子目录\n",
    "│       ├── 复制文件 (shutil.copy2)\n",
    "│       └── 记录备份文件信息\n",
    "├── 3. 统计和报告\n",
    "│   ├── 更新报告统计\n",
    "│   ├── 设置状态（成功/部分成功）\n",
    "│   └── 显示统计信息\n",
    "└── 4. 返回结果 ✅ True / ❌ False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第六题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📋 你的原始代码问题总结\n",
    "## ❌ 严重问题（影响功能）\n",
    "1. take_snapshot() 方法 - 性能灾难\n",
    "- 在for循环中每处理一个文件就写一次JSON文件\n",
    "- 监控快照文件本身，造成无限循环\n",
    "- 保存过多无用的文件属性信息\n",
    "2. detect_changes() 方法 - 逻辑错误\n",
    "- 重复调用load_snapshot()浪费IO\n",
    "- 变量命名混乱：old_snapshot实际只包含keys\n",
    "- 比较逻辑错误：用keys去索引完整字典\n",
    "3. log_changes() 方法 - 功能缺失\n",
    "- 只是打印变化，没有写入日志文件\n",
    "-缺少时间戳和格式化\n",
    "## ⚠️ 设计问题\n",
    "- 过度使用print()进行调试\n",
    "- 缺少类型注解和文档字符串\n",
    "- 异常处理不够精细\n",
    "- 硬编码文件路径\n",
    "## ✅ 修复后的核心改进\n",
    "1. 性能优化\n",
    "```python\n",
    "# ❌ 原代码：每个文件都写一次\n",
    "for file in files:\n",
    "    # 处理文件...\n",
    "    with open(snapshot_file, \"w\") as f:  # 重复IO！\n",
    "        json.dump(snapshot, f)\n",
    "\n",
    "# ✅ 修复后：处理完所有文件再写入一次\n",
    "snapshot = {}\n",
    "for file_path in self.monitor_dir.rglob('*'):\n",
    "    # 处理所有文件...\n",
    "    snapshot[file_path] = file_info\n",
    "\n",
    "self._save_snapshot(snapshot)  # 一次性写入a\n",
    "```\n",
    "2. 逻辑修复\n",
    "```python\n",
    "# ❌ 原代码：重复调用且逻辑错误\n",
    "old_snapshot = self.load_snapshot().keys()  # 只有keys\n",
    "old_snapshot_set = set(self.load_snapshot().keys())  # 重复调用\n",
    "if old_snapshot[file_path] != new_snapshot[file_path]:  # 错误！keys无法索引\n",
    "\n",
    "# ✅ 修复后：正确的逻辑\n",
    "old_snapshot = self.load_snapshot()  # 完整数据，只调用一次\n",
    "old_files = set(old_snapshot.keys())\n",
    "new_files = set(new_snapshot.keys())\n",
    "\n",
    "for file_path in common_files:\n",
    "    old_info = old_snapshot[file_path]  # 正确使用\n",
    "    new_info = new_snapshot[file_path]\n",
    "    if old_info != new_info:\n",
    "        changes[\"modified\"].add(file_path)\n",
    "```\n",
    "3. 功能完善\n",
    "```python\n",
    "# ❌ 原代码：每个文件都写一次\n",
    "for file in files:\n",
    "    # 处理文件...\n",
    "    with open(snapshot_file, \"w\") as f:  # 重复IO！\n",
    "        json.dump(snapshot, f)\n",
    "\n",
    "# ✅ 修复后：处理完所有文件再写入一次\n",
    "snapshot = {}\n",
    "for file_path in self.monitor_dir.rglob('*'):\n",
    "    # 处理所有文件...\n",
    "    snapshot[file_path] = file_info\n",
    "\n",
    "self._save_snapshot(snapshot)  # 一次性写入\n",
    "```\n",
    "## 🎯 学习要点\n",
    "1. 性能意识：避免在循环中进行重复的IO操作\n",
    "2. 逻辑严谨：确保变量的数据类型和内容与使用方式匹配\n",
    "3. 功能完整：每个方法都应该完成其承诺的功能\n",
    "4. 代码质量：使用类型注解、合理的异常处理、清晰的命名\n",
    "\n",
    "思路是对的，但实现细节上有不少问题。通过对比原始代码和修复后的版本，可以更好地理解后端开发中需要注意的质量标准。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第六题：文件监控器 - 标准答案\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class FileMonitorStandard:\n",
    "    \"\"\"文件监控器标准实现 - 生产级别的文件变化监控\"\"\"\n",
    "\n",
    "    def __init__(self, monitor_dir):\n",
    "        self.monitor_dir = monitor_dir\n",
    "        self.snapshot_file = \"file_snapshot.json\"\n",
    "        self.log_file = \"file_changes.log\"\n",
    "\n",
    "        # 配置日志记录\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "            handlers=[\n",
    "                logging.FileHandler(self.log_file, encoding=\"utf-8\"),\n",
    "                logging.StreamHandler(),\n",
    "            ],\n",
    "        )\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def get_file_info(self, filepath):\n",
    "        \"\"\"获取文件详细信息\"\"\"\n",
    "        try:\n",
    "            # 获取绝对路径\n",
    "            abs_path = os.path.abspath(filepath)\n",
    "\n",
    "            if not os.path.exists(abs_path):\n",
    "                raise FileNotFoundError(f\"文件不存在: {filepath}\")\n",
    "\n",
    "            # 获取文件统计信息\n",
    "            stat_info = os.stat(abs_path)\n",
    "\n",
    "            file_info = {\n",
    "                \"path\": abs_path,\n",
    "                \"size\": stat_info.st_size,  # 文件大小(字节)\n",
    "                \"mtime\": stat_info.st_mtime,  # 修改时间(时间戳)\n",
    "                \"ctime\": stat_info.st_ctime,  # 创建时间(时间戳)\n",
    "                \"mtime_readable\": datetime.fromtimestamp(\n",
    "                    stat_info.st_mtime\n",
    "                ).isoformat(),\n",
    "                \"ctime_readable\": datetime.fromtimestamp(\n",
    "                    stat_info.st_ctime\n",
    "                ).isoformat(),\n",
    "                \"is_file\": os.path.isfile(abs_path),\n",
    "                \"is_dir\": os.path.isdir(abs_path),\n",
    "            }\n",
    "\n",
    "            return file_info\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"获取文件信息失败 {filepath}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def take_snapshot(self):\n",
    "        \"\"\"创建当前目录状态的快照\"\"\"\n",
    "        snapshot = {}\n",
    "\n",
    "        try:\n",
    "            # 检查监控目录是否存在\n",
    "            if not os.path.exists(self.monitor_dir):\n",
    "                self.logger.error(f\"监控目录不存在: {self.monitor_dir}\")\n",
    "                return {}\n",
    "\n",
    "            self.logger.info(f\"📸 开始创建快照: {self.monitor_dir}\")\n",
    "\n",
    "            # 遍历目录中的所有文件\n",
    "            for root, dirs, files in os.walk(self.monitor_dir):\n",
    "                for filename in files:\n",
    "                    file_path = os.path.join(root, filename)\n",
    "                    relative_path = os.path.relpath(file_path, self.monitor_dir)\n",
    "\n",
    "                    # 获取文件信息\n",
    "                    file_info = self.get_file_info(file_path)\n",
    "                    if file_info:\n",
    "                        # 只保存必要信息到快照\n",
    "                        snapshot[relative_path] = {\n",
    "                            \"size\": file_info[\"size\"],\n",
    "                            \"mtime\": file_info[\"mtime\"],\n",
    "                            \"mtime_readable\": file_info[\"mtime_readable\"],\n",
    "                        }\n",
    "\n",
    "            # 保存快照到文件\n",
    "            self._save_snapshot(snapshot)\n",
    "\n",
    "            self.logger.info(f\"✅ 快照创建完成，包含 {len(snapshot)} 个文件\")\n",
    "            return snapshot\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"创建快照失败: {str(e)}\")\n",
    "            return {}\n",
    "\n",
    "    def _save_snapshot(self, snapshot):\n",
    "        \"\"\"保存快照到JSON文件\"\"\"\n",
    "        try:\n",
    "            with open(self.snapshot_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(\n",
    "                    {\"timestamp\": datetime.now().isoformat(), \"files\": snapshot},\n",
    "                    f,\n",
    "                    ensure_ascii=False,\n",
    "                    indent=2,\n",
    "                )\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"保存快照失败: {str(e)}\")\n",
    "\n",
    "    def load_snapshot(self):\n",
    "        \"\"\"加载之前保存的快照\"\"\"\n",
    "        try:\n",
    "            if not os.path.exists(self.snapshot_file):\n",
    "                self.logger.info(\"快照文件不存在，将创建新快照\")\n",
    "                return {}\n",
    "\n",
    "            with open(self.snapshot_file, \"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # 兼容旧格式和新格式\n",
    "            if \"files\" in data:\n",
    "                return data[\"files\"]\n",
    "            else:\n",
    "                return data\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"加载快照失败: {str(e)}\")\n",
    "            return {}\n",
    "\n",
    "    def detect_changes(self):\n",
    "        \"\"\"检测文件变化\"\"\"\n",
    "        changes = {\n",
    "            \"added\": [],\n",
    "            \"modified\": [],\n",
    "            \"deleted\": [],\n",
    "            \"summary\": {\"total_changes\": 0, \"scan_time\": datetime.now().isoformat()},\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            # 1. 加载旧快照\n",
    "            old_snapshot = self.load_snapshot()\n",
    "\n",
    "            # 2. 获取当前快照\n",
    "            current_snapshot = {}\n",
    "            if os.path.exists(self.monitor_dir):\n",
    "                for root, dirs, files in os.walk(self.monitor_dir):\n",
    "                    for filename in files:\n",
    "                        file_path = os.path.join(root, filename)\n",
    "                        relative_path = os.path.relpath(file_path, self.monitor_dir)\n",
    "\n",
    "                        file_info = self.get_file_info(file_path)\n",
    "                        if file_info:\n",
    "                            current_snapshot[relative_path] = {\n",
    "                                \"size\": file_info[\"size\"],\n",
    "                                \"mtime\": file_info[\"mtime\"],\n",
    "                                \"mtime_readable\": file_info[\"mtime_readable\"],\n",
    "                            }\n",
    "\n",
    "            # 3. 比较差异\n",
    "            current_files = set(current_snapshot.keys())\n",
    "            old_files = set(old_snapshot.keys())\n",
    "\n",
    "            # 检测新增文件\n",
    "            added_files = current_files - old_files\n",
    "            for file_path in added_files:\n",
    "                file_info = current_snapshot[file_path]\n",
    "                changes[\"added\"].append(\n",
    "                    {\n",
    "                        \"path\": file_path,\n",
    "                        \"size\": file_info[\"size\"],\n",
    "                        \"mtime\": file_info[\"mtime_readable\"],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            # 检测删除文件\n",
    "            deleted_files = old_files - current_files\n",
    "            for file_path in deleted_files:\n",
    "                changes[\"deleted\"].append(\n",
    "                    {\n",
    "                        \"path\": file_path,\n",
    "                        \"last_seen\": old_snapshot[file_path][\"mtime_readable\"],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            # 检测修改文件\n",
    "            common_files = current_files & old_files\n",
    "            for file_path in common_files:\n",
    "                current_info = current_snapshot[file_path]\n",
    "                old_info = old_snapshot[file_path]\n",
    "\n",
    "                # 比较修改时间或文件大小\n",
    "                if (\n",
    "                    current_info[\"mtime\"] != old_info[\"mtime\"]\n",
    "                    or current_info[\"size\"] != old_info[\"size\"]\n",
    "                ):\n",
    "                    changes[\"modified\"].append(\n",
    "                        {\n",
    "                            \"path\": file_path,\n",
    "                            \"old_size\": old_info[\"size\"],\n",
    "                            \"new_size\": current_info[\"size\"],\n",
    "                            \"old_mtime\": old_info[\"mtime_readable\"],\n",
    "                            \"new_mtime\": current_info[\"mtime_readable\"],\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "            # 更新摘要信息\n",
    "            changes[\"summary\"][\"total_changes\"] = (\n",
    "                len(changes[\"added\"])\n",
    "                + len(changes[\"modified\"])\n",
    "                + len(changes[\"deleted\"])\n",
    "            )\n",
    "\n",
    "            return changes\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"检测变化失败: {str(e)}\")\n",
    "            return changes\n",
    "\n",
    "    def log_changes(self, changes):\n",
    "        \"\"\"记录变化到日志文件\"\"\"\n",
    "        try:\n",
    "            if changes[\"summary\"][\"total_changes\"] == 0:\n",
    "                self.logger.info(\"🔍 文件扫描完成，未发现变化\")\n",
    "                return\n",
    "\n",
    "            self.logger.info(\n",
    "                f\"🚨 检测到 {changes['summary']['total_changes']} 个文件变化\"\n",
    "            )\n",
    "\n",
    "            # 记录新增文件\n",
    "            for file_info in changes[\"added\"]:\n",
    "                self.logger.info(\n",
    "                    f\"➕ 新增文件: {file_info['path']} \"\n",
    "                    f\"(大小: {file_info['size']} 字节)\"\n",
    "                )\n",
    "\n",
    "            # 记录修改文件\n",
    "            for file_info in changes[\"modified\"]:\n",
    "                size_change = file_info[\"new_size\"] - file_info[\"old_size\"]\n",
    "                size_change_str = (\n",
    "                    f\"+{size_change}\" if size_change > 0 else str(size_change)\n",
    "                )\n",
    "                self.logger.info(\n",
    "                    f\"✏️  修改文件: {file_info['path']} \"\n",
    "                    f\"(大小变化: {size_change_str} 字节)\"\n",
    "                )\n",
    "\n",
    "            # 记录删除文件\n",
    "            for file_info in changes[\"deleted\"]:\n",
    "                self.logger.info(\n",
    "                    f\"🗑️  删除文件: {file_info['path']} \"\n",
    "                    f\"(最后见于: {file_info['last_seen']})\"\n",
    "                )\n",
    "\n",
    "            # 保存详细的变化报告\n",
    "            self._save_change_report(changes)\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"记录变化失败: {str(e)}\")\n",
    "\n",
    "    def _save_change_report(self, changes):\n",
    "        \"\"\"保存详细的变化报告到JSON文件\"\"\"\n",
    "        try:\n",
    "            report_filename = (\n",
    "                f\"change_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "            )\n",
    "            with open(report_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(changes, f, ensure_ascii=False, indent=2)\n",
    "            self.logger.info(f\"📄 变化报告已保存: {report_filename}\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"保存变化报告失败: {str(e)}\")\n",
    "\n",
    "    def start_monitoring(self, interval=5):\n",
    "        \"\"\"开始持续监控(生产环境用)\"\"\"\n",
    "        self.logger.info(f\"🎯 开始监控目录: {self.monitor_dir} (间隔: {interval}秒)\")\n",
    "\n",
    "        # 创建初始快照\n",
    "        self.take_snapshot()\n",
    "\n",
    "        try:\n",
    "            while True:\n",
    "                time.sleep(interval)\n",
    "                changes = self.detect_changes()\n",
    "                self.log_changes(changes)\n",
    "\n",
    "                # 如果有变化，更新快照\n",
    "                if changes[\"summary\"][\"total_changes\"] > 0:\n",
    "                    self.take_snapshot()\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            self.logger.info(\"⏹️  监控已停止\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"监控过程出错: {str(e)}\")\n",
    "\n",
    "\n",
    "# 演示函数 - 模拟文件监控场景\n",
    "def demo_file_monitor():\n",
    "    \"\"\"演示文件监控器的完整功能\"\"\"\n",
    "    print(\"🔧 准备文件监控演示环境...\")\n",
    "\n",
    "    # 创建监控目录和测试文件\n",
    "    os.makedirs(\"watch_dir\", exist_ok=True)\n",
    "\n",
    "    # 创建初始测试文件\n",
    "    test_files = {\n",
    "        \"document.txt\": \"这是一个文档文件\\n包含重要信息\",\n",
    "        \"config.json\": json.dumps({\"app\": \"monitor\", \"version\": \"1.0\"}, indent=2),\n",
    "        \"data/log.txt\": \"应用日志\\n2024-01-15: 应用启动\",\n",
    "    }\n",
    "\n",
    "    for filepath, content in test_files.items():\n",
    "        full_path = os.path.join(\"watch_dir\", filepath)\n",
    "        os.makedirs(os.path.dirname(full_path), exist_ok=True)\n",
    "        with open(full_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(content)\n",
    "\n",
    "    # 初始化文件监控器\n",
    "    monitor = FileMonitorStandard(\"watch_dir\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"📸 第一步：创建初始快照\")\n",
    "    print(\"=\" * 60)\n",
    "    initial_snapshot = monitor.take_snapshot()\n",
    "\n",
    "    print(f\"初始快照包含 {len(initial_snapshot)} 个文件:\")\n",
    "    for filepath, info in initial_snapshot.items():\n",
    "        print(f\"  📄 {filepath} - {info['size']} 字节 - {info['mtime_readable']}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"🔄 第二步：模拟文件变化\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # 等待1秒确保时间戳不同\n",
    "    time.sleep(1)\n",
    "\n",
    "    # 1. 新增文件\n",
    "    with open(\"watch_dir/new_file.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"这是一个新建的文件\")\n",
    "    print(\"➕ 新增了文件: new_file.txt\")\n",
    "\n",
    "    # 2. 修改现有文件\n",
    "    with open(\"watch_dir/document.txt\", \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n新增的内容行\")\n",
    "    print(\"✏️ 修改了文件: document.txt\")\n",
    "\n",
    "    # 3. 删除文件\n",
    "    os.remove(\"watch_dir/data/log.txt\")\n",
    "    print(\"🗑️ 删除了文件: data/log.txt\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"🔍 第三步：检测文件变化\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # 检测变化\n",
    "    changes = monitor.detect_changes()\n",
    "\n",
    "    # 显示检测结果\n",
    "    print(f\"变化摘要:\")\n",
    "    print(f\"  - 新增文件: {len(changes['added'])} 个\")\n",
    "    print(f\"  - 修改文件: {len(changes['modified'])} 个\")\n",
    "    print(f\"  - 删除文件: {len(changes['deleted'])} 个\")\n",
    "    print(f\"  - 总变化数: {changes['summary']['total_changes']} 个\")\n",
    "\n",
    "    if changes[\"added\"]:\n",
    "        print(f\"\\n新增文件详情:\")\n",
    "        for file_info in changes[\"added\"]:\n",
    "            print(f\"  ➕ {file_info['path']} ({file_info['size']} 字节)\")\n",
    "\n",
    "    if changes[\"modified\"]:\n",
    "        print(f\"\\n修改文件详情:\")\n",
    "        for file_info in changes[\"modified\"]:\n",
    "            size_change = file_info[\"new_size\"] - file_info[\"old_size\"]\n",
    "            print(f\"  ✏️ {file_info['path']} (大小变化: {size_change:+d} 字节)\")\n",
    "\n",
    "    if changes[\"deleted\"]:\n",
    "        print(f\"\\n删除文件详情:\")\n",
    "        for file_info in changes[\"deleted\"]:\n",
    "            print(f\"  🗑️ {file_info['path']}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"📝 第四步：记录变化日志\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # 记录变化\n",
    "    monitor.log_changes(changes)\n",
    "\n",
    "    # 更新快照\n",
    "    print(f\"\\n📸 更新快照...\")\n",
    "    monitor.take_snapshot()\n",
    "\n",
    "    print(f\"\\n🎉 文件监控演示完成！\")\n",
    "    print(f\"📄 检查生成的文件:\")\n",
    "    print(f\"  - 快照文件: {monitor.snapshot_file}\")\n",
    "    print(f\"  - 日志文件: {monitor.log_file}\")\n",
    "\n",
    "    return monitor\n",
    "\n",
    "\n",
    "# 运行演示\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🚀 开始运行文件监控器标准答案演示...\")\n",
    "    monitor = demo_file_monitor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 📚 标准答案解析：文件监控器核心概念详解\n",
    "\n",
    "**🎯 核心功能模块分析：**\n",
    "\n",
    "#### 1. **文件信息获取** (`get_file_info()`)\n",
    "```python\n",
    "# 核心技术：os.stat() 获取文件元数据\n",
    "stat_info = os.stat(abs_path)\n",
    "file_info = {\n",
    "    \"size\": stat_info.st_size,      # 文件大小\n",
    "    \"mtime\": stat_info.st_mtime,    # 修改时间戳\n",
    "    \"ctime\": stat_info.st_ctime,    # 创建时间戳\n",
    "}\n",
    "```\n",
    "**💡 关键知识点：**\n",
    "- `os.stat()` 返回文件的详细统计信息\n",
    "- `st_mtime` 是检测文件变化的关键指标\n",
    "- 时间戳转换：`datetime.fromtimestamp()` 便于阅读\n",
    "\n",
    "#### 2. **快照管理算法** (`take_snapshot()` + `load_snapshot()`)\n",
    "```python\n",
    "# 快照创建：遍历 + 信息收集\n",
    "for root, dirs, files in os.walk(self.monitor_dir):\n",
    "    relative_path = os.path.relpath(file_path, self.monitor_dir)\n",
    "    snapshot[relative_path] = file_info\n",
    "```\n",
    "**💡 算法思路：**\n",
    "- 使用 `os.walk()` 递归遍历目录树\n",
    "- 保存相对路径避免绝对路径变化干扰\n",
    "- JSON序列化确保持久化存储\n",
    "\n",
    "#### 3. **变化检测核心算法** (`detect_changes()`)\n",
    "```python\n",
    "# 集合运算检测文件变化\n",
    "current_files = set(current_snapshot.keys())\n",
    "old_files = set(old_snapshot.keys())\n",
    "\n",
    "added_files = current_files - old_files      # 新增\n",
    "deleted_files = old_files - current_files    # 删除\n",
    "common_files = current_files & old_files     # 共同存在的文件\n",
    "```\n",
    "**💡 算法优势：**\n",
    "- **时间复杂度**: O(n) - 线性时间复杂度\n",
    "- **空间效率**: 使用集合运算，避免嵌套循环\n",
    "- **逻辑清晰**: 分离新增、删除、修改三种情况\n",
    "\n",
    "#### 4. **生产级日志系统** (`logging模块`)\n",
    "```python\n",
    "# 结构化日志配置\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(self.log_file, encoding='utf-8'),\n",
    "        logging.StreamHandler()  # 同时输出到控制台和文件\n",
    "    ]\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🔍 **关键技术点深度解析**\n",
    "\n",
    "#### **1. 时间戳比较策略**\n",
    "```python\n",
    "# 为什么同时检查 mtime 和 size？\n",
    "if (current_info[\"mtime\"] != old_info[\"mtime\"] or \n",
    "    current_info[\"size\"] != old_info[\"size\"]):\n",
    "```\n",
    "- **修改时间**: 大部分情况下足够检测变化\n",
    "- **文件大小**: 防止时间同步问题或特殊文件系统\n",
    "- **双重保险**: 提高检测准确性\n",
    "\n",
    "#### **2. 相对路径处理**\n",
    "```python\n",
    "relative_path = os.path.relpath(file_path, self.monitor_dir)\n",
    "```\n",
    "**优势说明：**\n",
    "- ✅ 目录移动时快照仍然有效\n",
    "- ✅ 跨平台兼容性（Windows/Linux路径差异）\n",
    "- ✅ 减少存储空间（路径更短）\n",
    "\n",
    "#### **3. 异常处理层次**\n",
    "```python\n",
    "# 三层异常处理策略\n",
    "try:\n",
    "    # 单个文件操作\n",
    "except Exception as e:\n",
    "    self.logger.error(f\"单个文件处理失败: {e}\")\n",
    "    continue  # 继续处理其他文件\n",
    "```\n",
    "- **文件级别**: 单个文件失败不影响整体\n",
    "- **方法级别**: 记录方法执行状态\n",
    "- **系统级别**: 捕获致命错误\n",
    "\n",
    "---\n",
    "\n",
    "### 🚀 **算法优化与扩展思路**\n",
    "\n",
    "#### **1. 性能优化策略**\n",
    "```python\n",
    "# 大目录优化：增量检查\n",
    "def incremental_check(self, file_path):\n",
    "    \\\"\\\"\\\"只检查修改时间大于上次扫描的文件\\\"\\\"\\\"\n",
    "    last_scan = self.get_last_scan_time()\n",
    "    file_mtime = os.path.getmtime(file_path)\n",
    "    return file_mtime > last_scan\n",
    "```\n",
    "\n",
    "#### **2. 内存优化策略**\n",
    "```python\n",
    "# 使用生成器避免大量文件时内存溢出\n",
    "def iter_files(self):\n",
    "    for root, dirs, files in os.walk(self.monitor_dir):\n",
    "        for filename in files:\n",
    "            yield os.path.join(root, filename)\n",
    "```\n",
    "\n",
    "#### **3. 实际应用扩展**\n",
    "- **文件过滤**: 忽略临时文件、隐藏文件\n",
    "- **实时监控**: 结合 `watchdog` 库实现事件驱动\n",
    "- **网络同步**: 检测到变化后触发备份/同步\n",
    "- **安全审计**: 监控敏感文件的修改记录\n",
    "\n",
    "---\n",
    "\n",
    "### ⚠️ **常见错误及避免方法**\n",
    "\n",
    "| 错误类型 | 典型问题 | 解决方案 |\n",
    "|---------|---------|---------|\n",
    "| **路径问题** | 硬编码绝对路径 | 使用 `os.path.relpath()` |\n",
    "| **编码问题** | 中文文件名乱码 | 统一使用 `encoding='utf-8'` |\n",
    "| **时间精度** | 毫秒级变化检测不到 | 考虑使用文件哈希值 |\n",
    "| **大文件处理** | 内存占用过高 | 分批处理或流式读取 |\n",
    "| **并发问题** | 文件正在被写入 | 添加文件锁检查 |\n",
    "\n",
    "---\n",
    "\n",
    "### 💡 **学习要点总结**\n",
    "\n",
    "1. **文件系统编程**：熟练使用 `os.stat()`, `os.walk()`, `os.path` 模块\n",
    "2. **数据结构应用**：集合运算优化算法效率\n",
    "3. **状态管理**：快照模式实现状态比较\n",
    "4. **错误处理**：分层异常处理确保系统稳定性\n",
    "5. **日志系统**：结构化日志便于问题排查\n",
    "6. **时间处理**：时间戳比较和格式化转换\n",
    "7. **JSON序列化**：数据持久化和跨语言兼容\n",
    "\n",
    "这个实现展示了如何构建一个**生产级别**的文件监控系统，不仅功能完整，还具备良好的可扩展性和健壮性！ 🎯\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 🚀 给初学者的简化版本 - 从简单开始理解\n",
    "\n",
    "### 💡 **核心思想很简单：记住文件列表，下次检查时对比差异**\n",
    "\n",
    "**第一步：理解最基本的概念**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "🧪 超简单文件监控器测试\n",
      "==================================================\n",
      "\n",
      "第一次检查:\n",
      "📸 第一次检查，记录当前文件...\n",
      "  📄 test1.txt\n",
      "\n",
      "添加新文件后:\n",
      "🚨 发现文件变化!\n",
      "  ➕ 新增: test2.txt\n",
      "\n",
      "删除文件后:\n",
      "🚨 发现文件变化!\n",
      "  ➖ 删除: test1.txt\n",
      "\n",
      "再次检查(无变化):\n",
      "✅ 没有文件变化\n"
     ]
    }
   ],
   "source": [
    "# 🌱 超级简化版文件监控器 - 初学者友好版本\n",
    "import os\n",
    "\n",
    "class SimpleFileMonitor:\n",
    "    \"\"\"超简单的文件监控器 - 只关注核心逻辑\"\"\"\n",
    "    \n",
    "    def __init__(self, folder_path):\n",
    "        self.folder = folder_path\n",
    "        self.old_files = []  # 记住上次的文件列表\n",
    "    \n",
    "    def get_current_files(self):\n",
    "        \"\"\"获取当前文件夹里的所有文件\"\"\"\n",
    "        if not os.path.exists(self.folder):\n",
    "            print(f\"文件夹不存在: {self.folder}\")\n",
    "            return []\n",
    "        \n",
    "        files = []\n",
    "        for filename in os.listdir(self.folder):\n",
    "            file_path = os.path.join(self.folder, filename)\n",
    "            if os.path.isfile(file_path):  # 只要文件，不要文件夹\n",
    "                files.append(filename)\n",
    "        \n",
    "        return files\n",
    "    \n",
    "    def check_changes(self):\n",
    "        \"\"\"检查文件是否有变化\"\"\"\n",
    "        current_files = self.get_current_files()\n",
    "        \n",
    "        # 第一次运行，只是记录文件列表\n",
    "        if not self.old_files:\n",
    "            print(\"📸 第一次检查，记录当前文件...\")\n",
    "            for file in current_files:\n",
    "                print(f\"  📄 {file}\")\n",
    "            self.old_files = current_files.copy()\n",
    "            return\n",
    "        \n",
    "        # 找出新增的文件\n",
    "        new_files = []\n",
    "        for file in current_files:\n",
    "            if file not in self.old_files:\n",
    "                new_files.append(file)\n",
    "        \n",
    "        # 找出删除的文件\n",
    "        deleted_files = []\n",
    "        for file in self.old_files:\n",
    "            if file not in current_files:\n",
    "                deleted_files.append(file)\n",
    "        \n",
    "        # 显示结果\n",
    "        if new_files or deleted_files:\n",
    "            print(\"🚨 发现文件变化!\")\n",
    "            for file in new_files:\n",
    "                print(f\"  ➕ 新增: {file}\")\n",
    "            for file in deleted_files:\n",
    "                print(f\"  ➖ 删除: {file}\")\n",
    "        else:\n",
    "            print(\"✅ 没有文件变化\")\n",
    "        \n",
    "        # 更新记录\n",
    "        self.old_files = current_files.copy()\n",
    "\n",
    "# 🧪 简单测试\n",
    "print(\"=\" * 50)\n",
    "print(\"🧪 超简单文件监控器测试\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 创建测试环境\n",
    "os.makedirs(\"simple_test\", exist_ok=True)\n",
    "\n",
    "# 创建一个文件\n",
    "with open(\"simple_test/test1.txt\", \"w\") as f:\n",
    "    f.write(\"测试文件\")\n",
    "\n",
    "# 开始监控\n",
    "monitor = SimpleFileMonitor(\"simple_test\")\n",
    "\n",
    "print(\"\\n第一次检查:\")\n",
    "monitor.check_changes()\n",
    "\n",
    "print(\"\\n添加新文件后:\")\n",
    "with open(\"simple_test/test2.txt\", \"w\") as f:\n",
    "    f.write(\"新文件\")\n",
    "monitor.check_changes()\n",
    "\n",
    "print(\"\\n删除文件后:\")\n",
    "os.remove(\"simple_test/test1.txt\")\n",
    "monitor.check_changes()\n",
    "\n",
    "print(\"\\n再次检查(无变化):\")\n",
    "monitor.check_changes()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 🎯 **看到了吗？核心就是这么简单！**\n",
    "\n",
    "**上面50行代码就实现了基本的文件监控功能：**\n",
    "1. **记录** 文件列表\n",
    "2. **比较** 新旧列表  \n",
    "3. **找出** 差异\n",
    "4. **更新** 记录\n",
    "\n",
    "---\n",
    "\n",
    "## 📚 **给初学者的循序渐进学习建议**\n",
    "\n",
    "### 🌱 **第一阶段：掌握基础 (1-2周)**\n",
    "```python\n",
    "# 先练习这些基本操作\n",
    "import os\n",
    "\n",
    "# 1. 列出文件夹中的文件\n",
    "files = os.listdir(\"某个文件夹\")\n",
    "\n",
    "# 2. 判断是文件还是文件夹\n",
    "os.path.isfile(\"路径\")\n",
    "os.path.isdir(\"路径\")\n",
    "\n",
    "# 3. 列表操作\n",
    "old_list = [\"a\", \"b\", \"c\"]\n",
    "new_list = [\"a\", \"c\", \"d\"]\n",
    "# 找新增: 在new里但不在old里\n",
    "# 找删除: 在old里但不在new里\n",
    "```\n",
    "\n",
    "### 🌿 **第二阶段：增加功能 (1-2周)**\n",
    "```python\n",
    "# 4. 获取文件信息\n",
    "stat_info = os.stat(\"文件路径\")\n",
    "file_size = stat_info.st_size\n",
    "modify_time = stat_info.st_mtime\n",
    "\n",
    "# 5. 简单的JSON存储\n",
    "import json\n",
    "data = {\"files\": [\"a.txt\", \"b.txt\"]}\n",
    "with open(\"记录.json\", \"w\") as f:\n",
    "    json.dump(data, f)\n",
    "```\n",
    "\n",
    "### 🌳 **第三阶段：完善细节 (2-3周)**\n",
    "```python\n",
    "# 6. 异常处理\n",
    "try:\n",
    "    # 文件操作\n",
    "except FileNotFoundError:\n",
    "    print(\"文件不存在\")\n",
    "\n",
    "# 7. 递归遍历文件夹\n",
    "for root, dirs, files in os.walk(\"文件夹\"):\n",
    "    print(files)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 💪 **我的建议：不要气馁！**\n",
    "\n",
    "### ✅ **你现在应该做什么：**\n",
    "1. **先理解简化版本** - 运行上面的代码，看看效果\n",
    "2. **逐个学习技术点** - 不要试图一次性理解所有东西\n",
    "3. **多练基础操作** - 文件操作、列表比较等\n",
    "4. **逐步添加功能** - 从简单到复杂\n",
    "\n",
    "### ❌ **不要做什么：**\n",
    "1. **不要一开始就看复杂版本** - 会被吓到\n",
    "2. **不要急于求成** - 编程需要时间积累\n",
    "3. **不要放弃** - 每个程序员都是从不会开始的\n",
    "\n",
    "---\n",
    "\n",
    "## 🎓 **学习路径建议**\n",
    "\n",
    "```\n",
    "第1周: 基础文件操作 (os.listdir, os.path)\n",
    "      ↓\n",
    "第2周: 列表操作和比较逻辑\n",
    "      ↓  \n",
    "第3周: JSON存储和读取\n",
    "      ↓\n",
    "第4周: 异常处理和错误防护\n",
    "      ↓\n",
    "第5周: 递归遍历和高级功能\n",
    "      ↓\n",
    "第6周: 日志系统和优化\n",
    "```\n",
    "\n",
    "记住：**编程是一个渐进的过程，没有人能一蹴而就！** 先从简单的开始，逐步积累经验。你能看懂简化版本，就已经理解了核心思想，这就是很大的进步！ 🎉\n",
    "\n",
    "继续加油，相信自己！ 💪\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python练习",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
