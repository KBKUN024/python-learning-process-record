# Pythonè¯­æ³•å·©å›ºç»ƒä¹ é¢˜2ç­”æ¡ˆè¯¦è§£

## æ–‡ä»¶æ“ä½œä¸æ•°æ®å¤„ç†ï¼ˆ1-7é¢˜ï¼‰

### é¢˜ç›®1ï¼šé…ç½®æ–‡ä»¶è¯»å–å™¨

```python
def read_config(filename):
    """è¯»å–é…ç½®æ–‡ä»¶å¹¶è§£æä¸ºå­—å…¸"""
    config = {}
    
    try:
        with open(filename, 'r', encoding='utf-8') as file:
            for line in file:
                line = line.strip()
                if line and '=' in line:
                    key, value = line.split('=', 1)
                    key = key.strip()
                    value = value.strip()
                    
                    # æ•°æ®ç±»å‹è½¬æ¢
                    if value.lower() == 'true':
                        config[key] = True
                    elif value.lower() == 'false':
                        config[key] = False
                    elif value.isdigit():
                        config[key] = int(value)
                    else:
                        config[key] = value
    except FileNotFoundError:
        print(f"é…ç½®æ–‡ä»¶ {filename} ä¸å­˜åœ¨")
        return {}
    except Exception as e:
        print(f"è¯»å–é…ç½®æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return {}
    
    return config

# åˆ›å»ºé…ç½®æ–‡ä»¶
config_content = """database_host=localhost
database_port=5432
database_name=myapp
debug_mode=True
max_connections=100"""

with open('config.txt', 'w', encoding='utf-8') as f:
    f.write(config_content)

# è¯»å–å¹¶è§£æé…ç½®
config = read_config('config.txt')
print(config)
```

### é¢˜ç›®2ï¼šæ—¥å¿—æ–‡ä»¶åˆ†æå™¨

```python
import re
from collections import defaultdict, Counter
from datetime import datetime

def analyze_log_file(log_content):
    """åˆ†ææ—¥å¿—æ–‡ä»¶"""
    lines = log_content.strip().split('\n')
    
    # ç»Ÿè®¡æ•°æ®
    level_counts = Counter()
    user_ids = set()
    errors = []
    hour_counts = defaultdict(int)
    
    for line in lines:
        # è§£ææ—¥å¿—è¡Œ
        parts = line.split(' ', 3)
        if len(parts) >= 4:
            date_str = parts[0]
            time_str = parts[1]
            level = parts[2]
            message = parts[3]
            
            # ç»Ÿè®¡æ—¥å¿—çº§åˆ«
            level_counts[level] += 1
            
            # æå–ç”¨æˆ·ID
            user_id_match = re.search(r'user_id=(\d+)', message)
            if user_id_match:
                user_ids.add(int(user_id_match.group(1)))
            
            # æ”¶é›†é”™è¯¯ä¿¡æ¯
            if level == 'ERROR':
                errors.append(message)
            
            # ç»Ÿè®¡æ¯å°æ—¶æ—¥å¿—æ•°
            hour = int(time_str.split(':')[0])
            hour_counts[hour] += 1
    
    return {
        'level_counts': dict(level_counts),
        'user_ids': sorted(list(user_ids)),
        'errors': errors,
        'hour_counts': dict(hour_counts)
    }

# æµ‹è¯•æ—¥å¿—å†…å®¹
log_content = """2024-01-15 10:30:25 INFO User login successful: user_id=123
2024-01-15 10:31:10 ERROR Database connection failed: timeout
2024-01-15 10:32:15 INFO User logout: user_id=123
2024-01-15 10:33:20 WARNING High memory usage: 85%
2024-01-15 10:34:05 INFO User login successful: user_id=456
2024-01-15 10:35:30 ERROR Authentication failed: invalid_token"""

result = analyze_log_file(log_content)
print("æ—¥å¿—çº§åˆ«ç»Ÿè®¡:", result['level_counts'])
print("ç”¨æˆ·IDåˆ—è¡¨:", result['user_ids'])
print("é”™è¯¯ä¿¡æ¯:", result['errors'])
print("æ¯å°æ—¶æ—¥å¿—æ•°:", result['hour_counts'])
```

### é¢˜ç›®3ï¼šCSVæ•°æ®å¤„ç†å™¨

```python
import csv
from datetime import datetime
from collections import defaultdict

def process_employee_data():
    """å¤„ç†å‘˜å·¥æ•°æ®CSVæ–‡ä»¶"""
    
    # åˆ›å»ºCSVæ–‡ä»¶
    employees_data = [
        ['å§“å', 'éƒ¨é—¨', 'å·¥èµ„', 'å…¥èŒæ—¥æœŸ'],
        ['å¼ ä¸‰', 'æŠ€æœ¯éƒ¨', '8000', '2023-01-15'],
        ['æå››', 'é”€å”®éƒ¨', '6000', '2023-02-20'],
        ['ç‹äº”', 'æŠ€æœ¯éƒ¨', '9000', '2022-12-10'],
        ['èµµå…­', 'äººäº‹éƒ¨', '7000', '2023-03-05'],
        ['é’±ä¸ƒ', 'æŠ€æœ¯éƒ¨', '8500', '2023-01-25']
    ]
    
    with open('employees.csv', 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerows(employees_data)
    
    # è¯»å–CSVæ–‡ä»¶
    employees = []
    with open('employees.csv', 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            row['å·¥èµ„'] = int(row['å·¥èµ„'])
            row['å…¥èŒæ—¥æœŸ'] = datetime.strptime(row['å…¥èŒæ—¥æœŸ'], '%Y-%m-%d')
            employees.append(row)
    
    # 1. è®¡ç®—å„éƒ¨é—¨å¹³å‡å·¥èµ„
    dept_salaries = defaultdict(list)
    for emp in employees:
        dept_salaries[emp['éƒ¨é—¨']].append(emp['å·¥èµ„'])
    
    dept_avg = {dept: sum(salaries)/len(salaries) 
                for dept, salaries in dept_salaries.items()}
    
    # 2. æ‰¾å‡ºå·¥èµ„æœ€é«˜å’Œæœ€ä½çš„å‘˜å·¥
    max_salary_emp = max(employees, key=lambda x: x['å·¥èµ„'])
    min_salary_emp = min(employees, key=lambda x: x['å·¥èµ„'])
    
    # 3. æŒ‰å…¥èŒæ—¥æœŸæ’åº
    sorted_employees = sorted(employees, key=lambda x: x['å…¥èŒæ—¥æœŸ'])
    
    # 4. ä¿å­˜ç»“æœåˆ°æ–°CSVæ–‡ä»¶
    with open('employee_analysis.csv', 'w', newline='', encoding='utf-8') as f:
        fieldnames = ['å§“å', 'éƒ¨é—¨', 'å·¥èµ„', 'å…¥èŒæ—¥æœŸ']
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        for emp in sorted_employees:
            emp_copy = emp.copy()
            emp_copy['å…¥èŒæ—¥æœŸ'] = emp_copy['å…¥èŒæ—¥æœŸ'].strftime('%Y-%m-%d')
            writer.writerow(emp_copy)
    
    return {
        'dept_avg': dept_avg,
        'max_salary': max_salary_emp,
        'min_salary': min_salary_emp,
        'sorted_employees': sorted_employees
    }

result = process_employee_data()
print("å„éƒ¨é—¨å¹³å‡å·¥èµ„:", result['dept_avg'])
print("å·¥èµ„æœ€é«˜å‘˜å·¥:", result['max_salary']['å§“å'], result['max_salary']['å·¥èµ„'])
print("å·¥èµ„æœ€ä½å‘˜å·¥:", result['min_salary']['å§“å'], result['min_salary']['å·¥èµ„'])
```

### é¢˜ç›®4ï¼šJSON APIæ•°æ®æ¨¡æ‹Ÿ

```python
import json
from collections import defaultdict

def process_api_data():
    """å¤„ç†API JSONæ•°æ®"""
    
    json_data = {
        "status": "success",
        "data": {
            "users": [
                {
                    "id": 1,
                    "username": "admin",
                    "email": "admin@example.com",
                    "roles": ["admin", "user"],
                    "profile": {
                        "first_name": "å¼ ",
                        "last_name": "ä¸‰",
                        "age": 28,
                        "department": "æŠ€æœ¯éƒ¨"
                    },
                    "is_active": True,
                    "last_login": "2024-01-15T10:30:00Z"
                },
                {
                    "id": 2,
                    "username": "user1",
                    "email": "user1@example.com",
                    "roles": ["user"],
                    "profile": {
                        "first_name": "æ",
                        "last_name": "å››",
                        "age": 25,
                        "department": "é”€å”®éƒ¨"
                    },
                    "is_active": False,
                    "last_login": "2024-01-10T15:20:00Z"
                }
            ]
        }
    }
    
    users = json_data["data"]["users"]
    
    # 1. æå–æ‰€æœ‰æ´»è·ƒç”¨æˆ·çš„ä¿¡æ¯
    active_users = [user for user in users if user["is_active"]]
    
    # 2. è®¡ç®—ç”¨æˆ·å¹³å‡å¹´é¾„
    total_age = sum(user["profile"]["age"] for user in users)
    avg_age = total_age / len(users)
    
    # 3. æŒ‰éƒ¨é—¨åˆ†ç»„ç»Ÿè®¡ç”¨æˆ·æ•°é‡
    dept_counts = defaultdict(int)
    for user in users:
        dept = user["profile"]["department"]
        dept_counts[dept] += 1
    
    # 4. æ‰¾å‡ºæ‹¥æœ‰adminè§’è‰²çš„ç”¨æˆ·
    admin_users = [user for user in users if "admin" in user["roles"]]
    
    return {
        "active_users": active_users,
        "average_age": avg_age,
        "department_counts": dict(dept_counts),
        "admin_users": admin_users
    }

result = process_api_data()
print("æ´»è·ƒç”¨æˆ·æ•°é‡:", len(result["active_users"]))
print("ç”¨æˆ·å¹³å‡å¹´é¾„:", result["average_age"])
print("éƒ¨é—¨ç”¨æˆ·ç»Ÿè®¡:", result["department_counts"])
print("ç®¡ç†å‘˜ç”¨æˆ·:", [user["username"] for user in result["admin_users"]])
```

### é¢˜ç›®5ï¼šæ•°æ®å¤‡ä»½å·¥å…·

```python
import os
import shutil
from datetime import datetime
import json

class BackupTool:
    def __init__(self, source_dir, backup_dir):
        self.source_dir = source_dir
        self.backup_dir = backup_dir
        self.backup_report = {
            "backup_time": None,
            "files_backed_up": [],
            "total_size": 0,
            "status": "success"
        }
    
    def create_backup(self):
        """åˆ›å»ºå¤‡ä»½"""
        try:
            # åˆ›å»ºå¤‡ä»½ç›®å½•
            os.makedirs(self.backup_dir, exist_ok=True)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            self.backup_report["backup_time"] = timestamp
            
            total_size = 0
            
            # éå†æºç›®å½•ä¸­çš„æ–‡ä»¶
            for filename in os.listdir(self.source_dir):
                source_path = os.path.join(self.source_dir, filename)
                
                if os.path.isfile(source_path):
                    # ä¸ºå¤‡ä»½æ–‡ä»¶æ·»åŠ æ—¶é—´æˆ³
                    name, ext = os.path.splitext(filename)
                    backup_filename = f"{name}_{timestamp}{ext}"
                    backup_path = os.path.join(self.backup_dir, backup_filename)
                    
                    # å¤åˆ¶æ–‡ä»¶
                    shutil.copy2(source_path, backup_path)
                    
                    # è®¡ç®—æ–‡ä»¶å¤§å°
                    file_size = os.path.getsize(source_path)
                    total_size += file_size
                    
                    self.backup_report["files_backed_up"].append({
                        "original": filename,
                        "backup": backup_filename,
                        "size": file_size
                    })
            
            self.backup_report["total_size"] = total_size
            
        except Exception as e:
            self.backup_report["status"] = "failed"
            self.backup_report["error"] = str(e)
    
    def generate_report(self):
        """ç”Ÿæˆå¤‡ä»½æŠ¥å‘Š"""
        report_filename = f"backup_report_{self.backup_report['backup_time']}.json"
        report_path = os.path.join(self.backup_dir, report_filename)
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(self.backup_report, f, ensure_ascii=False, indent=2)
        
        print(f"å¤‡ä»½å®Œæˆï¼")
        print(f"å¤‡ä»½æ–‡ä»¶æ•°: {len(self.backup_report['files_backed_up'])}")
        print(f"æ€»å¤§å°: {self.backup_report['total_size']} å­—èŠ‚")
        print(f"æŠ¥å‘Šæ–‡ä»¶: {report_path}")

# ç¤ºä¾‹ä½¿ç”¨
def demo_backup():
    # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
    os.makedirs("source_files", exist_ok=True)
    test_files = ["test1.txt", "test2.txt", "config.json"]
    
    for filename in test_files:
        with open(f"source_files/{filename}", 'w') as f:
            f.write(f"è¿™æ˜¯ {filename} çš„å†…å®¹")
    
    # æ‰§è¡Œå¤‡ä»½
    backup_tool = BackupTool("source_files", "backup_files")
    backup_tool.create_backup()
    backup_tool.generate_report()

demo_backup()
```

### é¢˜ç›®6ï¼šæ–‡ä»¶ç›‘æ§å™¨

```python
import os
import json
from datetime import datetime

class FileMonitor:
    def __init__(self, monitor_dir):
        self.monitor_dir = monitor_dir
        self.snapshot_file = "file_snapshot.json"
        self.log_file = "file_changes.log"
    
    def get_file_info(self, filepath):
        """è·å–æ–‡ä»¶ä¿¡æ¯"""
        stat = os.stat(filepath)
        return {
            "size": stat.st_size,
            "modified": stat.st_mtime,
            "created": stat.st_ctime
        }
    
    def take_snapshot(self):
        """è®°å½•å½“å‰æ–‡ä»¶çŠ¶æ€"""
        snapshot = {}
        
        if not os.path.exists(self.monitor_dir):
            return snapshot
        
        for filename in os.listdir(self.monitor_dir):
            filepath = os.path.join(self.monitor_dir, filename)
            if os.path.isfile(filepath):
                snapshot[filename] = self.get_file_info(filepath)
        
        with open(self.snapshot_file, 'w') as f:
            json.dump(snapshot, f, indent=2)
        
        return snapshot
    
    def load_snapshot(self):
        """åŠ è½½ä¹‹å‰çš„å¿«ç…§"""
        try:
            with open(self.snapshot_file, 'r') as f:
                return json.load(f)
        except FileNotFoundError:
            return {}
    
    def detect_changes(self):
        """æ£€æµ‹æ–‡ä»¶å˜åŒ–"""
        old_snapshot = self.load_snapshot()
        current_snapshot = {}
        
        changes = {
            "added": [],
            "modified": [],
            "deleted": []
        }
        
        # è·å–å½“å‰æ–‡ä»¶çŠ¶æ€
        if os.path.exists(self.monitor_dir):
            for filename in os.listdir(self.monitor_dir):
                filepath = os.path.join(self.monitor_dir, filename)
                if os.path.isfile(filepath):
                    current_snapshot[filename] = self.get_file_info(filepath)
        
        # æ£€æµ‹æ–°å¢å’Œä¿®æ”¹çš„æ–‡ä»¶
        for filename, info in current_snapshot.items():
            if filename not in old_snapshot:
                changes["added"].append(filename)
            elif info["modified"] > old_snapshot[filename]["modified"]:
                changes["modified"].append(filename)
        
        # æ£€æµ‹åˆ é™¤çš„æ–‡ä»¶
        for filename in old_snapshot:
            if filename not in current_snapshot:
                changes["deleted"].append(filename)
        
        return changes
    
    def log_changes(self, changes):
        """è®°å½•å˜åŒ–åˆ°æ—¥å¿—"""
        if not any(changes.values()):
            return
        
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        with open(self.log_file, 'a', encoding='utf-8') as f:
            f.write(f"\n=== {timestamp} ===\n")
            
            for added in changes["added"]:
                f.write(f"æ–°å¢æ–‡ä»¶: {added}\n")
            
            for modified in changes["modified"]:
                f.write(f"ä¿®æ”¹æ–‡ä»¶: {modified}\n")
            
            for deleted in changes["deleted"]:
                f.write(f"åˆ é™¤æ–‡ä»¶: {deleted}\n")

# ç¤ºä¾‹ä½¿ç”¨
def demo_file_monitor():
    monitor = FileMonitor("watch_dir")
    
    # åˆ›å»ºç›‘æ§ç›®å½•å’Œä¸€äº›æµ‹è¯•æ–‡ä»¶
    os.makedirs("watch_dir", exist_ok=True)
    with open("watch_dir/file1.txt", 'w') as f:
        f.write("åŸå§‹å†…å®¹")
    
    # é¦–æ¬¡å¿«ç…§
    print("åˆ›å»ºåˆå§‹å¿«ç…§...")
    monitor.take_snapshot()
    
    # æ¨¡æ‹Ÿæ–‡ä»¶å˜åŒ–
    print("æ¨¡æ‹Ÿæ–‡ä»¶å˜åŒ–...")
    with open("watch_dir/file2.txt", 'w') as f:  # æ–°å¢æ–‡ä»¶
        f.write("æ–°æ–‡ä»¶")
    
    import time
    time.sleep(1)  # ç¡®ä¿ä¿®æ”¹æ—¶é—´ä¸åŒ
    
    with open("watch_dir/file1.txt", 'w') as f:  # ä¿®æ”¹æ–‡ä»¶
        f.write("ä¿®æ”¹åçš„å†…å®¹")
    
    # æ£€æµ‹å˜åŒ–
    changes = monitor.detect_changes()
    print("æ£€æµ‹åˆ°çš„å˜åŒ–:", changes)
    
    # è®°å½•å˜åŒ–
    monitor.log_changes(changes)
    
    # æ›´æ–°å¿«ç…§
    monitor.take_snapshot()

demo_file_monitor()
```

### é¢˜ç›®7ï¼šæ•°æ®å¯¼å…¥å¯¼å‡ºå™¨

```python
import json
import csv
import xml.etree.ElementTree as ET
from typing import List, Dict, Any

class DataConverter:
    def __init__(self):
        self.supported_formats = ['json', 'csv', 'xml']
    
    def json_to_csv(self, json_data: List[Dict], csv_filename: str):
        """JSONè½¬CSV"""
        if not json_data:
            return False
        
        # æ‰å¹³åŒ–åµŒå¥—å­—å…¸
        flattened_data = []
        for item in json_data:
            flattened_item = self._flatten_dict(item)
            flattened_data.append(flattened_item)
        
        # è·å–æ‰€æœ‰å­—æ®µå
        fieldnames = set()
        for item in flattened_data:
            fieldnames.update(item.keys())
        fieldnames = sorted(list(fieldnames))
        
        # å†™å…¥CSV
        with open(csv_filename, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(flattened_data)
        
        return True
    
    def csv_to_json(self, csv_filename: str, json_filename: str):
        """CSVè½¬JSON"""
        try:
            with open(csv_filename, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                data = []
                for row in reader:
                    # æ¢å¤åµŒå¥—ç»“æ„
                    nested_row = self._unflatten_dict(row)
                    data.append(nested_row)
            
            with open(json_filename, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            return True
        except Exception as e:
            print(f"è½¬æ¢å¤±è´¥: {e}")
            return False
    
    def _flatten_dict(self, d: Dict, parent_key: str = '', sep: str = '.') -> Dict:
        """æ‰å¹³åŒ–å­—å…¸"""
        items = []
        for k, v in d.items():
            new_key = f"{parent_key}{sep}{k}" if parent_key else k
            if isinstance(v, dict):
                items.extend(self._flatten_dict(v, new_key, sep=sep).items())
            elif isinstance(v, list):
                # ç®€å•å¤„ç†åˆ—è¡¨ï¼šè½¬ä¸ºå­—ç¬¦ä¸²
                items.append((new_key, json.dumps(v, ensure_ascii=False)))
            else:
                items.append((new_key, v))
        return dict(items)
    
    def _unflatten_dict(self, d: Dict, sep: str = '.') -> Dict:
        """åæ‰å¹³åŒ–å­—å…¸"""
        result = {}
        for key, value in d.items():
            if sep in key:
                keys = key.split(sep)
                current = result
                for k in keys[:-1]:
                    if k not in current:
                        current[k] = {}
                    current = current[k]
                
                # å°è¯•è§£æJSONå­—ç¬¦ä¸²
                try:
                    current[keys[-1]] = json.loads(value)
                except (json.JSONDecodeError, TypeError):
                    current[keys[-1]] = value
            else:
                # å°è¯•è§£æJSONå­—ç¬¦ä¸²
                try:
                    result[key] = json.loads(value)
                except (json.JSONDecodeError, TypeError):
                    result[key] = value
        
        return result
    
    def validate_data(self, data: Any, data_type: str = 'json') -> bool:
        """éªŒè¯æ•°æ®æ ¼å¼"""
        if data_type == 'json':
            return isinstance(data, (list, dict))
        elif data_type == 'csv':
            # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„CSVæ•°æ®
            return isinstance(data, list) and all(isinstance(row, dict) for row in data)
        return False
    
    def batch_convert(self, file_list: List[str], source_format: str, target_format: str):
        """æ‰¹é‡è½¬æ¢æ–‡ä»¶"""
        results = []
        
        for filename in file_list:
            try:
                if source_format == 'json' and target_format == 'csv':
                    with open(filename, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    if self.validate_data(data, 'json'):
                        output_filename = filename.replace('.json', '.csv')
                        success = self.json_to_csv(data, output_filename)
                        results.append({'file': filename, 'success': success})
                
                elif source_format == 'csv' and target_format == 'json':
                    output_filename = filename.replace('.csv', '.json')
                    success = self.csv_to_json(filename, output_filename)
                    results.append({'file': filename, 'success': success})
                
            except Exception as e:
                results.append({'file': filename, 'success': False, 'error': str(e)})
        
        return results

# ç¤ºä¾‹ä½¿ç”¨
def demo_data_converter():
    converter = DataConverter()
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_data = [
        {
            "id": 1,
            "name": "å¼ ä¸‰",
            "profile": {
                "age": 25,
                "city": "åŒ—äº¬",
                "skills": ["Python", "JavaScript"]
            },
            "active": True
        },
        {
            "id": 2,
            "name": "æå››",
            "profile": {
                "age": 30,
                "city": "ä¸Šæµ·",
                "skills": ["Java", "SQL"]
            },
            "active": False
        }
    ]
    
    # ä¿å­˜æµ‹è¯•JSONæ–‡ä»¶
    with open('test_data.json', 'w', encoding='utf-8') as f:
        json.dump(test_data, f, ensure_ascii=False, indent=2)
    
    # JSONè½¬CSV
    print("JSONè½¬CSV...")
    success = converter.json_to_csv(test_data, 'test_data.csv')
    print(f"è½¬æ¢æˆåŠŸ: {success}")
    
    # CSVè½¬JSON
    print("CSVè½¬JSON...")
    success = converter.csv_to_json('test_data.csv', 'converted_data.json')
    print(f"è½¬æ¢æˆåŠŸ: {success}")
    
    # æ‰¹é‡è½¬æ¢
    print("æ‰¹é‡è½¬æ¢...")
    results = converter.batch_convert(['test_data.json'], 'json', 'csv')
    print("æ‰¹é‡è½¬æ¢ç»“æœ:", results)

demo_data_converter()
```

## å¼‚å¸¸å¤„ç†åŸºç¡€ï¼ˆ8-12é¢˜ï¼‰

### é¢˜ç›®8ï¼šç”¨æˆ·è¾“å…¥éªŒè¯å™¨

```python
import re
import logging

class ValidationError(Exception):
    """è‡ªå®šä¹‰éªŒè¯å¼‚å¸¸"""
    pass

class UserInputValidator:
    def __init__(self):
        self.error_log = []
        
        # é…ç½®æ—¥å¿—
        logging.basicConfig(
            filename='validation_errors.log',
            level=logging.ERROR,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger(__name__)
    
    def validate_username(self, username):
        """éªŒè¯ç”¨æˆ·å"""
        if not username:
            raise ValidationError("ç”¨æˆ·åä¸èƒ½ä¸ºç©º")
        
        if len(username) < 3 or len(username) > 20:
            raise ValidationError("ç”¨æˆ·åé•¿åº¦å¿…é¡»åœ¨3-20ä¸ªå­—ç¬¦ä¹‹é—´")
        
        if not re.match(r'^[a-zA-Z0-9_]+$', username):
            raise ValidationError("ç”¨æˆ·ååªèƒ½åŒ…å«å­—æ¯ã€æ•°å­—å’Œä¸‹åˆ’çº¿")
        
        return True
    
    def validate_password(self, password):
        """éªŒè¯å¯†ç """
        if not password:
            raise ValidationError("å¯†ç ä¸èƒ½ä¸ºç©º")
        
        if len(password) < 8:
            raise ValidationError("å¯†ç é•¿åº¦è‡³å°‘8ä¸ªå­—ç¬¦")
        
        if not re.search(r'[a-z]', password):
            raise ValidationError("å¯†ç å¿…é¡»åŒ…å«å°å†™å­—æ¯")
        
        if not re.search(r'[A-Z]', password):
            raise ValidationError("å¯†ç å¿…é¡»åŒ…å«å¤§å†™å­—æ¯")
        
        if not re.search(r'\d', password):
            raise ValidationError("å¯†ç å¿…é¡»åŒ…å«æ•°å­—")
        
        return True
    
    def validate_email(self, email):
        """éªŒè¯é‚®ç®±"""
        if not email:
            raise ValidationError("é‚®ç®±ä¸èƒ½ä¸ºç©º")
        
        pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
        if not re.match(pattern, email):
            raise ValidationError("é‚®ç®±æ ¼å¼ä¸æ­£ç¡®")
        
        return True
    
    def validate_age(self, age_str):
        """éªŒè¯å¹´é¾„"""
        try:
            age = int(age_str)
            if age < 18 or age > 100:
                raise ValidationError("å¹´é¾„å¿…é¡»åœ¨18-100ä¹‹é—´")
            return True
        except ValueError:
            raise ValidationError("å¹´é¾„å¿…é¡»æ˜¯æ•°å­—")
    
    def validate_user_input(self, max_retries=3):
        """å®Œæ•´çš„ç”¨æˆ·è¾“å…¥éªŒè¯æµç¨‹"""
        fields = {
            'username': self.validate_username,
            'password': self.validate_password,
            'email': self.validate_email,
            'age': self.validate_age
        }
        
        user_data = {}
        
        for field_name, validator in fields.items():
            retry_count = 0
            
            while retry_count < max_retries:
                try:
                    value = input(f"è¯·è¾“å…¥{field_name}: ")
                    validator(value)
                    user_data[field_name] = value
                    print(f"âœ… {field_name}éªŒè¯é€šè¿‡")
                    break
                    
                except ValidationError as e:
                    retry_count += 1
                    error_msg = f"{field_name}éªŒè¯å¤±è´¥: {e}"
                    print(f"âŒ {error_msg}")
                    
                    # è®°å½•é”™è¯¯æ—¥å¿—
                    self.logger.error(error_msg)
                    self.error_log.append({
                        'field': field_name,
                        'error': str(e),
                        'retry': retry_count
                    })
                    
                    if retry_count >= max_retries:
                        print(f"âŒ {field_name}éªŒè¯å¤±è´¥æ¬¡æ•°è¿‡å¤šï¼Œè·³è¿‡è¯¥å­—æ®µ")
                        break
                    else:
                        print(f"è¿˜æœ‰ {max_retries - retry_count} æ¬¡é‡è¯•æœºä¼š")
        
        return user_data

# ç¤ºä¾‹ä½¿ç”¨
def demo_validator():
    validator = UserInputValidator()
    
    # æ¨¡æ‹Ÿç”¨æˆ·è¾“å…¥ï¼ˆå®é™…ä½¿ç”¨æ—¶ä¼šä»æ§åˆ¶å°è¾“å…¥ï¼‰
    test_cases = [
        ("ab", "ç”¨æˆ·åå¤ªçŸ­"),
        ("valid_user123", "æœ‰æ•ˆç”¨æˆ·å"),
        ("123", "å¯†ç å¤ªçŸ­"),
        ("ValidPass123", "æœ‰æ•ˆå¯†ç "),
        ("invalid-email", "æ— æ•ˆé‚®ç®±"),
        ("user@example.com", "æœ‰æ•ˆé‚®ç®±"),
        ("15", "å¹´é¾„å¤ªå°"),
        ("25", "æœ‰æ•ˆå¹´é¾„")
    ]
    
    for value, description in test_cases:
        try:
            if "ç”¨æˆ·å" in description:
                validator.validate_username(value)
            elif "å¯†ç " in description:
                validator.validate_password(value)
            elif "é‚®ç®±" in description:
                validator.validate_email(value)
            elif "å¹´é¾„" in description:
                validator.validate_age(value)
            
            print(f"âœ… {description}: {value}")
            
        except ValidationError as e:
            print(f"âŒ {description}: {e}")

demo_validator()
```

### é¢˜ç›®9ï¼šæ–‡ä»¶æ“ä½œå¼‚å¸¸å¤„ç†

```python
import os
import shutil
import tempfile
from contextlib import contextmanager

class FileOperationError(Exception):
    """æ–‡ä»¶æ“ä½œå¼‚å¸¸"""
    pass

class SafeFileOperator:
    def __init__(self):
        self.backup_dir = "file_backups"
        os.makedirs(self.backup_dir, exist_ok=True)
    
    def safe_read_file(self, filepath, encoding='utf-8'):
        """å®‰å…¨è¯»å–æ–‡ä»¶"""
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(filepath):
                raise FileOperationError(f"æ–‡ä»¶ {filepath} ä¸å­˜åœ¨")
            
            # æ£€æŸ¥æ–‡ä»¶æƒé™
            if not os.access(filepath, os.R_OK):
                raise FileOperationError(f"æ²¡æœ‰è¯»å– {filepath} çš„æƒé™")
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼ˆé¿å…å†…å­˜é—®é¢˜ï¼‰
            file_size = os.path.getsize(filepath)
            if file_size > 100 * 1024 * 1024:  # 100MBé™åˆ¶
                raise FileOperationError(f"æ–‡ä»¶ {filepath} è¿‡å¤§ ({file_size} å­—èŠ‚)")
            
            with open(filepath, 'r', encoding=encoding) as f:
                content = f.read()
            
            return content
            
        except PermissionError:
            raise FileOperationError(f"æƒé™ä¸è¶³ï¼Œæ— æ³•è¯»å– {filepath}")
        except UnicodeDecodeError as e:
            raise FileOperationError(f"æ–‡ä»¶ç¼–ç é”™è¯¯: {e}")
        except MemoryError:
            raise FileOperationError(f"æ–‡ä»¶ {filepath} å¤ªå¤§ï¼Œå†…å­˜ä¸è¶³")
        except Exception as e:
            raise FileOperationError(f"è¯»å–æ–‡ä»¶æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
    
    def create_backup(self, filepath):
        """åˆ›å»ºæ–‡ä»¶å¤‡ä»½"""
        if os.path.exists(filepath):
            backup_name = f"{os.path.basename(filepath)}.backup"
            backup_path = os.path.join(self.backup_dir, backup_name)
            shutil.copy2(filepath, backup_path)
            return backup_path
        return None
    
    @contextmanager
    def atomic_write(self, filepath, mode='w', encoding='utf-8'):
        """åŸå­æ€§å†™å…¥æ–‡ä»¶"""
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        temp_fd, temp_path = tempfile.mkstemp(
            dir=os.path.dirname(filepath) or '.',
            prefix=f'.{os.path.basename(filepath)}.tmp'
        )
        
        try:
            # å…³é—­æ–‡ä»¶æè¿°ç¬¦ï¼Œç”¨Pythonçš„opené‡æ–°æ‰“å¼€
            os.close(temp_fd)
            
            with open(temp_path, mode, encoding=encoding) as temp_file:
                yield temp_file
            
            # åŸå­æ€§åœ°ç§»åŠ¨ä¸´æ—¶æ–‡ä»¶åˆ°ç›®æ ‡ä½ç½®
            if os.name == 'nt':  # Windows
                if os.path.exists(filepath):
                    os.remove(filepath)
            
            shutil.move(temp_path, filepath)
            
        except Exception:
            # å‡ºé”™æ—¶æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.remove(temp_path)
            except OSError:
                pass
            raise
    
    def safe_write_file(self, filepath, content, encoding='utf-8'):
        """å®‰å…¨å†™å…¥æ–‡ä»¶"""
        try:
            # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™åˆ›å»º
            directory = os.path.dirname(filepath)
            if directory and not os.path.exists(directory):
                os.makedirs(directory, exist_ok=True)
            
            # æ£€æŸ¥ç£ç›˜ç©ºé—´ï¼ˆç®€å•æ£€æŸ¥ï¼‰
            if hasattr(shutil, 'disk_usage'):
                free_space = shutil.disk_usage(directory or '.').free
                content_size = len(content.encode(encoding))
                if content_size > free_space:
                    raise FileOperationError("ç£ç›˜ç©ºé—´ä¸è¶³")
            
            # åˆ›å»ºå¤‡ä»½
            backup_path = self.create_backup(filepath)
            
            try:
                # åŸå­æ€§å†™å…¥
                with self.atomic_write(filepath, 'w', encoding) as f:
                    f.write(content)
                
                print(f"âœ… æ–‡ä»¶ {filepath} å†™å…¥æˆåŠŸ")
                if backup_path:
                    print(f"ğŸ“ å¤‡ä»½æ–‡ä»¶ä¿å­˜åœ¨: {backup_path}")
                
            except Exception as e:
                # å†™å…¥å¤±è´¥æ—¶æ¢å¤å¤‡ä»½
                if backup_path and os.path.exists(backup_path):
                    shutil.copy2(backup_path, filepath)
                    print(f"ğŸ”„ å·²ä»å¤‡ä»½æ¢å¤æ–‡ä»¶: {filepath}")
                raise e
                
        except PermissionError:
            raise FileOperationError(f"æƒé™ä¸è¶³ï¼Œæ— æ³•å†™å…¥ {filepath}")
        except OSError as e:
            if e.errno == 28:  # No space left on device
                raise FileOperationError("ç£ç›˜ç©ºé—´ä¸è¶³")
            elif e.errno == 36:  # File name too long
                raise FileOperationError("æ–‡ä»¶åå¤ªé•¿")
            else:
                raise FileOperationError(f"ç³»ç»Ÿé”™è¯¯: {e}")
        except Exception as e:
            raise FileOperationError(f"å†™å…¥æ–‡ä»¶æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")

# ç¤ºä¾‹ä½¿ç”¨å’Œæµ‹è¯•
def demo_safe_file_operator():
    operator = SafeFileOperator()
    
    # æµ‹è¯•åœºæ™¯1ï¼šæ­£å¸¸è¯»å†™æ“ä½œ
    print("=== æµ‹è¯•1ï¼šæ­£å¸¸æ–‡ä»¶æ“ä½œ ===")
    try:
        # å†™å…¥æ–‡ä»¶
        content = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡ä»¶\nåŒ…å«å¤šè¡Œå†…å®¹"
        operator.safe_write_file("test_file.txt", content)
        
        # è¯»å–æ–‡ä»¶
        read_content = operator.safe_read_file("test_file.txt")
        print(f"è¯»å–çš„å†…å®¹: {read_content}")
        
    except FileOperationError as e:
        print(f"æ–‡ä»¶æ“ä½œé”™è¯¯: {e}")
    
    # æµ‹è¯•åœºæ™¯2ï¼šè¯»å–ä¸å­˜åœ¨çš„æ–‡ä»¶
    print("\n=== æµ‹è¯•2ï¼šè¯»å–ä¸å­˜åœ¨çš„æ–‡ä»¶ ===")
    try:
        content = operator.safe_read_file("nonexistent_file.txt")
    except FileOperationError as e:
        print(f"é¢„æœŸçš„é”™è¯¯: {e}")
    
    # æµ‹è¯•åœºæ™¯3ï¼šå†™å…¥åˆ°åªè¯»ç›®å½•ï¼ˆæ¨¡æ‹Ÿï¼‰
    print("\n=== æµ‹è¯•3ï¼šæƒé™æµ‹è¯• ===")
    try:
        # åœ¨æŸäº›ç³»ç»Ÿä¸Šï¼Œ/root ç›®å½•å¯èƒ½æ²¡æœ‰å†™æƒé™
        # è¿™é‡Œåªæ˜¯ç¤ºä¾‹ï¼Œå®é™…æµ‹è¯•éœ€è¦æ ¹æ®ç³»ç»Ÿè°ƒæ•´
        if os.name != 'nt':  # éWindowsç³»ç»Ÿ
            operator.safe_write_file("/root/test.txt", "æµ‹è¯•å†…å®¹")
    except FileOperationError as e:
        print(f"æƒé™é”™è¯¯ï¼ˆé¢„æœŸï¼‰: {e}")
    
    # æµ‹è¯•åœºæ™¯4ï¼šåŸå­æ€§å†™å…¥æ¼”ç¤º
    print("\n=== æµ‹è¯•4ï¼šåŸå­æ€§å†™å…¥ ===")
    try:
        with operator.atomic_write("atomic_test.txt") as f:
            f.write("ç¬¬ä¸€è¡Œ\n")
            f.write("ç¬¬äºŒè¡Œ\n")
            # å¦‚æœè¿™é‡Œå‘ç”Ÿå¼‚å¸¸ï¼Œæ–‡ä»¶ä¸ä¼šè¢«åˆ›å»ºæˆ–éƒ¨åˆ†å†™å…¥
        print("åŸå­æ€§å†™å…¥æˆåŠŸ")
    except Exception as e:
        print(f"åŸå­æ€§å†™å…¥å¤±è´¥: {e}")

demo_safe_file_operator()
```

### é¢˜ç›®10ï¼šç½‘ç»œè¯·æ±‚æ¨¡æ‹Ÿå™¨

```python
import time
import random
from enum import Enum
from typing import Optional, Dict, Any

class NetworkError(Exception):
    """ç½‘ç»œé”™è¯¯åŸºç±»"""
    pass

class TimeoutError(NetworkError):
    """è¶…æ—¶é”™è¯¯"""
    pass

class ConnectionError(NetworkError):
    """è¿æ¥é”™è¯¯"""
    pass

class DNSError(NetworkError):
    """DNSè§£æé”™è¯¯"""
    pass

class NetworkErrorType(Enum):
    TIMEOUT = "timeout"
    CONNECTION_REFUSED = "connection_refused"
    DNS_ERROR = "dns_error"
    SUCCESS = "success"

class NetworkSimulator:
    def __init__(self, success_rate=0.7):
        self.success_rate = success_rate
        self.attempt_log = []
    
    def simulate_request(self, url: str) -> NetworkErrorType:
        """æ¨¡æ‹Ÿç½‘ç»œè¯·æ±‚"""
        # éšæœºå†³å®šè¯·æ±‚ç»“æœ
        rand = random.random()
        
        if rand < self.success_rate:
            return NetworkErrorType.SUCCESS
        elif rand < self.success_rate + 0.1:
            return NetworkErrorType.TIMEOUT
        elif rand < self.success_rate + 0.2:
            return NetworkErrorType.CONNECTION_REFUSED
        else:
            return NetworkErrorType.DNS_ERROR
    
    def make_request(self, url: str, timeout: int = 5) -> Dict[str, Any]:
        """æ‰§è¡Œå•æ¬¡è¯·æ±‚"""
        start_time = time.time()
        
        # æ¨¡æ‹Ÿè¯·æ±‚å»¶è¿Ÿ
        time.sleep(random.uniform(0.1, 0.5))
        
        result = self.simulate_request(url)
        
        if result == NetworkErrorType.SUCCESS:
            return {
                "status": "success",
                "data": f"Response from {url}",
                "status_code": 200,
                "response_time": time.time() - start_time
            }
        elif result == NetworkErrorType.TIMEOUT:
            raise TimeoutError(f"Request to {url} timed out after {timeout}s")
        elif result == NetworkErrorType.CONNECTION_REFUSED:
            raise ConnectionError(f"Connection to {url} refused")
        else:
            raise DNSError(f"DNS resolution failed for {url}")

class RetryableNetworkClient:
    def __init__(self, max_retries=3, base_delay=1.0, backoff_factor=2.0):
        self.max_retries = max_retries
        self.base_delay = base_delay
        self.backoff_factor = backoff_factor
        self.simulator = NetworkSimulator()
        self.request_log = []
    
    def calculate_delay(self, attempt: int) -> float:
        """è®¡ç®—æŒ‡æ•°é€€é¿å»¶è¿Ÿ"""
        return self.base_delay * (self.backoff_factor ** (attempt - 1))
    
    def request_with_retry(self, url: str, fallback_response=None) -> Dict[str, Any]:
        """å¸¦é‡è¯•æœºåˆ¶çš„ç½‘ç»œè¯·æ±‚"""
        last_exception = None
        
        for attempt in range(1, self.max_retries + 1):
            try:
                print(f"ğŸ”„ ç¬¬ {attempt} æ¬¡å°è¯•è¯·æ±‚ {url}")
                
                response = self.simulator.make_request(url)
                
                # è®°å½•æˆåŠŸè¯·æ±‚
                self.request_log.append({
                    "url": url,
                    "attempt": attempt,
                    "status": "success",
                    "response_time": response.get("response_time", 0)
                })
                
                print(f"âœ… è¯·æ±‚æˆåŠŸï¼")
                return response
                
            except NetworkError as e:
                last_exception = e
                
                # è®°å½•å¤±è´¥è¯·æ±‚
                self.request_log.append({
                    "url": url,
                    "attempt": attempt,
                    "status": "failed",
                    "error": str(e),
                    "error_type": type(e).__name__
                })
                
                print(f"âŒ ç¬¬ {attempt} æ¬¡å°è¯•å¤±è´¥: {e}")
                
                # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œåˆ™ç­‰å¾…åé‡è¯•
                if attempt < self.max_retries:
                    delay = self.calculate_delay(attempt)
                    print(f"â³ {delay:.1f}ç§’åé‡è¯•...")
                    time.sleep(delay)
                else:
                    print(f"ğŸ’¥ æ‰€æœ‰é‡è¯•å‡å¤±è´¥ï¼Œä½¿ç”¨é™çº§æ–¹æ¡ˆ")
        
        # æ‰€æœ‰é‡è¯•å‡å¤±è´¥ï¼Œè¿”å›é™çº§å“åº”
        if fallback_response is not None:
            print(f"ğŸ”„ ä½¿ç”¨é™çº§å“åº”")
            return fallback_response
        
        # å¦‚æœæ²¡æœ‰é™çº§æ–¹æ¡ˆï¼ŒæŠ›å‡ºæœ€åä¸€ä¸ªå¼‚å¸¸
        raise last_exception
    
    def bulk_request(self, urls: list, fallback_responses=None) -> Dict[str, Any]:
        """æ‰¹é‡è¯·æ±‚"""
        results = {}
        fallback_dict = fallback_responses or {}
        
        for url in urls:
            try:
                fallback = fallback_dict.get(url)
                response = self.request_with_retry(url, fallback)
                results[url] = response
            except Exception as e:
                results[url] = {"status": "failed", "error": str(e)}
        
        return results
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–è¯·æ±‚ç»Ÿè®¡ä¿¡æ¯"""
        if not self.request_log:
            return {"total_requests": 0}
        
        total_requests = len(self.request_log)
        successful_requests = len([r for r in self.request_log if r["status"] == "success"])
        failed_requests = total_requests - successful_requests
        
        # æŒ‰é”™è¯¯ç±»å‹ç»Ÿè®¡
        error_types = {}
        for request in self.request_log:
            if request["status"] == "failed":
                error_type = request.get("error_type", "Unknown")
                error_types[error_type] = error_types.get(error_type, 0) + 1
        
        # è®¡ç®—å¹³å‡é‡è¯•æ¬¡æ•°
        urls = list(set([r["url"] for r in self.request_log]))
        avg_attempts = sum([
            max([r["attempt"] for r in self.request_log if r["url"] == url])
            for url in urls
        ]) / len(urls) if urls else 0
        
        return {
            "total_requests": total_requests,
            "successful_requests": successful_requests,
            "failed_requests": failed_requests,
            "success_rate": successful_requests / total_requests if total_requests > 0 else 0,
            "error_types": error_types,
            "average_attempts": avg_attempts
        }

# ç¤ºä¾‹ä½¿ç”¨
def demo_network_client():
    client = RetryableNetworkClient(max_retries=3, base_delay=1.0)
    
    # æµ‹è¯•å•ä¸ªè¯·æ±‚
    print("=== æµ‹è¯•å•ä¸ªè¯·æ±‚ ===")
    try:
        fallback = {"status": "fallback", "data": "Cached response", "source": "cache"}
        response = client.request_with_retry("https://api.example.com/users", fallback)
        print(f"æœ€ç»ˆå“åº”: {response}")
    except Exception as e:
        print(f"è¯·æ±‚æœ€ç»ˆå¤±è´¥: {e}")
    
    print("\n" + "="*50 + "\n")
    
    # æµ‹è¯•æ‰¹é‡è¯·æ±‚
    print("=== æµ‹è¯•æ‰¹é‡è¯·æ±‚ ===")
    urls = [
        "https://api.example.com/users",
        "https://api.example.com/products",
        "https://api.example.com/orders"
    ]
    
    fallback_responses = {
        "https://api.example.com/users": {"status": "cached", "data": "Cached users"},
        "https://api.example.com/products": {"status": "cached", "data": "Cached products"}
    }
    
    results = client.bulk_request(urls, fallback_responses)
    
    print("æ‰¹é‡è¯·æ±‚ç»“æœ:")
    for url, result in results.items():
        print(f"  {url}: {result.get('status', 'unknown')}")
    
    print("\n" + "="*50 + "\n")
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    print("=== è¯·æ±‚ç»Ÿè®¡ä¿¡æ¯ ===")
    stats = client.get_statistics()
    for key, value in stats.items():
        print(f"{key}: {value}")

demo_network_client()
```

### é¢˜ç›®11ï¼šæ•°æ®åº“è¿æ¥æ¨¡æ‹Ÿå™¨

```python
import time
import random
from enum import Enum
from typing import Optional, Dict, Any, List
from contextlib import contextmanager

class DatabaseError(Exception):
    """æ•°æ®åº“å¼‚å¸¸åŸºç±»"""
    pass

class ConnectionTimeoutError(DatabaseError):
    """è¿æ¥è¶…æ—¶å¼‚å¸¸"""
    pass

class AuthenticationError(DatabaseError):
    """è®¤è¯å¤±è´¥å¼‚å¸¸"""
    pass

class DatabaseNotFoundError(DatabaseError):
    """æ•°æ®åº“ä¸å­˜åœ¨å¼‚å¸¸"""
    pass

class SQLSyntaxError(DatabaseError):
    """SQLè¯­æ³•é”™è¯¯å¼‚å¸¸"""
    pass

class ConstraintViolationError(DatabaseError):
    """æ•°æ®çº¦æŸè¿åå¼‚å¸¸"""
    pass

class DatabaseConnectionState(Enum):
    DISCONNECTED = "disconnected"
    CONNECTING = "connecting"
    CONNECTED = "connected"
    ERROR = "error"

class MockDatabase:
    def __init__(self, name: str, success_rate: float = 0.8):
        self.name = name
        self.success_rate = success_rate
        self.connection_state = DatabaseConnectionState.DISCONNECTED
        self.transaction_active = False
        self.tables = {"users": [], "products": [], "orders": []}
    
    def simulate_connection(self, username: str, password: str) -> bool:
        """æ¨¡æ‹Ÿæ•°æ®åº“è¿æ¥"""
        # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
        time.sleep(random.uniform(0.1, 0.3))
        
        # æ¨¡æ‹Ÿå„ç§è¿æ¥é”™è¯¯
        rand = random.random()
        
        if rand < 0.1:  # 10% æ¦‚ç‡è¿æ¥è¶…æ—¶
            raise ConnectionTimeoutError("æ•°æ®åº“è¿æ¥è¶…æ—¶")
        elif rand < 0.15:  # 5% æ¦‚ç‡è®¤è¯å¤±è´¥
            raise AuthenticationError("ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯")
        elif rand < 0.18:  # 3% æ¦‚ç‡æ•°æ®åº“ä¸å­˜åœ¨
            raise DatabaseNotFoundError(f"æ•°æ®åº“ '{self.name}' ä¸å­˜åœ¨")
        elif rand < self.success_rate:
            return True
        else:
            raise DatabaseError("æœªçŸ¥æ•°æ®åº“é”™è¯¯")
    
    def execute_query(self, sql: str) -> Dict[str, Any]:
        """æ¨¡æ‹ŸSQLæŸ¥è¯¢æ‰§è¡Œ"""
        if self.connection_state != DatabaseConnectionState.CONNECTED:
            raise DatabaseError("æ•°æ®åº“æœªè¿æ¥")
        
        # æ¨¡æ‹ŸSQLè¯­æ³•æ£€æŸ¥
        if "SELEC" in sql.upper() and "SELECT" not in sql.upper():
            raise SQLSyntaxError(f"SQLè¯­æ³•é”™è¯¯: {sql}")
        
        # æ¨¡æ‹Ÿçº¦æŸè¿å
        if "INSERT" in sql.upper() and "duplicate" in sql.lower():
            raise ConstraintViolationError("è¿åå”¯ä¸€æ€§çº¦æŸ")
        
        # æ¨¡æ‹Ÿæ‰§è¡Œå»¶è¿Ÿ
        time.sleep(random.uniform(0.05, 0.2))
        
        return {
            "status": "success",
            "rows_affected": random.randint(1, 10),
            "execution_time": random.uniform(0.1, 0.5)
        }

class DatabaseConnectionManager:
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.database = MockDatabase(config["database"], config.get("success_rate", 0.8))
        self.connection_pool = []
        self.max_retries = config.get("max_retries", 3)
        self.retry_delay = config.get("retry_delay", 1.0)
        self.connection_log = []
    
    def connect_with_retry(self) -> bool:
        """å¸¦é‡è¯•æœºåˆ¶çš„æ•°æ®åº“è¿æ¥"""
        for attempt in range(1, self.max_retries + 1):
            try:
                print(f"ğŸ”„ ç¬¬ {attempt} æ¬¡å°è¯•è¿æ¥æ•°æ®åº“ '{self.config['database']}'")
                
                success = self.database.simulate_connection(
                    self.config["username"],
                    self.config["password"]
                )
                
                if success:
                    self.database.connection_state = DatabaseConnectionState.CONNECTED
                    print(f"âœ… æ•°æ®åº“è¿æ¥æˆåŠŸï¼")
                    
                    self.connection_log.append({
                        "timestamp": time.time(),
                        "attempt": attempt,
                        "status": "success"
                    })
                    
                    return True
                    
            except DatabaseError as e:
                print(f"âŒ è¿æ¥å¤±è´¥: {e}")
                
                self.connection_log.append({
                    "timestamp": time.time(),
                    "attempt": attempt,
                    "status": "failed",
                    "error": str(e),
                    "error_type": type(e).__name__
                })
                
                if attempt < self.max_retries:
                    delay = self.retry_delay * attempt  # çº¿æ€§é€€é¿
                    print(f"â³ {delay}ç§’åé‡è¯•...")
                    time.sleep(delay)
        
        print(f"ğŸ’¥ æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
        self.database.connection_state = DatabaseConnectionState.ERROR
        return False
    
    @contextmanager
    def transaction(self):
        """äº‹åŠ¡ç®¡ç†ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        if self.database.connection_state != DatabaseConnectionState.CONNECTED:
            raise DatabaseError("æ•°æ®åº“æœªè¿æ¥")
        
        print("ğŸ“ å¼€å§‹äº‹åŠ¡")
        self.database.transaction_active = True
        transaction_log = []
        
        try:
            yield transaction_log
            
            # äº‹åŠ¡æäº¤
            print("âœ… äº‹åŠ¡æäº¤æˆåŠŸ")
            
        except Exception as e:
            # äº‹åŠ¡å›æ»š
            print(f"ğŸ”„ äº‹åŠ¡å›æ»š: {e}")
            
            # æ¨¡æ‹Ÿå›æ»šæ“ä½œ
            for operation in reversed(transaction_log):
                print(f"  æ’¤é”€æ“ä½œ: {operation}")
            
            raise e
        finally:
            self.database.transaction_active = False
            print("ğŸ“ äº‹åŠ¡ç»“æŸ")
    
    def execute_query_safe(self, sql: str) -> Optional[Dict[str, Any]]:
        """å®‰å…¨æ‰§è¡ŒSQLæŸ¥è¯¢"""
        try:
            if self.database.connection_state != DatabaseConnectionState.CONNECTED:
                # å°è¯•é‡æ–°è¿æ¥
                if not self.connect_with_retry():
                    return None
            
            result = self.database.execute_query(sql)
            
            # è®°å½•æŸ¥è¯¢æ—¥å¿—
            self.connection_log.append({
                "timestamp": time.time(),
                "type": "query",
                "sql": sql,
                "status": "success",
                "result": result
            })
            
            return result
            
        except DatabaseError as e:
            print(f"âŒ æŸ¥è¯¢æ‰§è¡Œå¤±è´¥: {e}")
            
            self.connection_log.append({
                "timestamp": time.time(),
                "type": "query",
                "sql": sql,
                "status": "failed",
                "error": str(e),
                "error_type": type(e).__name__
            })
            
            return None
    
    def get_connection_statistics(self) -> Dict[str, Any]:
        """è·å–è¿æ¥ç»Ÿè®¡ä¿¡æ¯"""
        total_connections = len([log for log in self.connection_log if log.get("type") != "query"])
        successful_connections = len([log for log in self.connection_log 
                                    if log.get("status") == "success" and log.get("type") != "query"])
        
        total_queries = len([log for log in self.connection_log if log.get("type") == "query"])
        successful_queries = len([log for log in self.connection_log 
                                if log.get("type") == "query" and log.get("status") == "success"])
        
        error_types = {}
        for log in self.connection_log:
            if log.get("status") == "failed":
                error_type = log.get("error_type", "Unknown")
                error_types[error_type] = error_types.get(error_type, 0) + 1
        
        return {
            "total_connection_attempts": total_connections,
            "successful_connections": successful_connections,
            "total_queries": total_queries,
            "successful_queries": successful_queries,
            "connection_success_rate": successful_connections / total_connections if total_connections > 0 else 0,
            "query_success_rate": successful_queries / total_queries if total_queries > 0 else 0,
            "error_types": error_types,
            "current_state": self.database.connection_state.value
        }

# ç¤ºä¾‹ä½¿ç”¨
def demo_database_manager():
    # æ•°æ®åº“é…ç½®
    config = {
        "host": "localhost",
        "port": 5432,
        "database": "testdb",
        "username": "admin",
        "password": "password123",
        "max_retries": 3,
        "retry_delay": 1.0,
        "success_rate": 0.7  # æ¨¡æ‹Ÿ70%æˆåŠŸç‡
    }
    
    db_manager = DatabaseConnectionManager(config)
    
    # æµ‹è¯•è¿æ¥
    print("=== æµ‹è¯•æ•°æ®åº“è¿æ¥ ===")
    if db_manager.connect_with_retry():
        
        # æµ‹è¯•æ™®é€šæŸ¥è¯¢
        print("\n=== æµ‹è¯•æ™®é€šæŸ¥è¯¢ ===")
        queries = [
            "SELECT * FROM users",
            "SELEC * FROM products",  # è¯­æ³•é”™è¯¯
            "INSERT INTO users VALUES (1, 'duplicate')",  # çº¦æŸè¿å
            "UPDATE users SET name='John' WHERE id=1"
        ]
        
        for sql in queries:
            print(f"\næ‰§è¡ŒæŸ¥è¯¢: {sql}")
            result = db_manager.execute_query_safe(sql)
            if result:
                print(f"æŸ¥è¯¢ç»“æœ: {result}")
        
        # æµ‹è¯•äº‹åŠ¡
        print("\n=== æµ‹è¯•äº‹åŠ¡ç®¡ç† ===")
        try:
            with db_manager.transaction() as transaction_log:
                transaction_log.append("INSERT INTO users VALUES (1, 'Alice')")
                transaction_log.append("INSERT INTO users VALUES (2, 'Bob')")
                
                # æ¨¡æ‹Ÿäº‹åŠ¡ä¸­çš„æ“ä½œ
                for operation in transaction_log:
                    print(f"  æ‰§è¡Œ: {operation}")
                    db_manager.execute_query_safe(operation)
                
                # æ¨¡æ‹Ÿäº‹åŠ¡ä¸­å‘ç”Ÿé”™è¯¯
                if random.random() < 0.3:  # 30%æ¦‚ç‡å‘ç”Ÿé”™è¯¯
                    raise DatabaseError("æ¨¡æ‹Ÿäº‹åŠ¡é”™è¯¯")
                    
        except DatabaseError as e:
            print(f"äº‹åŠ¡å¤„ç†å¼‚å¸¸: {e}")
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    print("\n=== æ•°æ®åº“è¿æ¥ç»Ÿè®¡ ===")
    stats = db_manager.get_connection_statistics()
    for key, value in stats.items():
        print(f"{key}: {value}")

demo_database_manager()
```

### é¢˜ç›®12ï¼šAPIé”™è¯¯å¤„ç†æ¡†æ¶

```python
import json
import time
from enum import Enum
from typing import Dict, Any, Optional, List
from dataclasses import dataclass
from collections import defaultdict

class HTTPStatus(Enum):
    """HTTPçŠ¶æ€ç æšä¸¾"""
    OK = 200
    BAD_REQUEST = 400
    UNAUTHORIZED = 401
    FORBIDDEN = 403
    NOT_FOUND = 404
    INTERNAL_SERVER_ERROR = 500

class ErrorCode(Enum):
    """é”™è¯¯ç æšä¸¾"""
    VALIDATION_ERROR = "VALIDATION_ERROR"
    AUTHENTICATION_FAILED = "AUTHENTICATION_FAILED"
    PERMISSION_DENIED = "PERMISSION_DENIED"
    RESOURCE_NOT_FOUND = "RESOURCE_NOT_FOUND"
    INTERNAL_ERROR = "INTERNAL_ERROR"
    INVALID_INPUT = "INVALID_INPUT"
    DUPLICATE_RESOURCE = "DUPLICATE_RESOURCE"

@dataclass
class ErrorDetail:
    """é”™è¯¯è¯¦ç»†ä¿¡æ¯"""
    field: str
    message: str
    code: Optional[str] = None

class APIError(Exception):
    """APIå¼‚å¸¸åŸºç±»"""
    def __init__(self, 
                 error_code: ErrorCode, 
                 message: str, 
                 http_status: HTTPStatus = HTTPStatus.INTERNAL_SERVER_ERROR,
                 details: List[ErrorDetail] = None,
                 request_id: str = None):
        self.error_code = error_code
        self.message = message
        self.http_status = http_status
        self.details = details or []
        self.request_id = request_id
        self.timestamp = time.time()
        super().__init__(message)

class ValidationError(APIError):
    """å‚æ•°éªŒè¯é”™è¯¯"""
    def __init__(self, message: str, details: List[ErrorDetail] = None, request_id: str = None):
        super().__init__(
            error_code=ErrorCode.VALIDATION_ERROR,
            message=message,
            http_status=HTTPStatus.BAD_REQUEST,
            details=details,
            request_id=request_id
        )

class AuthenticationError(APIError):
    """è®¤è¯å¤±è´¥é”™è¯¯"""
    def __init__(self, message: str = "è®¤è¯å¤±è´¥", request_id: str = None):
        super().__init__(
            error_code=ErrorCode.AUTHENTICATION_FAILED,
            message=message,
            http_status=HTTPStatus.UNAUTHORIZED,
            request_id=request_id
        )

class AuthorizationError(APIError):
    """æƒé™ä¸è¶³é”™è¯¯"""
    def __init__(self, message: str = "æƒé™ä¸è¶³", request_id: str = None):
        super().__init__(
            error_code=ErrorCode.PERMISSION_DENIED,
            message=message,
            http_status=HTTPStatus.FORBIDDEN,
            request_id=request_id
        )

class ResourceNotFoundError(APIError):
    """èµ„æºæœªæ‰¾åˆ°é”™è¯¯"""
    def __init__(self, resource: str, resource_id: str = None, request_id: str = None):
        message = f"èµ„æº {resource}"
        if resource_id:
            message += f" (ID: {resource_id})"
        message += " æœªæ‰¾åˆ°"
        
        super().__init__(
            error_code=ErrorCode.RESOURCE_NOT_FOUND,
            message=message,
            http_status=HTTPStatus.NOT_FOUND,
            request_id=request_id
        )

class InternalServerError(APIError):
    """æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"""
    def __init__(self, message: str = "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯", request_id: str = None):
        super().__init__(
            error_code=ErrorCode.INTERNAL_ERROR,
            message=message,
            http_status=HTTPStatus.INTERNAL_SERVER_ERROR,
            request_id=request_id
        )

class ErrorResponseFormatter:
    """é”™è¯¯å“åº”æ ¼å¼åŒ–å™¨"""
    
    def __init__(self, locale: str = "zh-CN"):
        self.locale = locale
        self.translations = self._load_translations()
    
    def _load_translations(self) -> Dict[str, Dict[str, str]]:
        """åŠ è½½å›½é™…åŒ–æ¶ˆæ¯"""
        return {
            "zh-CN": {
                "VALIDATION_ERROR": "å‚æ•°éªŒè¯å¤±è´¥",
                "AUTHENTICATION_FAILED": "è®¤è¯å¤±è´¥",
                "PERMISSION_DENIED": "æƒé™ä¸è¶³",
                "RESOURCE_NOT_FOUND": "èµ„æºæœªæ‰¾åˆ°",
                "INTERNAL_ERROR": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯",
                "INVALID_INPUT": "è¾“å…¥å‚æ•°æ— æ•ˆ",
                "DUPLICATE_RESOURCE": "èµ„æºå·²å­˜åœ¨"
            },
            "en-US": {
                "VALIDATION_ERROR": "Validation failed",
                "AUTHENTICATION_FAILED": "Authentication failed",
                "PERMISSION_DENIED": "Permission denied",
                "RESOURCE_NOT_FOUND": "Resource not found",
                "INTERNAL_ERROR": "Internal server error",
                "INVALID_INPUT": "Invalid input",
                "DUPLICATE_RESOURCE": "Resource already exists"
            }
        }
    
    def format_error_response(self, error: APIError) -> Dict[str, Any]:
        """æ ¼å¼åŒ–é”™è¯¯å“åº”"""
        # è·å–æœ¬åœ°åŒ–æ¶ˆæ¯
        translated_message = self.translations.get(self.locale, {}).get(
            error.error_code.value, 
            error.message
        )
        
        response = {
            "error": {
                "code": error.error_code.value,
                "message": translated_message,
                "timestamp": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime(error.timestamp)),
                "request_id": error.request_id or self._generate_request_id()
            }
        }
        
        # æ·»åŠ è¯¦ç»†é”™è¯¯ä¿¡æ¯
        if error.details:
            response["error"]["details"] = [
                {
                    "field": detail.field,
                    "message": detail.message,
                    "code": detail.code
                }
                for detail in error.details
            ]
        
        return response
    
    def _generate_request_id(self) -> str:
        """ç”Ÿæˆè¯·æ±‚ID"""
        import uuid
        return str(uuid.uuid4())[:8]

class ErrorStatistics:
    """é”™è¯¯ç»Ÿè®¡"""
    
    def __init__(self):
        self.error_counts = defaultdict(int)
        self.error_history = []
        self.hourly_stats = defaultdict(lambda: defaultdict(int))
    
    def record_error(self, error: APIError):
        """è®°å½•é”™è¯¯"""
        # ç»Ÿè®¡é”™è¯¯ç±»å‹
        self.error_counts[error.error_code.value] += 1
        
        # è®°å½•é”™è¯¯å†å²
        self.error_history.append({
            "timestamp": error.timestamp,
            "error_code": error.error_code.value,
            "http_status": error.http_status.value,
            "message": error.message,
            "request_id": error.request_id
        })
        
        # æŒ‰å°æ—¶ç»Ÿè®¡
        hour = int(error.timestamp // 3600)
        self.hourly_stats[hour][error.error_code.value] += 1
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        total_errors = sum(self.error_counts.values())
        
        if total_errors == 0:
            return {"total_errors": 0}
        
        # è®¡ç®—é”™è¯¯ç‡
        error_rates = {
            error_type: count / total_errors
            for error_type, count in self.error_counts.items()
        }
        
        # æœ€è¿‘1å°æ—¶çš„é”™è¯¯
        current_hour = int(time.time() // 3600)
        recent_errors = self.hourly_stats.get(current_hour, {})
        
        return {
            "total_errors": total_errors,
            "error_counts": dict(self.error_counts),
            "error_rates": error_rates,
            "recent_errors": dict(recent_errors),
            "most_common_error": max(self.error_counts.items(), key=lambda x: x[1])[0] if self.error_counts else None
        }

class APIErrorHandler:
    """APIé”™è¯¯å¤„ç†å™¨"""
    
    def __init__(self, locale: str = "zh-CN"):
        self.formatter = ErrorResponseFormatter(locale)
        self.statistics = ErrorStatistics()
    
    def handle_error(self, error: Exception, request_id: str = None) -> tuple[Dict[str, Any], int]:
        """å¤„ç†é”™è¯¯å¹¶è¿”å›å“åº”"""
        # å°†æ™®é€šå¼‚å¸¸è½¬æ¢ä¸ºAPIError
        if not isinstance(error, APIError):
            if isinstance(error, ValueError):
                api_error = ValidationError(str(error), request_id=request_id)
            elif isinstance(error, PermissionError):
                api_error = AuthorizationError(str(error), request_id=request_id)
            elif isinstance(error, FileNotFoundError):
                api_error = ResourceNotFoundError("æ–‡ä»¶", request_id=request_id)
            else:
                api_error = InternalServerError(f"æœªçŸ¥é”™è¯¯: {str(error)}", request_id=request_id)
        else:
            api_error = error
        
        # è®°å½•é”™è¯¯ç»Ÿè®¡
        self.statistics.record_error(api_error)
        
        # æ ¼å¼åŒ–å“åº”
        response = self.formatter.format_error_response(api_error)
        
        return response, api_error.http_status.value

# ç¤ºä¾‹ä½¿ç”¨å’Œæµ‹è¯•
def demo_api_error_handler():
    handler = APIErrorHandler("zh-CN")
    
    # æµ‹è¯•ä¸åŒç±»å‹çš„é”™è¯¯
    test_errors = [
        ValidationError(
            "ç”¨æˆ·æ•°æ®éªŒè¯å¤±è´¥",
            details=[
                ErrorDetail("email", "é‚®ç®±æ ¼å¼ä¸æ­£ç¡®", "INVALID_EMAIL"),
                ErrorDetail("age", "å¹´é¾„å¿…é¡»åœ¨18-100ä¹‹é—´", "INVALID_RANGE")
            ],
            request_id="req_001"
        ),
        AuthenticationError("JWT tokenå·²è¿‡æœŸ", request_id="req_002"),
        AuthorizationError("éœ€è¦ç®¡ç†å‘˜æƒé™", request_id="req_003"),
        ResourceNotFoundError("ç”¨æˆ·", "12345", request_id="req_004"),
        InternalServerError("æ•°æ®åº“è¿æ¥å¤±è´¥", request_id="req_005"),
        
        # æ™®é€šå¼‚å¸¸
        ValueError("æ— æ•ˆçš„å‚æ•°å€¼"),
        PermissionError("æ–‡ä»¶è®¿é—®æƒé™ä¸è¶³"),
        FileNotFoundError("é…ç½®æ–‡ä»¶ä¸å­˜åœ¨")
    ]
    
    print("=== APIé”™è¯¯å¤„ç†æµ‹è¯• ===")
    for i, error in enumerate(test_errors, 1):
        print(f"\n--- æµ‹è¯• {i}: {type(error).__name__} ---")
        response, status_code = handler.handle_error(error, f"req_{i:03d}")
        
        print(f"HTTPçŠ¶æ€ç : {status_code}")
        print(f"å“åº”å†…å®¹: {json.dumps(response, ensure_ascii=False, indent=2)}")
    
    # æ˜¾ç¤ºé”™è¯¯ç»Ÿè®¡
    print("\n=== é”™è¯¯ç»Ÿè®¡ä¿¡æ¯ ===")
    stats = handler.statistics.get_statistics()
    print(json.dumps(stats, ensure_ascii=False, indent=2))
    
    # æµ‹è¯•å›½é™…åŒ–
    print("\n=== å›½é™…åŒ–æµ‹è¯• ===")
    en_handler = APIErrorHandler("en-US")
    error = ValidationError("æµ‹è¯•é”™è¯¯", request_id="req_i18n")
    response, _ = en_handler.handle_error(error)
    print("è‹±æ–‡å“åº”:", json.dumps(response, indent=2))

demo_api_error_handler()
``` 