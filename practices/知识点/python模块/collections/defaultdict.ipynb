{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Python Collections.defaultdict å®Œå…¨æŒ‡å—\n",
    "\n",
    "## ğŸ“š å­¦ä¹ ç›®æ ‡\n",
    "- ç†è§£ defaultdict çš„å·¥ä½œåŸç†å’Œä¼˜åŠ¿\n",
    "- æŒæ¡ defaultdict çš„åŸºæœ¬ç”¨æ³•å’Œè¯­æ³•\n",
    "- å­¦ä¼šåœ¨å®é™…é¡¹ç›®ä¸­åº”ç”¨ defaultdict\n",
    "- äº†è§£æ€§èƒ½ä¼˜åŒ–å’Œæœ€ä½³å®è·µ\n",
    "- æŒæ¡å¸¸è§çš„ä½¿ç”¨åœºæ™¯å’Œè®¾è®¡æ¨¡å¼\n",
    "\n",
    "## ğŸ¯ é€‚ç”¨åœºæ™¯\n",
    "- åˆ†ç»„æ•°æ®å¤„ç†\n",
    "- ç»Ÿè®¡è®¡æ•°\n",
    "- åµŒå¥—æ•°æ®ç»“æ„æ„å»º\n",
    "- é¿å… KeyError å¼‚å¸¸\n",
    "- åç«¯æ•°æ®èšåˆå’Œå¤„ç†\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 1. åŸºç¡€æ¦‚å¿µå¯¹æ¯”\n",
    "\n",
    "### æ™®é€š dict vs defaultdict\n",
    "æ™®é€šå­—å…¸åœ¨è®¿é—®ä¸å­˜åœ¨çš„é”®æ—¶ä¼šæŠ›å‡º `KeyError`ï¼Œè€Œ `defaultdict` ä¼šè‡ªåŠ¨åˆ›å»ºé»˜è®¤å€¼ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== æ™®é€šå­—å…¸çš„ KeyError é—®é¢˜ ===\n",
      "KeyError: 'users'\n",
      "æ™®é€šå­—å…¸ç»“æœ: {'users': ['å¼ ä¸‰']}\n",
      "\n",
      "=== defaultdict çš„ä¼˜é›…è§£å†³æ–¹æ¡ˆ ===\n",
      "default_dict: defaultdict(<class 'list'>, {})\n",
      "defaultdict ç»“æœ: {'users': ['å¼ ä¸‰', 'æå››'], 'admins': ['ç‹äº”']}\n",
      "ç±»å‹: <class 'collections.defaultdict'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Set, Any\n",
    "import json\n",
    "\n",
    "# æ™®é€šå­—å…¸çš„é—®é¢˜æ¼”ç¤º\n",
    "print(\"=== æ™®é€šå­—å…¸çš„ KeyError é—®é¢˜ ===\")\n",
    "normal_dict: Dict[str, List[str]] = {}\n",
    "\n",
    "try:\n",
    "    # è¿™ä¼šæŠ›å‡º KeyError\n",
    "    normal_dict['users'].append('å¼ ä¸‰')\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {e}\")\n",
    "    \n",
    "# ä¼ ç»Ÿè§£å†³æ–¹æ¡ˆï¼šéœ€è¦æ£€æŸ¥é”®æ˜¯å¦å­˜åœ¨\n",
    "if 'users' not in normal_dict:\n",
    "    normal_dict['users'] = []\n",
    "normal_dict['users'].append('å¼ ä¸‰')\n",
    "print(f\"æ™®é€šå­—å…¸ç»“æœ: {normal_dict}\")\n",
    "\n",
    "print(\"\\n=== defaultdict çš„ä¼˜é›…è§£å†³æ–¹æ¡ˆ ===\")\n",
    "# defaultdict è‡ªåŠ¨åˆ›å»ºé»˜è®¤å€¼\n",
    "default_dict = defaultdict(list)  # é»˜è®¤å·¥å‚å‡½æ•°æ˜¯ list\n",
    "print('default_dict:',default_dict)\n",
    "default_dict['users'].append('å¼ ä¸‰')  # ä¸ä¼šæŠ›å‡ºå¼‚å¸¸\n",
    "default_dict['users'].append('æå››')\n",
    "default_dict['admins'].append('ç‹äº”')\n",
    "\n",
    "print(f\"defaultdict ç»“æœ: {dict(default_dict)}\")\n",
    "print(f\"ç±»å‹: {type(default_dict)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ¤”ç–‘é—®ï¼š\n",
    "\n",
    "`default_dict = defaultdict(list)`è¿™è¡Œä»£ç åœ¨åšä»€ä¹ˆå‘¢?\n",
    "\n",
    "è¿™è¡Œä»£ç åˆ›å»ºäº†ä¸€ä¸ªç‰¹æ®Šçš„å­—å…¸default_dictï¼Œå½“è®¿é—®ä¸å­˜åœ¨çš„é”®æ—¶ï¼Œä¼šè‡ªåŠ¨åˆ›å»ºä¸€ä¸ªç©ºåˆ—è¡¨[]ä½œä¸ºé»˜è®¤å€¼ã€‚è¿™æ¯”æ™®é€šå­—å…¸æ›´æ–¹ä¾¿ï¼Œå› ä¸ºä¸éœ€è¦æ‰‹åŠ¨æ£€æŸ¥é”®æ˜¯å¦å­˜åœ¨ã€‚\n",
    "\n",
    "åŸå› ï¼šlistä½œä¸ºå·¥å‚å‡½æ•°ä¼ å…¥defaultdictï¼Œå®ƒä¼šåœ¨éœ€è¦æ—¶è‡ªåŠ¨è°ƒç”¨list()æ¥åˆ›å»ºæ–°çš„ç©ºåˆ—è¡¨ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2. å¸¸ç”¨å·¥å‚å‡½æ•°\n",
    "\n",
    "`defaultdict` çš„ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯å·¥å‚å‡½æ•°ï¼Œå†³å®šäº†é»˜è®¤å€¼çš„ç±»å‹ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ä¸åŒå·¥å‚å‡½æ•°çš„ä½¿ç”¨ ===\n",
      "defaultdict(list) é»˜è®¤å€¼: []\n",
      "defaultdict(int) é»˜è®¤å€¼: 0\n",
      "defaultdict(set) é»˜è®¤å€¼: set()\n",
      "defaultdict(dict) é»˜è®¤å€¼: {}\n",
      "è‡ªå®šä¹‰å·¥å‚å‡½æ•°é»˜è®¤å€¼: æœªè®¾ç½®\n",
      "lambda å·¥å‚å‡½æ•°é»˜è®¤å€¼: {'status': 'active', 'count': 0}\n",
      "\n",
      "æ‰€æœ‰ defaultdict å†…å®¹:\n",
      "groups: {'new_key': []}\n",
      "counters: {'new_key': 0}\n",
      "unique_items: {'new_key': set()}\n",
      "nested: {'new_key': {}}\n",
      "custom_default: {'new_key': 'æœªè®¾ç½®'}\n",
      "lambda_default: {'new_key': {'status': 'active', 'count': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(\"=== ä¸åŒå·¥å‚å‡½æ•°çš„ä½¿ç”¨ ===\")\n",
    "\n",
    "# 1. list - ç”¨äºåˆ†ç»„æ•°æ®\n",
    "groups = defaultdict(list)\n",
    "print(f\"defaultdict(list) é»˜è®¤å€¼: {groups['new_key']}\")\n",
    "\n",
    "# 2. int - ç”¨äºè®¡æ•°\n",
    "counters = defaultdict(int)\n",
    "print(f\"defaultdict(int) é»˜è®¤å€¼: {counters['new_key']}\")\n",
    "\n",
    "# 3. set - ç”¨äºå»é‡æ”¶é›†\n",
    "unique_items = defaultdict(set)\n",
    "print(f\"defaultdict(set) é»˜è®¤å€¼: {unique_items['new_key']}\")\n",
    "\n",
    "# 4. dict - ç”¨äºåµŒå¥—å­—å…¸\n",
    "nested = defaultdict(dict)\n",
    "print(f\"defaultdict(dict) é»˜è®¤å€¼: {nested['new_key']}\")\n",
    "\n",
    "# 5. è‡ªå®šä¹‰å·¥å‚å‡½æ•°\n",
    "def default_value():\n",
    "    return \"æœªè®¾ç½®\"\n",
    "\n",
    "custom_default = defaultdict(default_value)\n",
    "print(f\"è‡ªå®šä¹‰å·¥å‚å‡½æ•°é»˜è®¤å€¼: {custom_default['new_key']}\")\n",
    "\n",
    "# 6. lambda è¡¨è¾¾å¼ä½œä¸ºå·¥å‚å‡½æ•°\n",
    "lambda_default = defaultdict(lambda: {'status': 'active', 'count': 0})\n",
    "print(f\"lambda å·¥å‚å‡½æ•°é»˜è®¤å€¼: {lambda_default['new_key']}\")\n",
    "\n",
    "print(f\"\\næ‰€æœ‰ defaultdict å†…å®¹:\")\n",
    "print(f\"groups: {dict(groups)}\")\n",
    "print(f\"counters: {dict(counters)}\")\n",
    "print(f\"unique_items: {dict(unique_items)}\")\n",
    "print(f\"nested: {dict(nested)}\")\n",
    "print(f\"custom_default: {dict(custom_default)}\")\n",
    "print(f\"lambda_default: {dict(lambda_default)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3. å®é™…åº”ç”¨åœºæ™¯\n",
    "\n",
    "### åœºæ™¯1ï¼šæ•°æ®åˆ†ç»„ - æŒ‰éƒ¨é—¨åˆ†ç»„å‘˜å·¥\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ä½¿ç”¨ defaultdict æŒ‰éƒ¨é—¨åˆ†ç»„å‘˜å·¥ ===\n",
      "æŒ‰éƒ¨é—¨åˆ†ç»„ emp: {'name': 'å¼ ä¸‰', 'department': 'æŠ€æœ¯éƒ¨', 'salary': 15000}\n",
      "æŒ‰éƒ¨é—¨åˆ†ç»„ emp: {'name': 'æå››', 'department': 'é”€å”®éƒ¨', 'salary': 12000}\n",
      "æŒ‰éƒ¨é—¨åˆ†ç»„ emp: {'name': 'ç‹äº”', 'department': 'æŠ€æœ¯éƒ¨', 'salary': 18000}\n",
      "æŒ‰éƒ¨é—¨åˆ†ç»„ emp: {'name': 'èµµå…­', 'department': 'äººäº‹éƒ¨', 'salary': 10000}\n",
      "æŒ‰éƒ¨é—¨åˆ†ç»„ emp: {'name': 'é’±ä¸ƒ', 'department': 'é”€å”®éƒ¨', 'salary': 13000}\n",
      "æŒ‰éƒ¨é—¨åˆ†ç»„ emp: {'name': 'å­™å…«', 'department': 'æŠ€æœ¯éƒ¨', 'salary': 16000}\n",
      "æŒ‰éƒ¨é—¨åˆ†ç»„åï¼Œdepartment_groups: defaultdict(<class 'list'>, {'æŠ€æœ¯éƒ¨': [{'name': 'å¼ ä¸‰', 'department': 'æŠ€æœ¯éƒ¨', 'salary': 15000}, {'name': 'ç‹äº”', 'department': 'æŠ€æœ¯éƒ¨', 'salary': 18000}, {'name': 'å­™å…«', 'department': 'æŠ€æœ¯éƒ¨', 'salary': 16000}], 'é”€å”®éƒ¨': [{'name': 'æå››', 'department': 'é”€å”®éƒ¨', 'salary': 12000}, {'name': 'é’±ä¸ƒ', 'department': 'é”€å”®éƒ¨', 'salary': 13000}], 'äººäº‹éƒ¨': [{'name': 'èµµå…­', 'department': 'äººäº‹éƒ¨', 'salary': 10000}]})\n",
      "\n",
      "æŠ€æœ¯éƒ¨:\n",
      "  - å¼ ä¸‰: Â¥15,000\n",
      "  - ç‹äº”: Â¥18,000\n",
      "  - å­™å…«: Â¥16,000\n",
      "\n",
      "é”€å”®éƒ¨:\n",
      "  - æå››: Â¥12,000\n",
      "  - é’±ä¸ƒ: Â¥13,000\n",
      "\n",
      "äººäº‹éƒ¨:\n",
      "  - èµµå…­: Â¥10,000\n",
      "\n",
      "å„éƒ¨é—¨å¹³å‡è–ªèµ„:\n",
      "æŠ€æœ¯éƒ¨: Â¥16,333\n",
      "é”€å”®éƒ¨: Â¥12,500\n",
      "äººäº‹éƒ¨: Â¥10,000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# æ¨¡æ‹Ÿå‘˜å·¥æ•°æ®\n",
    "employees = [\n",
    "    {'name': 'å¼ ä¸‰', 'department': 'æŠ€æœ¯éƒ¨', 'salary': 15000},\n",
    "    {'name': 'æå››', 'department': 'é”€å”®éƒ¨', 'salary': 12000},\n",
    "    {'name': 'ç‹äº”', 'department': 'æŠ€æœ¯éƒ¨', 'salary': 18000},\n",
    "    {'name': 'èµµå…­', 'department': 'äººäº‹éƒ¨', 'salary': 10000},\n",
    "    {'name': 'é’±ä¸ƒ', 'department': 'é”€å”®éƒ¨', 'salary': 13000},\n",
    "    {'name': 'å­™å…«', 'department': 'æŠ€æœ¯éƒ¨', 'salary': 16000},\n",
    "]\n",
    "\n",
    "print(\"=== ä½¿ç”¨ defaultdict æŒ‰éƒ¨é—¨åˆ†ç»„å‘˜å·¥ ===\")\n",
    "\n",
    "# æŒ‰éƒ¨é—¨åˆ†ç»„\n",
    "department_groups = defaultdict(list)\n",
    "for emp in employees:\n",
    "    print('æŒ‰éƒ¨é—¨åˆ†ç»„ emp:',emp)\n",
    "    department_groups[emp['department']].append(emp)\n",
    "print('æŒ‰éƒ¨é—¨åˆ†ç»„åï¼Œdepartment_groups:',department_groups)\n",
    "# æ˜¾ç¤ºåˆ†ç»„ç»“æœ\n",
    "for dept, emps in department_groups.items():\n",
    "    print(f\"\\n{dept}:\")\n",
    "    for emp in emps:\n",
    "        print(f\"  - {emp['name']}: Â¥{emp['salary']:,}\")\n",
    "\n",
    "# è®¡ç®—å„éƒ¨é—¨å¹³å‡è–ªèµ„\n",
    "dept_avg_salary = {}\n",
    "for dept, emps in department_groups.items():\n",
    "    avg_salary = sum(emp['salary'] for emp in emps) / len(emps)\n",
    "    dept_avg_salary[dept] = avg_salary\n",
    "\n",
    "print(f\"\\nå„éƒ¨é—¨å¹³å‡è–ªèµ„:\")\n",
    "for dept, avg in dept_avg_salary.items():\n",
    "    print(f\"{dept}: Â¥{avg:,.0f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### åœºæ™¯2ï¼šç»Ÿè®¡è®¡æ•° - æ–‡æœ¬è¯é¢‘åˆ†æ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Counter\n",
    "\n",
    "# ç¤ºä¾‹æ–‡æœ¬\n",
    "text = \"\"\"\n",
    "Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼ŒPythonè¯­æ³•ç®€æ´æ˜äº†ã€‚\n",
    "Pythonå¹¿æ³›åº”ç”¨äºæ•°æ®ç§‘å­¦ã€ç½‘ç«™å¼€å‘ã€è‡ªåŠ¨åŒ–ç­‰é¢†åŸŸã€‚\n",
    "å­¦ä¹ Pythonå¯ä»¥æé«˜ç¼–ç¨‹æ•ˆç‡ï¼ŒPythonç¤¾åŒºä¹Ÿéå¸¸æ´»è·ƒã€‚\n",
    "\"\"\"\n",
    "\n",
    "print(\"=== ä½¿ç”¨ defaultdict è¿›è¡Œè¯é¢‘ç»Ÿè®¡ ===\")\n",
    "\n",
    "# æ–¹æ³•1ï¼šä½¿ç”¨ defaultdict(int)\n",
    "word_count = defaultdict(int)\n",
    "words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "\n",
    "for word in words:\n",
    "    word_count[word] += 1\n",
    "\n",
    "print(\"è¯é¢‘ç»Ÿè®¡ç»“æœï¼ˆå‰10ä¸ªï¼‰:\")\n",
    "# æŒ‰é¢‘ç‡æ’åº\n",
    "sorted_words = sorted(word_count.items(), key=lambda x: x[1], reverse=True)\n",
    "for word, count in sorted_words[:10]:\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "print(f\"\\næ€»è¯æ•°: {sum(word_count.values())}\")\n",
    "print(f\"å”¯ä¸€è¯æ•°: {len(word_count)}\")\n",
    "\n",
    "# æ–¹æ³•2ï¼šå¯¹æ¯” - ä½¿ç”¨ Counterï¼ˆcollections æ¨¡å—çš„å¦ä¸€ä¸ªå·¥å…·ï¼‰\n",
    "from collections import Counter\n",
    "counter_result = Counter(words)\n",
    "print(f\"\\nä½¿ç”¨ Counter çš„ç»“æœï¼ˆå‰5ä¸ªï¼‰: {counter_result.most_common(5)}\")\n",
    "\n",
    "# ç»Ÿè®¡å­—ç¬¦é¢‘ç‡\n",
    "char_count = defaultdict(int)\n",
    "for char in text:\n",
    "    if char.isalpha():  # åªç»Ÿè®¡å­—æ¯\n",
    "        char_count[char.lower()] += 1\n",
    "\n",
    "print(f\"\\nå­—ç¬¦é¢‘ç‡ï¼ˆå‰10ä¸ªï¼‰:\")\n",
    "sorted_chars = sorted(char_count.items(), key=lambda x: x[1], reverse=True)\n",
    "for char, count in sorted_chars[:10]:\n",
    "    print(f\"'{char}': {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### åœºæ™¯3ï¼šåµŒå¥—æ•°æ®ç»“æ„ - å¤šçº§åˆ†ç±»ç³»ç»Ÿ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== åµŒå¥— defaultdict æ„å»ºå¤šçº§åˆ†ç±» ===\")\n",
    "\n",
    "# åˆ›å»ºåµŒå¥—çš„ defaultdict\n",
    "# ç¬¬ä¸€çº§ï¼šæŒ‰å¹´ä»½åˆ†ç»„ï¼Œç¬¬äºŒçº§ï¼šæŒ‰æœˆä»½åˆ†ç»„ï¼Œç¬¬ä¸‰çº§ï¼šæŒ‰æ—¥æœŸåˆ†ç»„\n",
    "def nested_dict():\n",
    "    return defaultdict(list)\n",
    "\n",
    "def monthly_dict():\n",
    "    return defaultdict(nested_dict)\n",
    "\n",
    "yearly_data = defaultdict(monthly_dict)\n",
    "\n",
    "# æ¨¡æ‹Ÿæ—¥å¿—æ•°æ®\n",
    "log_entries = [\n",
    "    {'date': '2024-01-15', 'level': 'INFO', 'message': 'ç”¨æˆ·ç™»å½•æˆåŠŸ'},\n",
    "    {'date': '2024-01-15', 'level': 'ERROR', 'message': 'æ•°æ®åº“è¿æ¥å¤±è´¥'},\n",
    "    {'date': '2024-01-16', 'level': 'INFO', 'message': 'ç³»ç»Ÿå¯åŠ¨'},\n",
    "    {'date': '2024-02-01', 'level': 'WARNING', 'message': 'å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜'},\n",
    "    {'date': '2024-02-01', 'level': 'INFO', 'message': 'å®šæ—¶ä»»åŠ¡æ‰§è¡Œ'},\n",
    "    {'date': '2023-12-25', 'level': 'INFO', 'message': 'èŠ‚æ—¥é—®å€™'},\n",
    "]\n",
    "\n",
    "# æŒ‰å¹´-æœˆ-æ—¥åˆ†ç±»å­˜å‚¨æ—¥å¿—\n",
    "for entry in log_entries:\n",
    "    date_parts = entry['date'].split('-')\n",
    "    year, month, day = date_parts[0], date_parts[1], date_parts[2]\n",
    "    \n",
    "    yearly_data[year][month][day].append({\n",
    "        'level': entry['level'],\n",
    "        'message': entry['message']\n",
    "    })\n",
    "\n",
    "# æ˜¾ç¤ºåˆ†ç±»ç»“æœ\n",
    "print(\"æŒ‰å¹´-æœˆ-æ—¥åˆ†ç±»çš„æ—¥å¿—:\")\n",
    "for year, months in yearly_data.items():\n",
    "    print(f\"\\n{year}å¹´:\")\n",
    "    for month, days in months.items():\n",
    "        print(f\"  {month}æœˆ:\")\n",
    "        for day, logs in days.items():\n",
    "            print(f\"    {day}æ—¥ ({len(logs)}æ¡æ—¥å¿—):\")\n",
    "            for log in logs:\n",
    "                print(f\"      [{log['level']}] {log['message']}\")\n",
    "\n",
    "# ç»Ÿè®¡å„çº§åˆ«æ—¥å¿—æ•°é‡\n",
    "level_stats = defaultdict(int)\n",
    "for year, months in yearly_data.items():\n",
    "    for month, days in months.items():\n",
    "        for day, logs in days.items():\n",
    "            for log in logs:\n",
    "                level_stats[log['level']] += 1\n",
    "\n",
    "print(f\"\\næ—¥å¿—çº§åˆ«ç»Ÿè®¡:\")\n",
    "for level, count in level_stats.items():\n",
    "    print(f\"{level}: {count}æ¡\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### åœºæ™¯4ï¼šAPI æ•°æ®èšåˆ - ç”¨æˆ·è¡Œä¸ºåˆ†æ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "print(\"=== API æ•°æ®èšåˆæ¡ˆä¾‹ ===\")\n",
    "\n",
    "# æ¨¡æ‹Ÿç”¨æˆ·è¡Œä¸ºæ•°æ®\n",
    "def generate_user_actions():\n",
    "    \"\"\"ç”Ÿæˆæ¨¡æ‹Ÿçš„ç”¨æˆ·è¡Œä¸ºæ•°æ®\"\"\"\n",
    "    actions = ['ç™»å½•', 'æµè§ˆå•†å“', 'åŠ å…¥è´­ç‰©è½¦', 'ä¸‹å•', 'æ”¯ä»˜', 'è¯„ä»·']\n",
    "    users = [f'user_{i:03d}' for i in range(1, 21)]  # 20ä¸ªç”¨æˆ·\n",
    "    \n",
    "    data = []\n",
    "    base_date = datetime.now() - timedelta(days=7)  # æœ€è¿‘7å¤©\n",
    "    \n",
    "    for day in range(7):\n",
    "        current_date = base_date + timedelta(days=day)\n",
    "        for _ in range(random.randint(20, 50)):  # æ¯å¤©20-50ä¸ªè¡Œä¸º\n",
    "            data.append({\n",
    "                'user_id': random.choice(users),\n",
    "                'action': random.choice(actions),\n",
    "                'timestamp': current_date.strftime('%Y-%m-%d'),\n",
    "                'value': random.randint(1, 1000)  # å•†å“ä»·å€¼æˆ–å…¶ä»–æŒ‡æ ‡\n",
    "            })\n",
    "    return data\n",
    "\n",
    "user_actions = generate_user_actions()\n",
    "\n",
    "# ä½¿ç”¨ defaultdict è¿›è¡Œæ•°æ®èšåˆ\n",
    "print(\"1. æŒ‰ç”¨æˆ·èšåˆè¡Œä¸º:\")\n",
    "user_behavior = defaultdict(lambda: defaultdict(int))\n",
    "user_values = defaultdict(list)\n",
    "\n",
    "for action in user_actions:\n",
    "    user_id = action['user_id']\n",
    "    action_type = action['action']\n",
    "    value = action['value']\n",
    "    \n",
    "    user_behavior[user_id][action_type] += 1\n",
    "    user_values[user_id].append(value)\n",
    "\n",
    "# æ˜¾ç¤ºç”¨æˆ·è¡Œä¸ºç»Ÿè®¡ï¼ˆå‰5ä¸ªç”¨æˆ·ï¼‰\n",
    "for i, (user_id, behaviors) in enumerate(user_behavior.items()):\n",
    "    if i >= 5:  # åªæ˜¾ç¤ºå‰5ä¸ª\n",
    "        break\n",
    "    print(f\"\\n{user_id}:\")\n",
    "    for action, count in behaviors.items():\n",
    "        print(f\"  {action}: {count}æ¬¡\")\n",
    "    avg_value = sum(user_values[user_id]) / len(user_values[user_id])\n",
    "    print(f\"  å¹³å‡ä»·å€¼: {avg_value:.2f}\")\n",
    "\n",
    "# 2. æŒ‰æ—¥æœŸèšåˆ\n",
    "print(f\"\\n2. æŒ‰æ—¥æœŸèšåˆæ´»è·ƒåº¦:\")\n",
    "daily_activity = defaultdict(lambda: defaultdict(int))\n",
    "daily_users = defaultdict(set)\n",
    "\n",
    "for action in user_actions:\n",
    "    date = action['timestamp']\n",
    "    action_type = action['action']\n",
    "    user_id = action['user_id']\n",
    "    \n",
    "    daily_activity[date][action_type] += 1\n",
    "    daily_users[date].add(user_id)\n",
    "\n",
    "for date, activities in sorted(daily_activity.items()):\n",
    "    print(f\"\\n{date}:\")\n",
    "    print(f\"  æ´»è·ƒç”¨æˆ·æ•°: {len(daily_users[date])}\")\n",
    "    for action, count in activities.items():\n",
    "        print(f\"  {action}: {count}æ¬¡\")\n",
    "\n",
    "# 3. è®¡ç®—è½¬åŒ–ç‡ï¼ˆä»æµè§ˆåˆ°è´­ä¹°ï¼‰\n",
    "print(f\"\\n3. ç”¨æˆ·è½¬åŒ–åˆ†æ:\")\n",
    "conversion_data = defaultdict(lambda: {'æµè§ˆå•†å“': 0, 'ä¸‹å•': 0, 'æ”¯ä»˜': 0})\n",
    "\n",
    "for action in user_actions:\n",
    "    user_id = action['user_id']\n",
    "    action_type = action['action']\n",
    "    \n",
    "    if action_type in conversion_data[user_id]:\n",
    "        conversion_data[user_id][action_type] += 1\n",
    "\n",
    "# è®¡ç®—è½¬åŒ–ç‡\n",
    "browse_users = 0\n",
    "order_users = 0\n",
    "pay_users = 0\n",
    "\n",
    "for user_id, actions in conversion_data.items():\n",
    "    if actions['æµè§ˆå•†å“'] > 0:\n",
    "        browse_users += 1\n",
    "        if actions['ä¸‹å•'] > 0:\n",
    "            order_users += 1\n",
    "            if actions['æ”¯ä»˜'] > 0:\n",
    "                pay_users += 1\n",
    "\n",
    "print(f\"æµè§ˆç”¨æˆ·æ•°: {browse_users}\")\n",
    "print(f\"ä¸‹å•ç”¨æˆ·æ•°: {order_users}\")\n",
    "print(f\"æ”¯ä»˜ç”¨æˆ·æ•°: {pay_users}\")\n",
    "if browse_users > 0:\n",
    "    print(f\"æµè§ˆ->ä¸‹å•è½¬åŒ–ç‡: {order_users/browse_users*100:.1f}%\")\n",
    "if order_users > 0:\n",
    "    print(f\"ä¸‹å•->æ”¯ä»˜è½¬åŒ–ç‡: {pay_users/order_users*100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. é«˜çº§åº”ç”¨ï¼šç”Ÿäº§çº§ä»£ç ç¤ºä¾‹\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Dict, List, Optional, DefaultDict\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "\n",
    "# é…ç½®æ—¥å¿—\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"=== ç”Ÿäº§çº§ä»£ç ï¼šç¼“å­˜ç³»ç»Ÿå’Œæ•°æ®èšåˆå™¨ ===\")\n",
    "\n",
    "class CacheStrategy(Enum):\n",
    "    \"\"\"ç¼“å­˜ç­–ç•¥æšä¸¾\"\"\"\n",
    "    LRU = \"lru\"\n",
    "    LFU = \"lfu\"\n",
    "    TTL = \"ttl\"\n",
    "\n",
    "@dataclass\n",
    "class CacheStats:\n",
    "    \"\"\"ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯\"\"\"\n",
    "    hits: int = 0\n",
    "    misses: int = 0\n",
    "    evictions: int = 0\n",
    "    \n",
    "    @property\n",
    "    def hit_rate(self) -> float:\n",
    "        total = self.hits + self.misses\n",
    "        return (self.hits / total * 100) if total > 0 else 0.0\n",
    "\n",
    "class ProductionCacheManager:\n",
    "    \"\"\"ç”Ÿäº§çº§ç¼“å­˜ç®¡ç†å™¨ï¼Œä½¿ç”¨ defaultdict ä¼˜åŒ–æ•°æ®ç»“æ„\"\"\"\n",
    "    \n",
    "    def __init__(self, max_size: int = 1000):\n",
    "        self.max_size = max_size\n",
    "        \n",
    "        # ä½¿ç”¨ defaultdict ç®€åŒ–æ•°æ®ç»“æ„ç®¡ç†\n",
    "        self.cache_data: DefaultDict[str, Dict] = defaultdict(dict)\n",
    "        self.access_counts: DefaultDict[str, int] = defaultdict(int)\n",
    "        self.access_times: DefaultDict[str, List[float]] = defaultdict(list)\n",
    "        self.namespace_stats: DefaultDict[str, CacheStats] = defaultdict(CacheStats)\n",
    "        \n",
    "        logger.info(f\"ç¼“å­˜ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆï¼Œæœ€å¤§å®¹é‡: {max_size}\")\n",
    "    \n",
    "    def get(self, namespace: str, key: str) -> Optional[any]:\n",
    "        \"\"\"è·å–ç¼“å­˜æ•°æ®\"\"\"\n",
    "        if key in self.cache_data[namespace]:\n",
    "            self.access_counts[namespace + \":\" + key] += 1\n",
    "            self.namespace_stats[namespace].hits += 1\n",
    "            \n",
    "            logger.debug(f\"ç¼“å­˜å‘½ä¸­: {namespace}:{key}\")\n",
    "            return self.cache_data[namespace][key]\n",
    "        \n",
    "        self.namespace_stats[namespace].misses += 1\n",
    "        logger.debug(f\"ç¼“å­˜æœªå‘½ä¸­: {namespace}:{key}\")\n",
    "        return None\n",
    "    \n",
    "    def set(self, namespace: str, key: str, value: any) -> None:\n",
    "        \"\"\"è®¾ç½®ç¼“å­˜æ•°æ®\"\"\"\n",
    "        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ¸…ç†ç©ºé—´\n",
    "        if self._total_items() >= self.max_size:\n",
    "            self._evict_least_used()\n",
    "        \n",
    "        self.cache_data[namespace][key] = value\n",
    "        self.access_counts[namespace + \":\" + key] = 1\n",
    "        \n",
    "        logger.debug(f\"ç¼“å­˜è®¾ç½®: {namespace}:{key}\")\n",
    "    \n",
    "    def _total_items(self) -> int:\n",
    "        \"\"\"è®¡ç®—æ€»ç¼“å­˜é¡¹æ•°\"\"\"\n",
    "        return sum(len(data) for data in self.cache_data.values())\n",
    "    \n",
    "    def _evict_least_used(self) -> None:\n",
    "        \"\"\"æ¸…ç†æœ€å°‘ä½¿ç”¨çš„ç¼“å­˜é¡¹\"\"\"\n",
    "        if not self.access_counts:\n",
    "            return\n",
    "        \n",
    "        # æ‰¾åˆ°ä½¿ç”¨æ¬¡æ•°æœ€å°‘çš„é”®\n",
    "        least_used_key = min(self.access_counts.keys(), \n",
    "                           key=lambda k: self.access_counts[k])\n",
    "        \n",
    "        namespace, key = least_used_key.split(\":\", 1)\n",
    "        \n",
    "        # æ¸…ç†æ•°æ®\n",
    "        del self.cache_data[namespace][key]\n",
    "        del self.access_counts[least_used_key]\n",
    "        \n",
    "        # å¦‚æœå‘½åç©ºé—´ä¸ºç©ºï¼Œä¹Ÿæ¸…ç†æ‰\n",
    "        if not self.cache_data[namespace]:\n",
    "            del self.cache_data[namespace]\n",
    "        \n",
    "        self.namespace_stats[namespace].evictions += 1\n",
    "        logger.info(f\"æ¸…ç†ç¼“å­˜é¡¹: {namespace}:{key}\")\n",
    "    \n",
    "    def get_stats(self) -> Dict[str, CacheStats]:\n",
    "        \"\"\"è·å–ç»Ÿè®¡ä¿¡æ¯\"\"\"\n",
    "        return dict(self.namespace_stats)\n",
    "    \n",
    "    def clear_namespace(self, namespace: str) -> None:\n",
    "        \"\"\"æ¸…ç©ºæŒ‡å®šå‘½åç©ºé—´\"\"\"\n",
    "        if namespace in self.cache_data:\n",
    "            # æ¸…ç†ç›¸å…³çš„è®¿é—®è®¡æ•°\n",
    "            keys_to_remove = [k for k in self.access_counts.keys() \n",
    "                            if k.startswith(f\"{namespace}:\")]\n",
    "            for key in keys_to_remove:\n",
    "                del self.access_counts[key]\n",
    "            \n",
    "            del self.cache_data[namespace]\n",
    "            logger.info(f\"æ¸…ç©ºå‘½åç©ºé—´: {namespace}\")\n",
    "\n",
    "# æµ‹è¯•ç¼“å­˜ç®¡ç†å™¨\n",
    "cache_manager = ProductionCacheManager(max_size=10)\n",
    "\n",
    "# æ¨¡æ‹Ÿç¼“å­˜æ“ä½œ\n",
    "print(\"\\\\næµ‹è¯•ç¼“å­˜æ“ä½œ:\")\n",
    "\n",
    "# è®¾ç½®ä¸åŒå‘½åç©ºé—´çš„æ•°æ®\n",
    "cache_manager.set(\"users\", \"user_123\", {\"name\": \"å¼ ä¸‰\", \"age\": 25})\n",
    "cache_manager.set(\"users\", \"user_456\", {\"name\": \"æå››\", \"age\": 30})\n",
    "cache_manager.set(\"products\", \"prod_001\", {\"name\": \"Pythonæ•™ç¨‹\", \"price\": 99})\n",
    "cache_manager.set(\"products\", \"prod_002\", {\"name\": \"æ•°æ®ç»“æ„\", \"price\": 79})\n",
    "\n",
    "# æµ‹è¯•ç¼“å­˜å‘½ä¸­\n",
    "user_data = cache_manager.get(\"users\", \"user_123\")\n",
    "print(f\"è·å–ç”¨æˆ·æ•°æ®: {user_data}\")\n",
    "\n",
    "product_data = cache_manager.get(\"products\", \"prod_001\")\n",
    "print(f\"è·å–äº§å“æ•°æ®: {product_data}\")\n",
    "\n",
    "# æµ‹è¯•ç¼“å­˜æœªå‘½ä¸­\n",
    "missing_data = cache_manager.get(\"users\", \"user_999\")\n",
    "print(f\"è·å–ä¸å­˜åœ¨çš„æ•°æ®: {missing_data}\")\n",
    "\n",
    "# è§¦å‘ç¼“å­˜æ¸…ç†ï¼ˆæ·»åŠ è¶…è¿‡å®¹é‡çš„æ•°æ®ï¼‰\n",
    "print(\"\\\\nè§¦å‘ç¼“å­˜æ¸…ç†:\")\n",
    "for i in range(15):\n",
    "    cache_manager.set(\"temp\", f\"item_{i}\", f\"data_{i}\")\n",
    "\n",
    "# æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯\n",
    "print(\"\\\\nç¼“å­˜ç»Ÿè®¡ä¿¡æ¯:\")\n",
    "stats = cache_manager.get_stats()\n",
    "for namespace, stat in stats.items():\n",
    "    print(f\"{namespace}: å‘½ä¸­ç‡={stat.hit_rate:.1f}%, \"\n",
    "          f\"å‘½ä¸­={stat.hits}, æœªå‘½ä¸­={stat.misses}, æ¸…ç†={stat.evictions}\")\n",
    "\n",
    "print(f\"\\\\nå½“å‰ç¼“å­˜æ€»é¡¹æ•°: {cache_manager._total_items()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 5. æ€§èƒ½ä¼˜åŒ–å’Œæœ€ä½³å®è·µ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "from memory_profiler import memory_usage  # éœ€è¦å®‰è£…: pip install memory_profiler\n",
    "\n",
    "print(\"=== æ€§èƒ½å¯¹æ¯”ï¼šdefaultdict vs æ™®é€šå­—å…¸ ===\")\n",
    "\n",
    "def benchmark_normal_dict(n: int) -> float:\n",
    "    \"\"\"æµ‹è¯•æ™®é€šå­—å…¸çš„æ€§èƒ½\"\"\"\n",
    "    start_time = time.time()\n",
    "    data = {}\n",
    "    \n",
    "    for i in range(n):\n",
    "        key = f\"group_{i % 100}\"\n",
    "        if key not in data:\n",
    "            data[key] = []\n",
    "        data[key].append(i)\n",
    "    \n",
    "    return time.time() - start_time\n",
    "\n",
    "def benchmark_defaultdict(n: int) -> float:\n",
    "    \"\"\"æµ‹è¯• defaultdict çš„æ€§èƒ½\"\"\"\n",
    "    start_time = time.time()\n",
    "    data = defaultdict(list)\n",
    "    \n",
    "    for i in range(n):\n",
    "        key = f\"group_{i % 100}\"\n",
    "        data[key].append(i)\n",
    "    \n",
    "    return time.time() - start_time\n",
    "\n",
    "def benchmark_setdefault(n: int) -> float:\n",
    "    \"\"\"æµ‹è¯•ä½¿ç”¨ setdefault çš„æ€§èƒ½\"\"\"\n",
    "    start_time = time.time()\n",
    "    data = {}\n",
    "    \n",
    "    for i in range(n):\n",
    "        key = f\"group_{i % 100}\"\n",
    "        data.setdefault(key, []).append(i)\n",
    "    \n",
    "    return time.time() - start_time\n",
    "\n",
    "# æ€§èƒ½æµ‹è¯•\n",
    "test_sizes = [1000, 10000, 100000]\n",
    "\n",
    "print(\"æ“ä½œæ•°\\\\t\\\\tæ™®é€šå­—å…¸\\\\tdefaultdict\\\\tsetdefault\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for size in test_sizes:\n",
    "    normal_time = benchmark_normal_dict(size)\n",
    "    default_time = benchmark_defaultdict(size)\n",
    "    setdefault_time = benchmark_setdefault(size)\n",
    "    \n",
    "    print(f\"{size:,}\\\\t\\\\t{normal_time:.4f}s\\\\t{default_time:.4f}s\\\\t{setdefault_time:.4f}s\")\n",
    "\n",
    "# å†…å­˜ä½¿ç”¨å¯¹æ¯”\n",
    "print(f\"\\\\n=== å†…å­˜ä½¿ç”¨å¯¹æ¯” ===\")\n",
    "\n",
    "def memory_test_normal_dict():\n",
    "    data = {}\n",
    "    for i in range(10000):\n",
    "        key = f\"group_{i % 100}\"\n",
    "        if key not in data:\n",
    "            data[key] = []\n",
    "        data[key].append(i)\n",
    "    return data\n",
    "\n",
    "def memory_test_defaultdict():\n",
    "    data = defaultdict(list)\n",
    "    for i in range(10000):\n",
    "        key = f\"group_{i % 100}\"\n",
    "        data[key].append(i)\n",
    "    return data\n",
    "\n",
    "try:\n",
    "    # æµ‹è¯•å†…å­˜ä½¿ç”¨ï¼ˆå¦‚æœå®‰è£…äº† memory_profilerï¼‰\n",
    "    normal_memory = memory_usage(memory_test_normal_dict)\n",
    "    default_memory = memory_usage(memory_test_defaultdict)\n",
    "    \n",
    "    print(f\"æ™®é€šå­—å…¸æœ€å¤§å†…å­˜ä½¿ç”¨: {max(normal_memory):.2f} MB\")\n",
    "    print(f\"defaultdictæœ€å¤§å†…å­˜ä½¿ç”¨: {max(default_memory):.2f} MB\")\n",
    "except ImportError:\n",
    "    print(\"æœªå®‰è£… memory_profilerï¼Œè·³è¿‡å†…å­˜æµ‹è¯•\")\n",
    "    print(\"å®‰è£…å‘½ä»¤: pip install memory_profiler\")\n",
    "\n",
    "# æœ€ä½³å®è·µç¤ºä¾‹\n",
    "print(f\"\\\\n=== defaultdict æœ€ä½³å®è·µ ===\")\n",
    "\n",
    "class BestPracticesDemo:\n",
    "    \"\"\"å±•ç¤º defaultdict æœ€ä½³å®è·µ\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def practice_1_avoid_lambda_when_possible():\n",
    "        \"\"\"å®è·µ1ï¼šé¿å…ä¸å¿…è¦çš„ lambda\"\"\"\n",
    "        print(\"âŒ ä¸æ¨èï¼š\")\n",
    "        bad_dict = defaultdict(lambda: [])  # ä¸å¿…è¦çš„ lambda\n",
    "        print(f\"defaultdict(lambda: []) -> {bad_dict['key']}\")\n",
    "        \n",
    "        print(\"âœ… æ¨èï¼š\")\n",
    "        good_dict = defaultdict(list)  # ç›´æ¥ä½¿ç”¨ç±»å‹\n",
    "        print(f\"defaultdict(list) -> {good_dict['key']}\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def practice_2_type_annotations():\n",
    "        \"\"\"å®è·µ2ï¼šä½¿ç”¨ç±»å‹æ³¨è§£\"\"\"\n",
    "        print(\"\\\\nâœ… ä½¿ç”¨ç±»å‹æ³¨è§£æé«˜ä»£ç å¯è¯»æ€§ï¼š\")\n",
    "        \n",
    "        # æ˜ç¡®çš„ç±»å‹æ³¨è§£\n",
    "        user_groups: DefaultDict[str, List[str]] = defaultdict(list)\n",
    "        user_counts: DefaultDict[str, int] = defaultdict(int)\n",
    "        \n",
    "        print(\"ä»£ç æ›´æ¸…æ™°ï¼ŒIDE æ”¯æŒæ›´å¥½\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def practice_3_convert_when_needed():\n",
    "        \"\"\"å®è·µ3ï¼šå¿…è¦æ—¶è½¬æ¢ä¸ºæ™®é€šå­—å…¸\"\"\"\n",
    "        print(\"\\\\nâœ… API è¿”å›æ—¶è½¬æ¢ä¸ºæ™®é€šå­—å…¸ï¼š\")\n",
    "        \n",
    "        data = defaultdict(list)\n",
    "        data['users'].append('å¼ ä¸‰')\n",
    "        data['users'].append('æå››')\n",
    "        \n",
    "        # è½¬æ¢ä¸ºæ™®é€šå­—å…¸è¿›è¡Œ JSON åºåˆ—åŒ–\n",
    "        api_response = dict(data)\n",
    "        print(f\"API å“åº”: {api_response}\")\n",
    "        print(f\"å¯ä»¥å®‰å…¨åºåˆ—åŒ–ä¸º JSON: {json.dumps(api_response, ensure_ascii=False)}\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def practice_4_careful_with_nesting():\n",
    "        \"\"\"å®è·µ4ï¼šè°¨æ…å¤„ç†åµŒå¥—ç»“æ„\"\"\"\n",
    "        print(\"\\\\nâœ… åµŒå¥— defaultdict çš„æ­£ç¡®æ–¹å¼ï¼š\")\n",
    "        \n",
    "        # æ–¹å¼1ï¼šä½¿ç”¨ lambda\n",
    "        nested1 = defaultdict(lambda: defaultdict(int))\n",
    "        nested1['user']['login_count'] += 1\n",
    "        print(f\"æ–¹å¼1ç»“æœ: {dict(nested1)}\")\n",
    "        \n",
    "        # æ–¹å¼2ï¼šå®šä¹‰è¾…åŠ©å‡½æ•°ï¼ˆæ›´æ¸…æ™°ï¼‰\n",
    "        def create_user_stats():\n",
    "            return defaultdict(int)\n",
    "        \n",
    "        nested2 = defaultdict(create_user_stats)\n",
    "        nested2['user']['login_count'] += 1\n",
    "        print(f\"æ–¹å¼2ç»“æœ: {dict(nested2)}\")\n",
    "\n",
    "# è¿è¡Œæœ€ä½³å®è·µæ¼”ç¤º\n",
    "demo = BestPracticesDemo()\n",
    "demo.practice_1_avoid_lambda_when_possible()\n",
    "demo.practice_2_type_annotations()\n",
    "demo.practice_3_convert_when_needed()\n",
    "demo.practice_4_careful_with_nesting()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 6. å¸¸è§é™·é˜±å’Œæ³¨æ„äº‹é¡¹\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== å¸¸è§é™·é˜±å’Œè§£å†³æ–¹æ¡ˆ ===\")\n",
    "\n",
    "# é™·é˜±1ï¼šæ„å¤–åˆ›å»ºé”®\n",
    "print(\"âš ï¸  é™·é˜±1ï¼šä»…ä»…è®¿é—®å°±ä¼šåˆ›å»ºé”®\")\n",
    "data = defaultdict(list)\n",
    "print(f\"è®¿é—®å‰çš„é”®: {list(data.keys())}\")\n",
    "\n",
    "# ä»…ä»…æ£€æŸ¥ä¼šåˆ›å»ºé”®ï¼\n",
    "if data['nonexistent_key']:  # è¿™ä¼šåˆ›å»ºé”®ï¼\n",
    "    print(\"ä¸ä¼šæ‰§è¡Œ\")\n",
    "\n",
    "print(f\"è®¿é—®åçš„é”®: {list(data.keys())}\")\n",
    "print(f\"å€¼: {data['nonexistent_key']}\")\n",
    "\n",
    "print(\"\\\\nâœ… è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨ in æ“ä½œç¬¦æˆ– get æ–¹æ³•\")\n",
    "safe_data = defaultdict(list)\n",
    "print(f\"å®‰å…¨æ£€æŸ¥å‰çš„é”®: {list(safe_data.keys())}\")\n",
    "\n",
    "# å®‰å…¨çš„æ£€æŸ¥æ–¹å¼\n",
    "if 'nonexistent_key' in safe_data:\n",
    "    print(\"ä¸ä¼šæ‰§è¡Œ\")\n",
    "\n",
    "# æˆ–è€…ä½¿ç”¨ get æ–¹æ³•\n",
    "value = safe_data.get('nonexistent_key')\n",
    "print(f\"å®‰å…¨æ£€æŸ¥åçš„é”®: {list(safe_data.keys())}\")\n",
    "print(f\"get è¿”å›å€¼: {value}\")\n",
    "\n",
    "# é™·é˜±2ï¼šåºåˆ—åŒ–é—®é¢˜\n",
    "print(\"\\\\nâš ï¸  é™·é˜±2ï¼šJSON åºåˆ—åŒ–é—®é¢˜\")\n",
    "try:\n",
    "    json_data = defaultdict(list)\n",
    "    json_data['items'].append('test')\n",
    "    \n",
    "    # è¿™ä¼šå¤±è´¥ï¼\n",
    "    json_str = json.dumps(json_data)\n",
    "except TypeError as e:\n",
    "    print(f\"åºåˆ—åŒ–å¤±è´¥: {e}\")\n",
    "\n",
    "print(\"âœ… è§£å†³æ–¹æ¡ˆï¼šè½¬æ¢ä¸ºæ™®é€šå­—å…¸\")\n",
    "json_data = defaultdict(list)\n",
    "json_data['items'].append('test')\n",
    "json_str = json.dumps(dict(json_data))\n",
    "print(f\"åºåˆ—åŒ–æˆåŠŸ: {json_str}\")\n",
    "\n",
    "# é™·é˜±3ï¼šå·¥å‚å‡½æ•°çš„å‰¯ä½œç”¨\n",
    "print(\"\\\\nâš ï¸  é™·é˜±3ï¼šå·¥å‚å‡½æ•°æœ‰å‰¯ä½œç”¨\")\n",
    "\n",
    "class Counter:\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "    \n",
    "    def __call__(self):\n",
    "        self.count += 1\n",
    "        print(f\"å·¥å‚å‡½æ•°è¢«è°ƒç”¨ç¬¬ {self.count} æ¬¡\")\n",
    "        return []\n",
    "\n",
    "counter = Counter()\n",
    "problematic_dict = defaultdict(counter)\n",
    "\n",
    "print(\"è®¿é—®é”®ä¼šè§¦å‘å·¥å‚å‡½æ•°:\")\n",
    "_ = problematic_dict['key1']\n",
    "_ = problematic_dict['key2']\n",
    "_ = problematic_dict['key3']\n",
    "\n",
    "print(\"\\\\nâœ… è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨æ— å‰¯ä½œç”¨çš„å·¥å‚å‡½æ•°\")\n",
    "clean_dict = defaultdict(list)  # æ— å‰¯ä½œç”¨\n",
    "\n",
    "# é™·é˜±4ï¼šåµŒå¥— defaultdict çš„æ··ä¹±\n",
    "print(\"\\\\nâš ï¸  é™·é˜±4ï¼šåµŒå¥—ç»“æ„å¯èƒ½å¯¼è‡´æ··ä¹±\")\n",
    "\n",
    "# é—®é¢˜ä»£ç \n",
    "messy_nested = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))\n",
    "messy_nested['a']['b']['c'] = 1\n",
    "\n",
    "print(\"åµŒå¥—å¤ªæ·±ï¼Œéš¾ä»¥ç†è§£:\")\n",
    "print(messy_nested['a']['b']['c'])\n",
    "\n",
    "print(\"\\\\nâœ… è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨æ¸…æ™°çš„ç»“æ„\")\n",
    "\n",
    "class UserStats:\n",
    "    def __init__(self):\n",
    "        self.login_count = 0\n",
    "        self.page_views = 0\n",
    "        self.actions = []\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            'login_count': self.login_count,\n",
    "            'page_views': self.page_views,\n",
    "            'actions': self.actions\n",
    "        }\n",
    "\n",
    "clean_nested = defaultdict(UserStats)\n",
    "clean_nested['user1'].login_count += 1\n",
    "clean_nested['user1'].actions.append('login')\n",
    "\n",
    "print(\"æ¸…æ™°çš„ç»“æ„:\")\n",
    "print(clean_nested['user1'].to_dict())\n",
    "\n",
    "# é™·é˜±5ï¼šå†…å­˜æ³„æ¼é£é™©\n",
    "print(\"\\\\nâš ï¸  é™·é˜±5ï¼šæ„å¤–çš„å†…å­˜ä½¿ç”¨\")\n",
    "\n",
    "def memory_leak_example():\n",
    "    # å¦‚æœé”®æ˜¯åŠ¨æ€ç”Ÿæˆçš„ï¼Œå¯èƒ½å¯¼è‡´å†…å­˜æ³„æ¼\n",
    "    leak_dict = defaultdict(list)\n",
    "    \n",
    "    # æ¨¡æ‹Ÿéšæœºé”®ï¼ˆå®é™…ä½¿ç”¨ä¸­å¯èƒ½æ¥è‡ªç”¨æˆ·è¾“å…¥ï¼‰\n",
    "    import random\n",
    "    for i in range(1000):\n",
    "        random_key = f\"user_{random.randint(1, 1000000)}\"\n",
    "        leak_dict[random_key].append(f\"data_{i}\")\n",
    "    \n",
    "    return len(leak_dict)\n",
    "\n",
    "leaked_keys = memory_leak_example()\n",
    "print(f\"åˆ›å»ºäº† {leaked_keys} ä¸ªé”®ï¼Œå¯èƒ½å¯¼è‡´å†…å­˜é—®é¢˜\")\n",
    "\n",
    "print(\"\\\\nâœ… è§£å†³æ–¹æ¡ˆï¼šé™åˆ¶é”®çš„æ•°é‡æˆ–å®šæœŸæ¸…ç†\")\n",
    "\n",
    "class BoundedDefaultDict(defaultdict):\n",
    "    def __init__(self, default_factory, max_size=1000):\n",
    "        super().__init__(default_factory)\n",
    "        self.max_size = max_size\n",
    "    \n",
    "    def __setitem__(self, key, value):\n",
    "        if len(self) >= self.max_size and key not in self:\n",
    "            # ç§»é™¤æœ€è€çš„é”®ï¼ˆç®€å•å®ç°ï¼‰\n",
    "            oldest_key = next(iter(self))\n",
    "            del self[oldest_key]\n",
    "            print(f\"ç§»é™¤æœ€è€çš„é”®: {oldest_key}\")\n",
    "        \n",
    "        super().__setitem__(key, value)\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        if len(self) >= self.max_size and key not in self:\n",
    "            oldest_key = next(iter(self))\n",
    "            del self[oldest_key]\n",
    "            print(f\"ç§»é™¤æœ€è€çš„é”®: {oldest_key}\")\n",
    "        \n",
    "        return super().__getitem__(key)\n",
    "\n",
    "bounded_dict = BoundedDefaultDict(list, max_size=3)\n",
    "for i in range(5):\n",
    "    bounded_dict[f'key_{i}'].append(f'value_{i}')\n",
    "\n",
    "print(f\"æœ€ç»ˆé”®æ•°é‡: {len(bounded_dict)}\")\n",
    "print(f\"å‰©ä½™çš„é”®: {list(bounded_dict.keys())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 7. æ€»ç»“ä¸å­¦ä¹ å»ºè®®\n",
    "\n",
    "### ğŸ¯ æ ¸å¿ƒè¦ç‚¹å›é¡¾\n",
    "\n",
    "1. **åŸºæœ¬åŸç†**ï¼š`defaultdict` é€šè¿‡å·¥å‚å‡½æ•°è‡ªåŠ¨åˆ›å»ºç¼ºå¤±é”®çš„é»˜è®¤å€¼ï¼Œé¿å… `KeyError`\n",
    "2. **æ€§èƒ½ä¼˜åŠ¿**ï¼šæ¯”ä¼ ç»Ÿçš„é”®æ£€æŸ¥æ–¹å¼æ›´é«˜æ•ˆï¼Œç‰¹åˆ«æ˜¯åœ¨å¤§é‡æ•°æ®æ“ä½œæ—¶\n",
    "3. **å¸¸ç”¨åœºæ™¯**ï¼šåˆ†ç»„ã€è®¡æ•°ã€åµŒå¥—ç»“æ„ã€æ•°æ®èšåˆ\n",
    "4. **ç±»å‹å®‰å…¨**ï¼šé…åˆç±»å‹æ³¨è§£ä½¿ç”¨ï¼Œæé«˜ä»£ç è´¨é‡\n",
    "\n",
    "### ğŸ“š å­¦ä¹ è·¯çº¿å»ºè®®\n",
    "\n",
    "**åˆå­¦è€…**ï¼š\n",
    "- æŒæ¡åŸºæœ¬è¯­æ³•å’Œå¸¸ç”¨å·¥å‚å‡½æ•°ï¼ˆ`list`, `int`, `set`, `dict`ï¼‰\n",
    "- ç»ƒä¹ ç®€å•çš„åˆ†ç»„å’Œè®¡æ•°ä»»åŠ¡\n",
    "- ç†è§£ä¸æ™®é€šå­—å…¸çš„åŒºåˆ«\n",
    "\n",
    "**ä¸­çº§å¼€å‘è€…**ï¼š\n",
    "- å­¦ä¼šè®¾è®¡åµŒå¥—æ•°æ®ç»“æ„\n",
    "- æŒæ¡æ€§èƒ½ä¼˜åŒ–æŠ€å·§\n",
    "- äº†è§£å¸¸è§é™·é˜±å’Œè§£å†³æ–¹æ¡ˆ\n",
    "\n",
    "**é«˜çº§å¼€å‘è€…**ï¼š\n",
    "- ç»“åˆå…¶ä»– collections æ¨¡å—å·¥å…·ä½¿ç”¨\n",
    "- è®¾è®¡ç”Ÿäº§çº§çš„æ•°æ®å¤„ç†ç³»ç»Ÿ\n",
    "- è‡ªå®šä¹‰ defaultdict å­ç±»\n",
    "\n",
    "### ğŸ”§ å®æˆ˜ç»ƒä¹ å»ºè®®\n",
    "\n",
    "1. **æ—¥å¿—åˆ†æå™¨**ï¼šæŒ‰æ—¶é—´ã€çº§åˆ«ã€æ¨¡å—åˆ†ç»„åˆ†ææ—¥å¿—\n",
    "2. **ç”¨æˆ·è¡Œä¸ºè¿½è¸ª**ï¼šåˆ†æç”¨æˆ·è·¯å¾„å’Œè½¬åŒ–ç‡\n",
    "3. **æ•°æ®æŠ¥è¡¨ç”Ÿæˆå™¨**ï¼šå¤šç»´åº¦æ•°æ®èšåˆå’Œç»Ÿè®¡\n",
    "4. **ç¼“å­˜ç³»ç»Ÿ**ï¼šå®ç°å¸¦æœ‰ç»Ÿè®¡åŠŸèƒ½çš„ç¼“å­˜ç®¡ç†å™¨\n",
    "\n",
    "### ğŸš€ è¿›é˜¶å­¦ä¹ \n",
    "\n",
    "- **collections.Counter**ï¼šä¸“é—¨ç”¨äºè®¡æ•°çš„å·¥å…·\n",
    "- **collections.ChainMap**ï¼šå¤šå­—å…¸é“¾å¼æŸ¥æ‰¾\n",
    "- **collections.OrderedDict**ï¼šä¿åºå­—å…¸\n",
    "- **functools.lru_cache**ï¼šä¸ç¼“å­˜ç›¸å…³çš„è£…é¥°å™¨\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æœ€ç»ˆç»ƒä¹ ï¼šç»¼åˆåº”ç”¨ç¤ºä¾‹\n",
    "print(\"=== ğŸ¯ ç»¼åˆç»ƒä¹ ï¼šç½‘ç«™è®¿é—®ç»Ÿè®¡åˆ†æå™¨ ===\")\n",
    "\n",
    "class WebsiteAnalyzer:\n",
    "    \"\"\"ç½‘ç«™è®¿é—®ç»Ÿè®¡åˆ†æå™¨ - ç»¼åˆåº”ç”¨ defaultdict\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # ä½¿ç”¨ä¸åŒç±»å‹çš„ defaultdict æ¥å­˜å‚¨ç»Ÿè®¡æ•°æ®\n",
    "        self.page_views: DefaultDict[str, int] = defaultdict(int)\n",
    "        self.user_sessions: DefaultDict[str, List[Dict]] = defaultdict(list)\n",
    "        self.hourly_traffic: DefaultDict[int, int] = defaultdict(int)\n",
    "        self.referrer_stats: DefaultDict[str, int] = defaultdict(int)\n",
    "        self.device_types: DefaultDict[str, Set[str]] = defaultdict(set)\n",
    "        \n",
    "        # ç”¨äºè®¡ç®—å¹³å‡å€¼çš„æ•°æ®\n",
    "        self.response_times: DefaultDict[str, List[float]] = defaultdict(list)\n",
    "        \n",
    "        logger.info(\"ç½‘ç«™åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ\")\n",
    "    \n",
    "    def log_visit(self, user_id: str, page: str, timestamp: str, \n",
    "                  referrer: str = \"direct\", device: str = \"desktop\",\n",
    "                  response_time: float = 0.1):\n",
    "        \"\"\"è®°å½•ä¸€æ¬¡è®¿é—®\"\"\"\n",
    "        \n",
    "        # æå–å°æ—¶ä¿¡æ¯\n",
    "        hour = int(timestamp.split(':')[0]) if ':' in timestamp else 12\n",
    "        \n",
    "        # æ›´æ–°å„é¡¹ç»Ÿè®¡\n",
    "        self.page_views[page] += 1\n",
    "        self.user_sessions[user_id].append({\n",
    "            'page': page,\n",
    "            'timestamp': timestamp,\n",
    "            'referrer': referrer,\n",
    "            'device': device,\n",
    "            'response_time': response_time\n",
    "        })\n",
    "        self.hourly_traffic[hour] += 1\n",
    "        self.referrer_stats[referrer] += 1\n",
    "        self.device_types[device].add(user_id)\n",
    "        self.response_times[page].append(response_time)\n",
    "        \n",
    "        logger.debug(f\"è®°å½•è®¿é—®: {user_id} -> {page}\")\n",
    "    \n",
    "    def get_popular_pages(self, top_n: int = 5) -> List[tuple]:\n",
    "        \"\"\"è·å–æœ€å—æ¬¢è¿çš„é¡µé¢\"\"\"\n",
    "        return sorted(self.page_views.items(), \n",
    "                     key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    \n",
    "    def get_user_behavior(self, user_id: str) -> Dict:\n",
    "        \"\"\"åˆ†æç”¨æˆ·è¡Œä¸º\"\"\"\n",
    "        sessions = self.user_sessions[user_id]\n",
    "        if not sessions:\n",
    "            return {'error': 'User not found'}\n",
    "        \n",
    "        pages_visited = [session['page'] for session in sessions]\n",
    "        unique_pages = len(set(pages_visited))\n",
    "        \n",
    "        return {\n",
    "            'total_visits': len(sessions),\n",
    "            'unique_pages': unique_pages,\n",
    "            'pages_visited': pages_visited,\n",
    "            'devices_used': list(set(s['device'] for s in sessions)),\n",
    "            'referrer_sources': list(set(s['referrer'] for s in sessions))\n",
    "        }\n",
    "    \n",
    "    def get_performance_stats(self) -> Dict:\n",
    "        \"\"\"è·å–æ€§èƒ½ç»Ÿè®¡\"\"\"\n",
    "        performance = {}\n",
    "        for page, times in self.response_times.items():\n",
    "            if times:\n",
    "                performance[page] = {\n",
    "                    'avg_response_time': sum(times) / len(times),\n",
    "                    'min_response_time': min(times),\n",
    "                    'max_response_time': max(times),\n",
    "                    'total_requests': len(times)\n",
    "                }\n",
    "        return performance\n",
    "    \n",
    "    def generate_report(self) -> str:\n",
    "        \"\"\"ç”Ÿæˆå®Œæ•´çš„åˆ†ææŠ¥å‘Š\"\"\"\n",
    "        report = []\n",
    "        report.append(\"ğŸ“Š ç½‘ç«™è®¿é—®ç»Ÿè®¡æŠ¥å‘Š\")\n",
    "        report.append(\"=\" * 30)\n",
    "        \n",
    "        # çƒ­é—¨é¡µé¢\n",
    "        popular_pages = self.get_popular_pages()\n",
    "        report.append(f\"\\\\nğŸ”¥ çƒ­é—¨é¡µé¢ (å‰5å):\")\n",
    "        for i, (page, views) in enumerate(popular_pages, 1):\n",
    "            report.append(f\"{i}. {page}: {views} æ¬¡è®¿é—®\")\n",
    "        \n",
    "        # æµé‡åˆ†å¸ƒ\n",
    "        report.append(f\"\\\\nâ° 24å°æ—¶æµé‡åˆ†å¸ƒ:\")\n",
    "        for hour in sorted(self.hourly_traffic.keys()):\n",
    "            count = self.hourly_traffic[hour]\n",
    "            bar = \"â–ˆ\" * (count // 5)  # ç®€å•çš„æŸ±çŠ¶å›¾\n",
    "            report.append(f\"{hour:02d}:00 - {count:3d} è®¿é—® {bar}\")\n",
    "        \n",
    "        # æ¥æºç»Ÿè®¡\n",
    "        report.append(f\"\\\\nğŸ”— æµé‡æ¥æº:\")\n",
    "        total_visits = sum(self.referrer_stats.values())\n",
    "        for referrer, count in sorted(self.referrer_stats.items(), \n",
    "                                    key=lambda x: x[1], reverse=True):\n",
    "            percentage = (count / total_visits * 100) if total_visits > 0 else 0\n",
    "            report.append(f\"{referrer}: {count} ({percentage:.1f}%)\")\n",
    "        \n",
    "        # è®¾å¤‡ç»Ÿè®¡\n",
    "        report.append(f\"\\\\nğŸ“± è®¾å¤‡ç±»å‹ç»Ÿè®¡:\")\n",
    "        for device, users in self.device_types.items():\n",
    "            report.append(f\"{device}: {len(users)} ç”¨æˆ·\")\n",
    "        \n",
    "        return \"\\\\n\".join(report)\n",
    "\n",
    "# åˆ›å»ºåˆ†æå™¨å¹¶æ¨¡æ‹Ÿæ•°æ®\n",
    "analyzer = WebsiteAnalyzer()\n",
    "\n",
    "# æ¨¡æ‹Ÿè®¿é—®æ•°æ®\n",
    "sample_visits = [\n",
    "    (\"user_001\", \"/home\", \"09:30\", \"google.com\", \"mobile\", 0.12),\n",
    "    (\"user_001\", \"/products\", \"09:32\", \"direct\", \"mobile\", 0.15),\n",
    "    (\"user_002\", \"/home\", \"10:15\", \"facebook.com\", \"desktop\", 0.08),\n",
    "    (\"user_002\", \"/about\", \"10:20\", \"direct\", \"desktop\", 0.10),\n",
    "    (\"user_003\", \"/products\", \"11:45\", \"google.com\", \"tablet\", 0.20),\n",
    "    (\"user_001\", \"/contact\", \"14:30\", \"direct\", \"mobile\", 0.18),\n",
    "    (\"user_004\", \"/home\", \"15:20\", \"twitter.com\", \"desktop\", 0.09),\n",
    "    (\"user_004\", \"/products\", \"15:25\", \"direct\", \"desktop\", 0.14),\n",
    "    (\"user_005\", \"/home\", \"16:45\", \"direct\", \"mobile\", 0.11),\n",
    "    (\"user_003\", \"/home\", \"18:30\", \"google.com\", \"tablet\", 0.13),\n",
    "]\n",
    "\n",
    "# è®°å½•æ‰€æœ‰è®¿é—®\n",
    "for visit in sample_visits:\n",
    "    analyzer.log_visit(*visit)\n",
    "\n",
    "# ç”ŸæˆæŠ¥å‘Š\n",
    "report = analyzer.generate_report()\n",
    "print(report)\n",
    "\n",
    "# åˆ†æç‰¹å®šç”¨æˆ·\n",
    "print(f\"\\\\nğŸ‘¤ ç”¨æˆ· user_001 è¡Œä¸ºåˆ†æ:\")\n",
    "user_behavior = analyzer.get_user_behavior(\"user_001\")\n",
    "for key, value in user_behavior.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# æ€§èƒ½ç»Ÿè®¡\n",
    "print(f\"\\\\nâš¡ é¡µé¢æ€§èƒ½ç»Ÿè®¡:\")\n",
    "perf_stats = analyzer.get_performance_stats()\n",
    "for page, stats in perf_stats.items():\n",
    "    print(f\"{page}:\")\n",
    "    print(f\"  å¹³å‡å“åº”æ—¶é—´: {stats['avg_response_time']:.3f}s\")\n",
    "    print(f\"  è¯·æ±‚æ¬¡æ•°: {stats['total_requests']}\")\n",
    "\n",
    "print(\"\\\\nğŸ‰ defaultdict å­¦ä¹ å®Œæˆï¼ç°åœ¨ä½ å·²ç»æŒæ¡äº†è¿™ä¸ªå¼ºå¤§çš„æ•°æ®ç»“æ„ã€‚\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonç»ƒä¹ ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
